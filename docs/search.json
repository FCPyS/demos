[
  {
    "objectID": "quienes.html#responsable",
    "href": "quienes.html#responsable",
    "title": "¿Quiénes somos?",
    "section": "Responsable",
    "text": "Responsable\n\nAna Ruth Escoto Castillo\nCentro de Estudios Teóricos y Multidisciplinarios en Ciencias Sociales, FCPYS Contacto: ana.escoto@politicas.unam.mx Profesora Asociada ‘C’ de Tiempo Completo. Cubículo: Edificio E - 211 - a la par de la DEPRO\nEs doctora en Estudios de Población por El Colegio de México, maestra en Población y Desarrollo por FLACSO-México e investigadora nivel I del Sistema Nacional de Investigadores. Estudia el bienestar de la población, en el presente, analizando los procesos de desigualdad y exclusión en los mercados laborales latinoamericanos así como la formación y estructura de los hogares; mientras que en el futuro, a través del estudio de la sustentabilidad. Co-coordinó la Red de Población y Trabajo de la Asociación Latinoamericana de Población (junto con Clara Márquez Scotti) y fui parte del Comité Técnico Académico de la Red Temática de CONACYT “TeTra: Trabajo y Condiciones laborales”. Actualmente es co-editora de la Revista Latinoamericana de Población"
  },
  {
    "objectID": "quienes.html#participantes-académicos",
    "href": "quienes.html#participantes-académicos",
    "title": "¿Quiénes somos?",
    "section": "Participantes Académicos",
    "text": "Participantes Académicos\n\nAbigail Vanessa Rojas Huerta\nInvestigadora Asociada “C” de tiempo completo en el Instituto de Geografía, Universidad Nacional Autónoma de México (UNAM) desde 2019. Profesora de asignatura en las Facultades de Ciencias y Filosofía y Letras, UNAM. Doctora en Estudios de Población y Maestra en Demografía por el Colegio de México, actuaria por la Facultad de Ciencias, UNAM. \nSus temas de investigación están relacionados con el envejecimiento poblacional, pensiones, seguridad social, salud y enfermedad; así como temas relacionados con la dinámica y el cambio demográfico. Ha publicado en revistas indexadas, y ha sido revisora de artículos, libros y proyectos de investigación. Además, ha dirigido tesis y ha sido parte de comités tutoriales a nivel licenciatura y posgrado de Facultades o Programas de la UNAM e INSP.\n\n\nEnrique Mauricio Padrón Innamorato\nInvestigador Titular de Tiempo Completo en el Instituto de Investigaciones Jurídicas en el Área de Sociología del Derecho. Es miembro del Sistema Nacional de Investigadores del CONACyT y pertenece al Nivel C del Programa de Primas al Desempeño del Personal Académico de Tiempo Completo (PRIDE - UNAM). Actualmente es Responsable Técnico de la Red Temática “Trabajo y condiciones laborales” (teTra) del CONACyT. Es Coordinador académico del Diplomado sobre el Derecho a la No Discriminación que se imparte en el IIJ – UNAM. Es doctor en Estudios de Población por el Colegio de México y Maestro en Población por la Facultad Latinoamericana de Ciencias Sociales (FLACSO México).\nSus principales líneas de investigación versan sobre mercados laborales; condiciones y características del trabajo y los trabajadores; vulnerabilidad social, exclusión social, discriminación, niñas, niños, adolescentes y jóvenes y el enfoque de derechos humanos. Desde hace más de diez años, además, ha trabajado e impartido cursos sobre metodología de la investigación social, tanto desde el enfoque cuantitativo como cualitativo. Pertenece a distintas asociaciones científicas y profesionales, tanto a nivel nacional como internacional.\n\n\nAbraham Granados Martínez\nInvestigador Nacional del Sistema Nacional de Investigadores (SNI) Nivel I, de enero de 2021 al 31 de diciembre de 2023. Investigador Asociado “C”, de Tiempo Completo. Investigador del Instituto de Investigaciones Económicas de la Universidad Nacional Autónoma de México desde agosto de 2017. Es Doctor en Economía por la Universidad Nacional Autónoma de México (UNAM); Maestro en Estudios Urbanos por El Colegio de México A.C y Licenciado en Economía por la Universidad Autónoma Metropolitana (UAM).\nActualmente coordina el Programa de Apoyo a Proyectos de Investigación e Innovación Tecnológica (PAPIIT) IA301922 Discriminación y vulnerabilidad en salud en la era post-COVID-19. Políticas públicas de igualdad de género y equidad territorial. Ha impartido materias en el Posgrado de la Facultad de Economía de la UNAM como “La Política Macroeconómica Actual y su Impacto en la Economía no Remunerada de la Reproducción” y “Macroeconomía III”."
  },
  {
    "objectID": "quienes.html#académicos-y-académicas-externas",
    "href": "quienes.html#académicos-y-académicas-externas",
    "title": "¿Quiénes somos?",
    "section": "Académicos y académicas externas",
    "text": "Académicos y académicas externas\n\nNina Castro-Méndez\nDoctora en Estudios de Población por El Colegio de México. Maestra en Población por la Facultad Latinoamericana de Ciencias Sociales (sede México) y Actuaria por la Facultad de Ciencias de la UNAM. Se ha desempeñado como docente de demografía, estadística y metodología de la investigación. Actualmente imparte el Seminario de Graduación de la Maestría en Demografía Social del Posgrado en Ciencias Sociales de la UNAM. \nSus intereses de investigación son: el trabajo remunerado y el trabajo de cuidados no remunerado; las trayectorias en el curso de vida y las técnicas cuantitativas y cualitativas para el análisis longitudinal; y la diversidad de desigualdades y vulnerabilidades que enfrentan las mujeres.\nEs integrante de la Red teTra \"Red temática Trabajo y Condiciones Laborales\" en la que ha participado en proyectos sobre: las condiciones de la población trabajadora en México ante la pandemia; la magnitud y características de los procesos laborales; la (re)conceptualización teórico-empírica de la dinámica laboral en México usando técnicas longitudianles.\n\n\nRicardo Regules García\nEs Senior Program Researcher en el Population Council donde desarrolla, supervisa y coordina proyectos programáticos y de investigación. Destacan entre ellos: Abriendo Futuros: A program for rural indigenous girls in Yucatan, Mexico; VoCes-19; Alianza Nacional por el Derecho a Decidir (andar) y Population, Environmental Risk, and the Climate Crisis; Assessment of young feminist organizing landscape and impact in Kenya and Mexico.\nDoctor en Estudios de Población por El Colegio de México. Maestro en Geografía Estudios Urbanos y Ambientales por la Universidad de Concordia - Canadá y Licenciado en Humanidades con Especialidad en Medio Ambiente Humano por la Universidad de Concordia - Canadá.\n\n\nVictor Manuel García Guerrero\nProfesor-Investigador de tiempo completo del Centro de Estudios Demográficos, Urbanos y Ambientales de El Colegio de México. Es Investigador Nacional nivel II por el Sistema Nacional de Investigadores del CONACyT. Editor Asociado de la revista Demographic Research. Es asesor en métodos demográficos para el Fondo de Población de Naciones Unidas, el Consejo Nacional de Población (en donde ha participado en los últimos tres ejercicios de proyecciones oficiales de población), en la Secretaría de Desarrollo Social, el Banco Interamericano de Desarrollo y en distintos despachos de consultoría, bancos y aseguradoras.\nDoctor en Estudios de Población por el CEDUA-COLMEX. Sus temas de investigación versan sobre demografía aplicada; estimaciones y proyecciones de población junto con su uso en la política pública y toma de decisiones; así como el análisis demográfico de la mortalidad, fecundidad y migraciones.\n\n\nClaudia Patricia Masferrer León\nClaudia Masferrer es Profesora-Investigadora en el Centro de Estudios Demográficos, Urbanos y Ambientales de El Colegio de México, Coordinadora del Seminario Migración, Desigualdad y Políticas Públicas y miembro del Cuerpo Académico Dinámica Demográfica. Desde 2023 es Editora Asociada del International Migration Review. Es Doctora en Sociología por la Universidad McGill y Maestra en Estadística por la Universidad de Texas en Austin. Sus líneas de investigación se centran en la migración interna e internacional, la integración de inmigrantes y las dinámicas demográficas, la desigualdad, y cómo las políticas públicas median estos procesos. Es autora del Atlas de migración de retorno de Estados Unidos a México, coordinadora del libro La década en que cambió la migración. Enfoque binacional del bienestar de los migrantes mexicanos en Estados Unidos y México, así como de decenas de artículos de investigación, capítulos de libro y reportes de política y coordinadora de otros libros.\n\n\nErika María Delfin Macías\nActualmente labora en la Universidad del Claustro de Sor Juana y en la Preparatoria Anáhuac campus Oxford. Cuenta con más de tres años de experiencia de divulgación cultural en televisión y radio, en donde ha ejercido como conductora (Radio y Televisión de Aguascalientes) durante dos años y uno y medio en Sín-Tesis Podcast; donde también es productora, directora y editora.\nEs Maestra en Estudios Latinoamericanos por la Pontificia Universidad Javeriana y Licenciada en Letras Hispánicas por la Universidad Autónoma de Aguascalientes. Sus líneas de investigación son las masculinidades en varones homosexuales y otros temas de género.\n\n\nJorge Augusto Paz\nDoctor en Economía (2007) y Doctor en Demografía (2018). Es Investigador Principal del Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET). También es Investigador Categoría 1 del Ministerio de Educación de la Nación Argentina y Profesor Regular Titular de la Universidad Nacional de Salta. Dirige el Instituto de Estudios Laborales y del Desarrollo Económico (IELDE) y la Maestría en Economía del Desarrollo (MED) de la Universidad Nacional de Salta. Miembro del Consejo Asesor para el proyecto de Pobreza Crónica (CIPPEC) e investigador asociado del Centro de Estudios sobre Desarrollo Humano (CEDH) Universidad de San Andrés. Investigador del Proyecto Internacional National Transfer Accounts (NTA) del Center for the Economics and Demography of Aging, University of California at Berkeley.\n\n\nVictoria Prieto Rosas\nEs Licenciada en Sociología por la Universidad de la República, Doctora en Demografía por la Universidad Autónoma de Barcelona, y docente del Programa de Población (PP) en régimen de dedicación total. Responsable del proyecto Using internet-based data to quantify and sample international migrants. Applications to examine recent immigration to Uruguay (Programa ANII-Sociedad Max Planck, 2019-2023), y coordinadora del Observatorio de Movilidad, Infancia y Familia (Convenio PP-UNICEF Uruguay, 2020-2023). Integra el equipo coordinador del Latin American Migration Project en la realización de etnoencuestas de inmigración en Chile, Colombia y Costa Rica (2021-2022), y es miembro fundador del grupo científico de Análisis Comparado sobre Migración y Desplazamiento Internacional en las Américas CAMINAR.\nSus intereses de investigación se centran en las dinámicas de inclusión-exclusión social de la población inmigrada en Uruguay y la región, combinando la producción de información primaria y la armonización de registros administrativos, encuestas específicas de migración, y datos derivados del uso de redes sociales web, analizando los límites y oportunidades para el estudio de las dinámicas de movilidad humana.\n\n\nMario Martínez Salgado\nInvestigador Asociado “C” de Tiempo Completo con adscripción en la Unidad de Investigación sobre Representaciones Culturales y Sociales de la Coordinación de Humanidades (UDIR), UNAM Campus Morelia.\nMaestro en Demografía y Doctor en Estudios de Población por El Colegio de México. En la UDIR-UNAM coordina el Seminario Identidad Cultura y Sociedad, y es co-coordinador del proyecto Escuela de Métodos para la Actualización Docente en la UNAM Campus Morelia.\nSus líneas de investigación son familia y curso de vida, uso del tiempo y trabajo no remunerado y los métodos de investigación social cuantitativos. Tiene experiencia didáctica dictando cursos de dinámica poblacional y metodología cuantitativa.\n\n\nIrene Casique\nEs investigadora titular en el Centro Regional de Investigaciones Multidisciplinarias de la Universidad Nacional Autónoma de México desde 1999 e integrante del Sistema Nacional de Investigadores desde 2001. Cursó la licenciatura en Sociología en la Universidad Católica Andrés Bello, en Caracas, la maestría en Demografía en el Colegio de México y obtuvo su doctorado en Sociología en la Universidad de Texas en Austin.\nRealiza investigaciones sobre temas de género, empoderamiento de las mujeres, dinámica familiar, salud reproductiva y violencia de género. Su principal línea de investigación es el empoderamiento de la mujer mexicana y la relación de este proceso con el bienestar de la mujer y la familia.\nSus libros más recientes son Apuesta por el Empoderamiento adolescente (2018) y Nuevas rutas y evidencias en el estudio de la violencia y la sexualidad de adolescentes (Coord., 2019)."
  },
  {
    "objectID": "quienes.html#participantes-estudiantes",
    "href": "quienes.html#participantes-estudiantes",
    "title": "¿Quiénes somos?",
    "section": "Participantes Estudiantes",
    "text": "Participantes Estudiantes\n\nTián Ramos Betancourt\nEstudiante de la Licenciatura en Sociología en la UNAM y del Programa de Especialización en Psicología de la Universidad de Palermo.\nHa participado como becarie en los proyectos PAPIME: “Las barreras para estudiantes con discapacidad en el aula” a cargo de la Dra. Patricia Brogna; “Recursos didácticos para la enseñanza-aprendizaje presencial y no-presencial de la asignatura Teoría del Intercambio y Acción Racional en sociología” del Dr. Christian Ascencio; y “DEMOS: Recursos didácticos para la enseñanza de la sociodemografía” de la Dra. Ana Escoto.\nTambién ha sido ayudante de profesor en las materias: Sociodemografía, Psicología Social, Teoría del Intercambio y Acción Racional y Teoría Crítica; en la Facultad de Ciencias Políticas y Sociales. Interesade en la interdisciplina: neurosociología, emociones, cuerpo e identidad.\n\n\nAna Paola Linares García\nEstudiante de Licenciatura en sociología. Becaria del proyecto PAPIME:DEMOS: Recursos didácticos para la enseñanza de la sociodemografía y ayudante de profesor en la materia Metodología I.\nHa participado como becaria en el proyecto PAPIIT “Las respuestas del mercado de trabajo mexicano ante la pandemia. Una visión desde las condiciones de la población trabajadora” a cargo de la Dra Ana Escoto. Y como ayudante de profesor en la materia de Metodología II.\nLe interesa compartir el conocimiento.\n\n\nZyanya Itzel Puga Sánchez\nEstudiante de licenciatura en sociología, ha participado en el curso “Inferencia e introducción a los modelos estadísticos en R” impartido por la Dra. Ana Ruth Escoto, fue voluntaria en la jornada universitaria de orientación vocacional 2023, ayudante de profesor en la materia de análisis cuantitativo de la carrera de ciencias políticas y en estadística aplicada a las ciencias sociales lll. \nIntereses en la sociología urbana y rural, la sociodemografía y la aplicación de la estadística en ciencias sociales.\n\n\nMiguel Ángel Cruz Ramírez\nEstudiante de la Licenciatura en Sociología en la Facultad de Ciencias Políticas y Sociales y participe en el proyecto PAPIME “DEMOS: Recursos didácticos para la enseñanza de la sociodemografía” de la Dra. Ana Escoto. También ha sido ayudante de profesor en las materias: Sociología Comprensiva, Sociología Funcionalista y Sociología del Género. \nInteresado en temas de género, infancias, y violencias, específicamente la violencia cultural.\n\n\nAldo Fabrizio Granados Avilés\nEstudiante de la Licenciatura en Sociología,  participó en el proyecto PAPIME “DEMOS: Recursos didácticos para la enseñanza de la sociodemografía” de la Dra. Ana Ruth Escoto Castillo. Además ha sido ayudante de profesor con la Dra. Teresa Azucena Rodríguez de la Vega en Sociología Clásica Positivista.  \nLe interesa la investigación, y compartir el conocimiento.\n\n\nOscar Uriel Valdés Bautista\nActualmente estudia el último año de la Licenciatura en Sociología en la Facultad de Ciencias Políticas y Sociales; y participa en el el proyecto PAPIME “DEMOS: Recursos didácticos para la enseñanza de la sociodemografía” de la Dra. Ana Ruth Escoto Castillo. \nHa sido profesor adjunto en la materia de Introducción a la Investigación en Ciencias Sociales,  Sociología Clásica: El proyecto científico del positivismo y Metodología II. Además de que ha trabajado como reportero y fotógrafo para el períodico ContraRéplica; y los medios digitales Capital CDMX y La Hoguera.\n\n\nAbril Saad Villegas\nEgresada de la Licenciatura en Sociología en la UNAM y tesista, estudiante independiente de artes visuales. Las líneas de investigación que más le interesan son los estudios de género, epistemologías feministas y la sociología del arte. Ha participado como expositora en el círculo de lectura “Sociología y Anarcofemínismo: Una historia de Amor Libre”; y como estudiante en la VI Edición de los cursos de verano sobre migraciones y movilidades del Seminario Universitario de Estudios sobre Desplazamiento, Interno, Migración, Exilio y Repatriación SUDIMER, en el curso “Temas de coyuntura. Movilidades, desigualdades y desplazamientos forzados”. \n\n\nAriadna Lozada Ávila\nArtivista y estudiante de la Licenciatura en Sociología por parte de la Facultad de Ciencias Políticas y Sociales de la UNAM. \nLíneas de investigación: futuridades, cuerpos y corporalidades. \nActualmente participante del programa académico en Estudios Interdisciplinarios del Centro Nacional de las Artes (CENART) y Campus Expandido del Museo Universitario Arte Contemporáneo. \n\n\nCanek T. Cancino Lopez\nEstudiante de Sociología en la UNAM. Ha sido ayudante de profesor en la materia de Estadística II y voluntario de los congresos ALAS 2022 y CLACSO 2022.\nAsistió al curso “Inferencia e introducción a los modelos estadísticos en R” impartido por la Dra. Ana Ruth Escoto Castillo y al curso “Orientalismo: la representación de las culturas asiáticas en Europa y Latinoamérica” coordinado por el Dr. Oscar Figueroa.\nSus temas de interés son la sociodemografía, el trabajo, la teología y el orientalismo (en especial la indología)."
  },
  {
    "objectID": "t4_enoe223.html",
    "href": "t4_enoe223.html",
    "title": "T4: ENOE t223",
    "section": "",
    "text": "Aquí dejo la presentación"
  },
  {
    "objectID": "t4_enoe223.html#descarga-el-proyecto-desde-acá",
    "href": "t4_enoe223.html#descarga-el-proyecto-desde-acá",
    "title": "T4: ENOE t223",
    "section": "Descarga el proyecto desde acá",
    "text": "Descarga el proyecto desde acá\nEn esta liga puedes descarga el proyecto de trabajo. De esta manera no tendremos problemas con las rutas relativas.\nhttps://tinyurl.com/demos-talleres"
  },
  {
    "objectID": "t4_enoe223.html#paquetes",
    "href": "t4_enoe223.html#paquetes",
    "title": "T4: ENOE t223",
    "section": "Paquetes",
    "text": "Paquetes\n\nif (!require(\"pacman\")) install.packages(\"pacman\") # instala pacman si se requiere\n\nLoading required package: pacman\n\npacman::p_load(tidyverse,\n               haven,\n               sjlabelled,\n               pollster,\n               janitor) #carga los paquetes necesarios"
  },
  {
    "objectID": "t4_enoe223.html#un-mini-repaso",
    "href": "t4_enoe223.html#un-mini-repaso",
    "title": "T4: ENOE t223",
    "section": "Un mini repaso",
    "text": "Un mini repaso\n\na <- 2\n\nb <- c(\"a\", \"b\")\n\nc <- c(NA, T, F,2)\n\nNA==F\n\n[1] NA\n\nsum(NA, T, F, 2)\n\n[1] NA\n\nsum(c)\n\n[1] NA\n\nsum(c, na.rm=T)\n\n[1] 3\n\n\n\nDatos primera parte\nVamos a fusionar la ENOE, se ha descargado desde INEGI su versión .dta\n\nvivt223 <- haven::read_dta(\"data_t4/2023trim2_dta/VIVT223.dta\") \nhogt223 <- haven::read_dta(\"data_t4/2023trim2_dta/HOGT223.dta\")\nsdemt223 <- haven::read_dta(\"data_t4/2023trim2_dta/SDEMT223.dta\")\ncoe1t223 <- haven::read_dta(\"data_t4/2023trim2_dta/COE1T223.dta\")\ncoe2t223 <- haven::read_dta(\"data_t4/2023trim2_dta/COE2T223.dta\")\n\n\n\nFusionado uno a uno de los COE\nEstas dos tablas sólo son para mayores de 12 años\n\ncoet223 <- coe1t223 %>% \n  dplyr::inner_join(coe2t223)\n\nJoining with `by = join_by(cd_a, ent, con, upm, d_sem, n_pro_viv, v_sel, n_hog,\nh_mud, n_ent, per, n_ren, eda, n_inf, ur, tipo, mes_cal, fac_tri, fac_men)`\n\n\nHay tres opciones más de join\n\nhelp(\"mutate-joins\")\n\n\n\nFusionado de las otras tablas\n\nidviv <- c(\"tipo\", \"mes_cal\", \"cd_a\", \"ent\", \"con\", \"v_sel\")\nidhog <- c(idviv, \"n_hog\", \"h_mud\")\nidsdem <- c(idhog, \"n_ren\" )\n\nNo queremos viviendas vacías\n\nenoe0<-vivt223 %>% \n  dplyr::inner_join(hogt223, by=idviv)\n\ndim(enoe0)\n\n[1] 151329     56\n\n\nRevisemos esta base\n\nnames(enoe0)\n\n [1] \"loc.x\"       \"mun.x\"       \"est.x\"       \"est_d_tri.x\" \"est_d_men.x\"\n [6] \"ageb.x\"      \"t_loc_tri.x\" \"t_loc_men.x\" \"cd_a\"        \"ent\"        \n[11] \"con\"         \"upm.x\"       \"d_sem.x\"     \"n_pro_viv.x\" \"v_sel\"      \n[16] \"n_ent.x\"     \"per.x\"       \"p1\"          \"p2\"          \"p3\"         \n[21] \"ur.x\"        \"tipo\"        \"mes_cal\"     \"fac_tri.x\"   \"fac_men.x\"  \n[26] \"loc.y\"       \"mun.y\"       \"est.y\"       \"est_d_tri.y\" \"est_d_men.y\"\n[31] \"ageb.y\"      \"t_loc_tri.y\" \"t_loc_men.y\" \"upm.y\"       \"d_sem.y\"    \n[36] \"n_pro_viv.y\" \"n_hog\"       \"h_mud\"       \"n_ent.y\"     \"per.y\"      \n[41] \"r_pre\"       \"p_dia\"       \"p_mes\"       \"p_anio\"      \"r_def\"      \n[46] \"d_dia\"       \"d_mes\"       \"d_anio\"      \"e_obs\"       \"p4_1\"       \n[51] \"p4_2\"        \"inf\"         \"ur.y\"        \"tipolev\"     \"fac_tri.y\"  \n[56] \"fac_men.y\"  \n\n\n\nenoe0 %>% \n  count(fac_tri.x==fac_tri.y)\n\n# A tibble: 2 × 2\n  `fac_tri.x == fac_tri.y`      n\n  <lgl>                     <int>\n1 FALSE                       135\n2 TRUE                     151194\n\n\n¿Por qué pasa esto?\nNo hay hogares en esas viviendas, hay valores en la base x, pero no en la base y\n\nenoe0 %>% \n  dplyr::filter(!fac_tri.x==fac_tri.y) %>% \n  janitor::tabyl(fac_tri.x, fac_tri.y)\n\n fac_tri.x 0\n        12 1\n        20 2\n        21 1\n        22 2\n        24 1\n        28 1\n        32 1\n        33 1\n        34 1\n        36 1\n        39 3\n        43 1\n        44 1\n        47 1\n        48 1\n        49 1\n        52 3\n        64 1\n        65 1\n        66 2\n        68 2\n        69 2\n        70 2\n        71 1\n        74 1\n        76 1\n        78 1\n        79 1\n        83 1\n        85 2\n        88 2\n        90 1\n        93 2\n        98 1\n       100 1\n       101 2\n       103 1\n       107 1\n       111 1\n       118 1\n       123 1\n       126 2\n       130 1\n       134 4\n       136 2\n       142 2\n       143 1\n       147 2\n       149 1\n       151 1\n       152 1\n       161 1\n       162 1\n       163 1\n       166 2\n       167 1\n       168 1\n       172 1\n       189 1\n       191 1\n       194 1\n       198 1\n       199 3\n       201 1\n       202 1\n       203 1\n       217 2\n       221 1\n       227 1\n       232 1\n       243 2\n       255 1\n       261 1\n       264 1\n       267 2\n       282 2\n       301 2\n       328 1\n       344 1\n       361 1\n       381 1\n       398 1\n       404 1\n       416 1\n       428 1\n       485 1\n       492 4\n       495 3\n       529 2\n       549 1\n       643 1\n       709 1\n       785 1\n       827 1\n       872 1\n      1136 1\n      1237 1\n      1302 2\n      4275 1\n\n\nObviamente, vamos quedarnos con la información.\n\nenoe0<-enoe0 %>% \n  dplyr::select(-ends_with(\".y\")) %>% # quita las variables que terminan con .y\n  dplyr::rename_at(vars(ends_with(\".x\")), ~ stringr::str_remove(.x, \".x\")) # renombra todas las variables que terminan en .x quitándoles el sufijo\n\nHoy pegaremos de manera similar a los individuos, pero primero nos vamos a quedar con quiénes tienen resultados definitivos de entrevistas completas\n\nenoe0 %>% \n  count(as_label(r_def))\n\n# A tibble: 14 × 2\n   `as_label(r_def)`                                             n\n   <fct>                                                     <int>\n 1 Entrevista completa                                      125951\n 2 Nadie en el momento de la entrevista                       4876\n 3 Ausente temporal                                           1659\n 4 Se negó a dar información                                  5441\n 5 Informante inadecuado                                       201\n 6 Otro motivo                                                2496\n 7 Adecuada para habitarse                                    5751\n 8 De uso temporal                                            3489\n 9 Inadecuada para habitarse                                   322\n10 De uso temporal para fines diferentes de habitación         481\n11 Demolida                                                     80\n12 Uso permanente para fines diferentes a los de habitación    262\n13 El hogar se mudó                                             79\n14 Entrevista suspendida                                       241\n\nsdemt223 %>% \n  count(as_label(c_res))\n\n# A tibble: 3 × 2\n  `as_label(c_res)`       n\n  <fct>               <int>\n1 Residente habitual 418269\n2 Ausente definitivo   7406\n3 Nuevo residente      5474\n\nenoe0 <- enoe0 %>% \n  filter(r_def==0) #entrevista completa\n\nsdemt223 <- sdemt223 %>% \n  filter(r_def==0) %>% \n  filter(!c_res==2) # residente que no es ausente\n\n\nenoe1<-enoe0 %>% \n  dplyr::left_join(sdemt223, by=idhog) %>% \n  dplyr::select(-ends_with(\".y\")) %>% # quita las variables que terminan con .y\n  dplyr::rename_at(vars(ends_with(\".x\")), ~ stringr::str_remove(.x, \".x\")) \n\nWarning: `cd_a` and `cd_a` have conflicting value labels.\nℹ Labels for these values will be taken from `cd_a`.\n✖ Values: 1\n\ndim(enoe1)\n\n[1] 422778    129\n\n\nYa tenemos lista una base de individuos que podemos pegar con nuestra base de coe. Pero revisemos que este cuestionario tiene preguntas simulares a la cuestionario de otras tablas\n\nintersect(names(enoe1), names(coet223))\n\n [1] \"cd_a\"      \"ent\"       \"con\"       \"upm\"       \"d_sem\"     \"n_pro_viv\"\n [7] \"v_sel\"     \"n_ent\"     \"per\"       \"p1\"        \"p3\"        \"ur\"       \n[13] \"tipo\"      \"mes_cal\"   \"fac_tri\"   \"fac_men\"   \"n_hog\"     \"h_mud\"    \n[19] \"r_def\"     \"p4_1\"      \"p4_2\"      \"n_ren\"     \"eda\"      \n\n\n\ncoet223<- coet223 %>% \n  dplyr::rename_at(vars(p1, p3, p4_1, p4_2), ~ paste0(.x, \"coe\") )%>% \n  dplyr::select(-ends_with(\".y\")) %>% # quita las variables que terminan con .y\n  dplyr::rename_at(vars(ends_with(\".x\")), ~ stringr::str_remove(.x, \".x\")) \n\nnames(coet223)\n\n  [1] \"r_def\"     \"cd_a\"      \"ent\"       \"con\"       \"upm\"       \"d_sem\"    \n  [7] \"n_pro_viv\" \"v_sel\"     \"n_hog\"     \"h_mud\"     \"n_ent\"     \"per\"      \n [13] \"n_ren\"     \"eda\"       \"n_inf\"     \"p1coe\"     \"p1a1\"      \"p1a2\"     \n [19] \"p1a3\"      \"p1b\"       \"p1c\"       \"p1d\"       \"p1e\"       \"p2_1\"     \n [25] \"p2_2\"      \"p2_3\"      \"p2_4\"      \"p2_9\"      \"p2a_dia\"   \"p2a_sem\"  \n [31] \"p2a_mes\"   \"p2a_anio\"  \"p2b_dia\"   \"p2b_sem\"   \"p2b_mes\"   \"p2b_anio\" \n [37] \"p2b\"       \"p2c\"       \"p2d1\"      \"p2d2\"      \"p2d3\"      \"p2d4\"     \n [43] \"p2d5\"      \"p2d6\"      \"p2d7\"      \"p2d8\"      \"p2d9\"      \"p2d10\"    \n [49] \"p2d11\"     \"p2d99\"     \"p2e\"       \"p2f\"       \"p2g1\"      \"p2g2\"     \n [55] \"p2h1\"      \"p2h2\"      \"p2h3\"      \"p2h4\"      \"p2h9\"      \"p2i\"      \n [61] \"p2j\"       \"p2k_anio\"  \"p2k_mes\"   \"p2k\"       \"p3coe\"     \"p3a\"      \n [67] \"p3b\"       \"p3c1\"      \"p3c2\"      \"p3c3\"      \"p3c4\"      \"p3c9\"     \n [73] \"p3d\"       \"p3e\"       \"p3f1\"      \"p3f2\"      \"p3g1_1\"    \"p3g1_2\"   \n [79] \"p3g2_1\"    \"p3g2_2\"    \"p3g3_1\"    \"p3g3_2\"    \"p3g4_1\"    \"p3g4_2\"   \n [85] \"p3g9\"      \"p3g_tot\"   \"p3h\"       \"p3i\"       \"p3j1\"      \"p3j2\"     \n [91] \"p3k1\"      \"p3k2\"      \"p3k3\"      \"p3k4\"      \"p3k5\"      \"p3k9\"     \n [97] \"p3l\"       \"p4\"        \"p4_1coe\"   \"p4_2coe\"   \"p4_3\"      \"p4a\"      \n[103] \"p4a_1\"     \"p4b\"       \"p4c\"       \"p4d1\"      \"p4d2\"      \"p4d3\"     \n[109] \"p4e\"       \"p4f\"       \"p4g\"       \"p4h\"       \"p4i\"       \"p4i_1\"    \n[115] \"p5\"        \"p5a\"       \"p5b_hlu\"   \"p5b_mlu\"   \"p5b_hma\"   \"p5b_mma\"  \n[121] \"p5b_hmi\"   \"p5b_mmi\"   \"p5b_hju\"   \"p5b_mju\"   \"p5b_hvi\"   \"p5b_mvi\"  \n[127] \"p5b_hsa\"   \"p5b_msa\"   \"p5b_hdo\"   \"p5b_mdo\"   \"p5b_thrs\"  \"p5b_tdia\" \n[133] \"p5c\"       \"p5d1\"      \"p5d_hlu\"   \"p5d_mlu\"   \"p5d_hma\"   \"p5d_mma\"  \n[139] \"p5d_hmi\"   \"p5d_mmi\"   \"p5d_hju\"   \"p5d_mju\"   \"p5d_hvi\"   \"p5d_mvi\"  \n[145] \"p5d_hsa\"   \"p5d_msa\"   \"p5d_hdo\"   \"p5d_mdo\"   \"p5d_thrs\"  \"p5d_tdia\" \n[151] \"p5e\"       \"p5f1\"      \"p5f2\"      \"p5f3\"      \"p5f4\"      \"p5f5\"     \n[157] \"p5f6\"      \"p5f7\"      \"p5f8\"      \"p5f9\"      \"p5f10\"     \"p5f11\"    \n[163] \"p5f12\"     \"p5f13\"     \"p5f14\"     \"p5f15\"     \"p5f99\"     \"ur\"       \n[169] \"tipo\"      \"mes_cal\"   \"fac_tri\"   \"fac_men\"   \"p6_1\"      \"p6_2\"     \n[175] \"p6_3\"      \"p6_4\"      \"p6_5\"      \"p6_6\"      \"p6_7\"      \"p6_8\"     \n[181] \"p6_9\"      \"p6_10\"     \"p6_99\"     \"p6a1\"      \"p6a2\"      \"p6a3\"     \n[187] \"p6a4\"      \"p6a9\"      \"p6b1\"      \"p6b2\"      \"p6c\"       \"p6d\"      \n[193] \"p6e\"       \"p6e_c\"     \"p6f\"       \"p6f_c\"     \"p6g\"       \"p6h\"      \n[199] \"p6h_c\"     \"p6i\"       \"p6i_c\"     \"p7\"        \"p7a\"       \"p7b\"      \n[205] \"p7c\"       \"p8_1\"      \"p8_2\"      \"p8_3\"      \"p8_4\"      \"p8_9\"     \n[211] \"p8a\"       \"p9_1\"      \"p9_h1\"     \"p9_m1\"     \"p9_2\"      \"p9_h2\"    \n[217] \"p9_m2\"     \"p9_3\"      \"p9_h3\"     \"p9_m3\"     \"p9_4\"      \"p9_h4\"    \n[223] \"p9_m4\"     \"p9_5\"      \"p9_h5\"     \"p9_m5\"     \"p9_6\"      \"p9_h6\"    \n[229] \"p9_m6\"     \"p9_7\"      \"p9_h7\"     \"p9_m7\"     \"p9_8\"      \"p9_h8\"    \n[235] \"p9_m8\"    \n\n\nBase final:\n\nenoet223 <- enoe1 %>% \n  left_join(coet223)\n\nJoining with `by = join_by(cd_a, ent, con, upm, d_sem, n_pro_viv, v_sel, n_ent,\nper, ur, tipo, mes_cal, fac_tri, fac_men, n_hog, h_mud, r_def, n_ren, eda)`\n\ndim(enoet223)\n\n[1] 422778    345\n\n\nVamos a quitar algunos objetos para mejorar nuestro uso de memoria\n\nrm(vivt223, hogt223, coe1t223, coe2t223, coet223, enoe0, enoe1)\ngc()\n\n            used   (Mb) gc trigger   (Mb) limit (Mb)  max used   (Mb)\nNcells   1149734   61.5    1992590  106.5         NA   1992590  106.5\nVcells 196118796 1496.3  527309211 4023.1      16384 447858498 3416.9"
  },
  {
    "objectID": "t4_enoe223.html#algunos-tabulados-de-la-enoe",
    "href": "t4_enoe223.html#algunos-tabulados-de-la-enoe",
    "title": "T4: ENOE t223",
    "section": "Algunos tabulados de la ENOE",
    "text": "Algunos tabulados de la ENOE\n\n## Sin expansión\nenoet223 %>%\n  filter(eda>14 & eda<99) %>% \n  mutate(clase1=as_label(clase1)) %>% \n  janitor::tabyl(clase1)\n\n                             clase1      n percent\n                          No aplica      0 0.00000\n    Población económicamente activa 201003 0.60978\n Población no económicamente activa 128629 0.39022\n\n## Con expansión\nenoet223 %>%\n  filter(eda>14 & eda<99) %>% # este el filtro que usa inegi para sus tabulados\n  mutate(clase1=as_label(clase1)) %>% \n  pollster::topline(clase1, weight = fac_tri)\n\n# A tibble: 2 × 5\n  Response                Frequency Percent `Valid Percent` `Cumulative Percent`\n  <fct>                       <dbl>   <dbl>           <dbl>                <dbl>\n1 Población económicamen…  60216432    60.2            60.2                 60.2\n2 Población no económica…  39834351    39.8            39.8                100  \n\n\nSiempre checa que tus tabulados sean como los de INEGI de tu variable a estudiar\n\nDe doble entrada\n\n## Sin expansión\nenoet223 %>%\n  filter(eda>14 & eda<99) %>% \n  mutate(clase1=as_label(clase1)) %>% \n  mutate(clase2=as_label(clase2)) %>% \n  janitor::tabyl(clase1, clase2)\n\n                             clase1 No aplica Población ocupada\n                          No aplica         0                 0\n    Población económicamente activa         0            195374\n Población no económicamente activa         0                 0\n Población desocupada Disponibles No disponibles\n                    0           0              0\n                 5629           0              0\n                    0       16467         112162\n\n## Con expansión\nenoet223 %>%\n  filter(eda>14 & eda<99) %>% # este el filtro que usa inegi para sus tabulados\n  mutate(clase1=as_label(clase1)) %>% \n  mutate(clase2=as_label(clase2)) %>% \n  pollster::crosstab(clase1, clase2, weight = fac_tri)\n\n# A tibble: 2 × 6\n  clase1 `Población ocupada` `Población desocupada` Disponibles `No disponibles`\n  <fct>                <dbl>                  <dbl>       <dbl>            <dbl>\n1 Pobla…                97.2                   2.81         0                0  \n2 Pobla…                 0                     0           13.0             87.0\n# ℹ 1 more variable: n <dbl>\n\n\n\nIngresos\nPara los ingresos, INEGI publica los válidos, es decir los mayores a cero.\n\nenoet223 %>% \n  filter(eda>14 & eda<99) %>% \n  filter(ing_x_hrs>0) %>% # ojo\n  summarise(promedio=weighted.mean(ing_x_hrs, w = fac_tri))\n\n# A tibble: 1 × 1\n  promedio\n     <dbl>\n1     54.4"
  },
  {
    "objectID": "t4_enoe223.html#segunda-parte-panel-rotativo",
    "href": "t4_enoe223.html#segunda-parte-panel-rotativo",
    "title": "T4: ENOE t223",
    "section": "Segunda parte: panel rotativo",
    "text": "Segunda parte: panel rotativo\nEl panel rotativo. Para hacer un ejemplo vamos a pegar únicamente el cuestionario sociodemográfico. Y sólo podemos pegar las entrevistas cara a cara\n\nDatos segunta parte\nVamos a trabajar con el panel que inicia el t222 y termina en t2 de 2023. Para que no sea tan pesado el ambiente aprovechamos y hacermos más filtros incluyendo el número de entrevista correspondiente.\n\nsdemt222 <- read_dta(\"data_t4/anterior/SDEMT222.dta\") %>% \n  filter(tipo==1) %>% # sólo cara cara\n  filter(r_def==0) %>% # sólo completa\n  filter(!c_res==2) %>%  #no ausentes definitivos\n  filter(n_ent==1) %>% \n  mutate(trim=\"t222\") %>% \n  mutate_at(vars(cs_p20a_1, cs_p20a_c, \n                 cs_p20b_1, cs_p20b_c,\n                 cs_p20c_1), ~ as.numeric(.x))\n\nsdemt322 <- read_dta(\"data_t4/anterior/SDEMT322.dta\") %>% \n  filter(tipo==1) %>% # sólo cara cara\n  filter(r_def==0) %>% # sólo completa\n  filter(!c_res==2) %>%  #no ausentes definitivos\n  filter(n_ent==2) %>% \n  mutate(trim=\"t322\") \n\n\nsdemt422 <- read_dta(\"data_t4/anterior/SDEMT422.dta\") %>% \n  filter(tipo==1) %>% # sólo cara cara\n  filter(r_def==0) %>% # sólo completa\n  filter(!c_res==2) %>% #no ausentes definitivos\n  filter(n_ent==3)  %>% \n  mutate(trim=\"t422\") \n\n\nsdemt123 <- read_dta(\"data_t4/anterior/SDEMT123.dta\")%>% \n  filter(tipo==1) %>% # sólo cara cara\n  filter(r_def==0) %>% # sólo completa\n  filter(!c_res==2) %>%  #no ausentes definitivos\n  filter(n_ent==4) %>% \n  mutate(trim=\"t123\") \n\nsdemt223<-sdemt223 %>% \n  filter(tipo==1) %>% \n  filter(n_ent==5) %>% \n  mutate(trim=\"t223\") \n\nVamos a hacer el panel hoy\n\npanel<- dplyr::bind_rows(sdemt222, # había un conflicto en cs_p20*\n                         sdemt322, \n                         sdemt422, \n                         sdemt123,\n                         sdemt223)\n\nWarning: `..1$tcco` and `..2$tcco` have conflicting value labels.\nℹ Labels for these values will be taken from `..1$tcco`.\n✖ Values: 2\n\n\nWarning: `..1$tcco` and `..3$tcco` have conflicting value labels.\nℹ Labels for these values will be taken from `..1$tcco`.\n✖ Values: 2\n\n\nWarning: `..1$cd_a` and `..4$cd_a` have conflicting value labels.\nℹ Labels for these values will be taken from `..1$cd_a`.\n✖ Values: 81, 82, 83, 84, 85, and 86\n\n\nWarning: `..1$tcco` and `..4$tcco` have conflicting value labels.\nℹ Labels for these values will be taken from `..1$tcco`.\n✖ Values: 2\n\n\nWarning: `..1$tcco` and `..5$tcco` have conflicting value labels.\nℹ Labels for these values will be taken from `..1$tcco`.\n✖ Values: 2\n\n\nLos warnigns son solo de las etiquetas que son diferentes\n\npanel %>% \n  mutate(n_ent=as_label(n_ent)) %>% \n  tabyl(n_ent)\n\n              n_ent     n   percent\n Primera entrevista 80588 0.2039748\n Segunda entrevista 79861 0.2021347\n Tercera entrevista 79046 0.2000719\n  Cuarta entrevista 77951 0.1973003\n  Quinta entrevista 77642 0.1965182\n\n\nVamos a revisar los id\n\npanel %>% \n  janitor::get_dupes(cd_a, ent, con, v_sel, n_hog, h_mud, n_ren, n_ent)\n\nNo duplicate combinations found of: cd_a, ent, con, v_sel, n_hog, h_mud, n_ren, n_ent\n\n\n# A tibble: 0 × 116\n# ℹ 116 variables: cd_a <dbl+lbl>, ent <dbl+lbl>, con <dbl>, v_sel <dbl+lbl>,\n#   n_hog <dbl+lbl>, h_mud <dbl+lbl>, n_ren <dbl+lbl>, n_ent <dbl+lbl>,\n#   dupe_count <int>, r_def <dbl+lbl>, loc <dbl>, mun <dbl>, est <dbl>,\n#   est_d_tri <dbl>, est_d_men <dbl>, ageb <dbl>, t_loc_tri <dbl+lbl>,\n#   t_loc_men <dbl+lbl>, upm <dbl>, d_sem <dbl+lbl>, n_pro_viv <dbl>,\n#   per <dbl+lbl>, c_res <dbl+lbl>, par_c <dbl>, sex <dbl+lbl>, eda <dbl>,\n#   nac_dia <dbl+lbl>, nac_mes <dbl+lbl>, nac_anio <dbl>, l_nac_c <dbl+lbl>, …\n\npanel %>% \n  janitor::get_dupes(cd_a, ent, con, v_sel, n_hog, h_mud, n_ren) %>% \n  tabyl(dupe_count)\n\n dupe_count      n    percent\n          2  15820 0.04118279\n          3  21696 0.05647926\n          4  37980 0.09886995\n          5 308645 0.80346800\n\n\nVamos a verificar con la edad si se trata de los mismos individuos\n\npanel<-panel %>% \n  mutate(edad_min=min(eda), \n            edad_max=max(eda),\n            .by = c(cd_a, ent, con, v_sel, n_hog, h_mud, n_ren)) %>% \n  mutate(diff_eda=edad_max-edad_min)\n\npanel %>% \n  tabyl(diff_eda)\n\n diff_eda      n    percent\n        0  39524 0.10003847\n        1 349991 0.88585581\n        2   5573 0.01410572\n\n\nVamos a hacer una variable que nos diga cuántas entrevista tiene cada individuo:\n\npanel<-panel %>% \n  mutate(total_n=sum(tipo),\n         .by = c(cd_a, ent, con, v_sel, n_hog, h_mud, n_ren)) \n\npanel<-panel %>% \n  filter(total_n==5)\n\n\n\nDe long a wide\nNo vamos a trabajar con toda la base, sino con la variable clase 2\n\npanel_corto<-panel %>% \n  select(cd_a, ent, con, v_sel, n_hog, h_mud, n_ren, n_ent, clase2) %>% \n  tidyr::pivot_wider(values_from = clase2,\n                     names_from = n_ent, \n                     names_prefix = \"clase2_\")\n\n\npanel_corto %>% \n  filter(clase2_1>0) %>% \n  mutate_at(vars(starts_with(\"clase2\")), ~ as_label(.x)) %>% \n  tabyl(clase2_1, clase2_2, show_missing_levels = F)\n\n             clase2_1 Población ocupada Población desocupada Disponibles\n    Población ocupada             24497                  429         609\n Población desocupada               455                  155          70\n          Disponibles               880                  103         528\n       No disponibles              2167                  183        1655\n No disponibles\n           2699\n            206\n           1903\n          14471\n\n\nPara incluir más variables, debemos de considerar cuáles cambian en el tiempo:\n\npanel_corto<-panel %>% \n  select(cd_a, ent, con, v_sel, n_hog, h_mud, n_ren, n_ent, eda, clase2) %>% \n  mutate(clase2=as_label(clase2)) %>% \n  tidyr::pivot_wider(values_from = c(clase2, eda),\n                     names_from = n_ent, \n                     names_glue = \"{.value}_{n_ent}\") # esto hace que la variables de -value vayan primero\n\n\nnames(panel_corto)\n\n [1] \"cd_a\"     \"ent\"      \"con\"      \"v_sel\"    \"n_hog\"    \"h_mud\"   \n [7] \"n_ren\"    \"clase2_1\" \"clase2_2\" \"clase2_3\" \"clase2_4\" \"clase2_5\"\n[13] \"eda_1\"    \"eda_2\"    \"eda_3\"    \"eda_4\"    \"eda_5\""
  },
  {
    "objectID": "t4_enoe223.html#algunas-cosas-para-pensar",
    "href": "t4_enoe223.html#algunas-cosas-para-pensar",
    "title": "T4: ENOE t223",
    "section": "Algunas cosas para pensar",
    "text": "Algunas cosas para pensar\n\n¿Qué pasa con los factores de expansión?\n¿Cómo calcularías cuál es porcentaje de atrición?\n¿Qué pasa con el COE que cambia en t1?"
  },
  {
    "objectID": "t5_texto.html",
    "href": "t5_texto.html",
    "title": "T5: Análisis de texto (I)",
    "section": "",
    "text": "https://tinyurl.com/demos-talleres\nEn esta primera práctica veremos algunas acciones para importación de texto para su análisis, así como el manejo de diferentes fuentes, así como importación de tablas desde pdf."
  },
  {
    "objectID": "t5_texto.html#paquetes",
    "href": "t5_texto.html#paquetes",
    "title": "T5: Análisis de texto (I)",
    "section": "Paquetes",
    "text": "Paquetes\n\nif (!require(\"pacman\")) install.packages(\"pacman\") # instala pacman si se requiere\n\nLoading required package: pacman\n\npacman::p_load(tidyverse, magrittr, tidytext,\n               tm, \n               NLP, SnowballC, \n               wordcloud, ggwordcloud,\n               quanteda, udpipe,\n               igraph, ggraph, # para unos gráficos\n               readxl, janitor, textrank,\n               broom, epubr, pdftools, tesseract, tokenizers)"
  },
  {
    "objectID": "t5_texto.html#importar-desde-un-archivo-.txt",
    "href": "t5_texto.html#importar-desde-un-archivo-.txt",
    "title": "T5: Análisis de texto (I)",
    "section": "Importar desde un archivo .txt",
    "text": "Importar desde un archivo .txt\nVamos a importar el discurso que el presidente dio el 1 de julio de 2022: https://lopezobrador.org.mx/2022/07/01/discurso-del-presidente-andres-manuel-lopez-obrador-en-4-ano-del-triunfo-democratico-historico/\n\namlo <- readLines(\"text/20220107_amlo.txt\")\n\nRevisemos un poco este objeto\n\nsummary(amlo)\n\n   Length     Class      Mode \n      113 character character \n\n\nTenemos 113 párrafos. Al momento no tenemos más información que lo revisaremos en siguientes secciones"
  },
  {
    "objectID": "t5_texto.html#importar-un-epub",
    "href": "t5_texto.html#importar-un-epub",
    "title": "T5: Análisis de texto (I)",
    "section": "Importar un epub",
    "text": "Importar un epub\nEl proyecto Gutenberg tiene una selección de libros publicados sin problemas de derechos de Autor. Trabajaremos con los Cuentos de Amor de Locura y de Muerte de Horacio Quiroga\n\nepubr::epub_head(\"text/quiroga.epub\") # muestra lo primero \n\n# A tibble: 9 × 2\n  section           text                                                  \n  <chr>             <chr>                                                 \n1 pg-header         \"The Project Gutenberg eBook of Cuentos de Amor de \"  \n2 id00249           \"#LOS OJOS SOMBRIOS#\\n\\nDespués de las primeras seman\"\n3 id00535           \"#EL INFIERNO ARTIFICIAL#\\n\\nLas noches en que hay lu\"\n4 id00745           \"#EL PERRO RABIOSO#\\n\\nEl 20 de marzo de este año, lo\"\n5 id01047           \"#LOS MENSÚ#\\n\\nCayetano Maidana y Esteban Podeley, p\"\n6 id01212           \"#LOS PESCADORES DE VIGAS#\\n\\nEl motivo fué cierto ju\"\n7 id01445           \"#LA MENINGITIS Y SU SOMBRA#\\n\\nNo vuelvo de mi sorpr\"\n8 pg-footer         \"*** END OF THIS PROJECT GUTENBERG EBOOK ***\\n      \" \n9 coverpage-wrapper \"\"                                                    \n\n\nEs una selección de cuentos. Revisemos un poco la meta-data:\n\nepubr::epub_meta(\"text/quiroga.epub\") # muestra el meta-data del libro\n\n# A tibble: 1 × 8\n  rights                  identifier creator title language subject date  source\n  <chr>                   <chr>      <chr>   <chr> <chr>    <chr>   <chr> <chr> \n1 Public domain in the U… http://ww… Horaci… Cuen… es       Short … 2004… https…\n\n\nHoy sí lo vamos a importar en nuestro ambiente:\n\nx <- epubr::epub(\"text/quiroga.epub\") # Importa todo el libro en el objeto x, pero no queremos todo\nx\n\n# A tibble: 1 × 9\n  rights         identifier creator title language subject date  source data    \n  <chr>          <chr>      <chr>   <chr> <chr>    <chr>   <chr> <chr>  <list>  \n1 Public domain… http://ww… Horaci… Cuen… es       Short … 2004… https… <tibble>\n\n\n¿Dónde están los cuentos?\n\nglimpse(x)\n\nRows: 1\nColumns: 9\n$ rights     <chr> \"Public domain in the USA.\"\n$ identifier <chr> \"http://www.gutenberg.org/13507\"\n$ creator    <chr> \"Horacio Quiroga\"\n$ title      <chr> \"Cuentos de Amor de Locura y de Muerte\"\n$ language   <chr> \"es\"\n$ subject    <chr> \"Short stories, Uruguayan|Uruguayan fiction\"\n$ date       <chr> \"2004-09-20|2022-10-06T21:09:10.400769+00:00\"\n$ source     <chr> \"https://www.gutenberg.org/files/13507/13507-8.txt\"\n$ data       <list> [<tbl_df[9 x 4]>]\n\n\nVemos que en realidad la última variable es una lista que adentro trae un objeto “tbl_df” de 9 x 4. Revisemos qué hay\n\nclass(x$data)\n\n[1] \"list\"\n\nx$data\n\n[[1]]\n# A tibble: 9 × 4\n  section           text                                             nword nchar\n  <chr>             <chr>                                            <int> <int>\n1 pg-header         \"The Project Gutenberg eBook of Cuentos de Amor…  6435 37893\n2 id00249           \"#LOS OJOS SOMBRIOS#\\n\\nDespués de las primeras…  5831 34153\n3 id00535           \"#EL INFIERNO ARTIFICIAL#\\n\\nLas noches en que …  7190 42642\n4 id00745           \"#EL PERRO RABIOSO#\\n\\nEl 20 de marzo de este a…  9356 55680\n5 id01047           \"#LOS MENSÚ#\\n\\nCayetano Maidana y Esteban Pode…  6816 40770\n6 id01212           \"#LOS PESCADORES DE VIGAS#\\n\\nEl motivo fué cie…  6325 38243\n7 id01445           \"#LA MENINGITIS Y SU SOMBRA#\\n\\nNo vuelvo de mi…  7364 43275\n8 pg-footer         \"*** END OF THIS PROJECT GUTENBERG EBOOK ***\\n …  2894 18593\n9 coverpage-wrapper \"\"                                                   0     0\n\n\nComo es una lista, pero una lista de un solo elemento [[1]], vamos a consultarlo:\n\nx$data[[1]]\n\n# A tibble: 9 × 4\n  section           text                                             nword nchar\n  <chr>             <chr>                                            <int> <int>\n1 pg-header         \"The Project Gutenberg eBook of Cuentos de Amor…  6435 37893\n2 id00249           \"#LOS OJOS SOMBRIOS#\\n\\nDespués de las primeras…  5831 34153\n3 id00535           \"#EL INFIERNO ARTIFICIAL#\\n\\nLas noches en que …  7190 42642\n4 id00745           \"#EL PERRO RABIOSO#\\n\\nEl 20 de marzo de este a…  9356 55680\n5 id01047           \"#LOS MENSÚ#\\n\\nCayetano Maidana y Esteban Pode…  6816 40770\n6 id01212           \"#LOS PESCADORES DE VIGAS#\\n\\nEl motivo fué cie…  6325 38243\n7 id01445           \"#LA MENINGITIS Y SU SOMBRA#\\n\\nNo vuelvo de mi…  7364 43275\n8 pg-footer         \"*** END OF THIS PROJECT GUTENBERG EBOOK ***\\n …  2894 18593\n9 coverpage-wrapper \"\"                                                   0     0\n\n\nEsta es nuestra matriz de datos. Aquí podemos elegir una sección. Por ejemplo un cuento\n\nepub<-x$data[[1]]\nclass(epub)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nVamos a quedarnos con un solo cuento:\n\nojos_sombrios <- epub %>% \n  filter(section ==\"id00249\") %>%  # nos quedamos con el primer cuento\n  select(text)\n\nojos_sombrios\n\n# A tibble: 1 × 1\n  text                                                                          \n  <chr>                                                                         \n1 \"#LOS OJOS SOMBRIOS#\\n\\nDespués de las primeras semanas de romper con Elena, …\n\nclass(ojos_sombrios)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nSigue teniendo formato de data.frame. Para poder usar algunos elementos necesitamos convertirlo a texto. Por eso lo vamos a “pegar”\n\nojos_sombrios<-paste(ojos_sombrios$text) # lo volvemos caracter\nclass(ojos_sombrios)\n\n[1] \"character\"\n\n\nCon esto ya podremos hacer muchas operaciones de aquí en adelante."
  },
  {
    "objectID": "t5_texto.html#importar-un-pdf-conpdftools",
    "href": "t5_texto.html#importar-un-pdf-conpdftools",
    "title": "T5: Análisis de texto (I)",
    "section": "Importar un pdf con{pdftools}",
    "text": "Importar un pdf con{pdftools}\n\ndof4nov <- pdftools::pdf_text(\"text/04112022-MAT.pdf\")\ndof4nov[6] \n\n[1] \"   6                                            DIARIO OFICIAL                 Viernes 4 de noviembre de 2022\\n\\n   Con oficio número SEGOB/CNBP/2354/2022, de fecha 12 de agosto de 2022, “LA CNBP” autorizó la\\nprocedencia de la solicitud de acceso al recurso concursable, lo anterior, con fundamento en los artículos 21,\\n22, 23 y 24 de los “Lineamientos”, y en términos de la Cláusula Vigésima del Convenio de Coordinación\\ny Adhesión.\\n   Por lo que, resulta necesario utilizar la totalidad de los recursos destinados para el otorgamiento de\\nsubsidios a las entidades federativas para realizar acciones de búsqueda en materia de desaparición forzada\\nde personas y desaparición cometida por particulares.\\n                                              DECLARACIONES\\n   I.     “LA CNBP” declara que:\\n   I.1.   En virtud de que el presente Convenio Modificatorio se deriva del Convenio de Coordinación y\\n          Adhesión, las Declaraciones manifestadas en dicho instrumento permanecen vigentes, con\\n          excepción de las expresadas en el presente Convenio Modificatorio, por lo que se tienen por\\n          reproducidas y ratificadas en su integridad como si a la letra se insertaran en el Convenio de\\n          Coordinación y Adhesión de referencia.\\n   I.2.   Las documentales, justificativas y comprobatorias que acreditan y sustentan la procedencia de este\\n          instrumento, obran en el expediente de “LA CNBP”; lo anterior, para todos los fines y efectos\\n          legales a que haya lugar, por lo que corresponde a dicha área cualquier justificación y sustento sobre\\n          el particular.\\n   II.    La “ENTIDAD FEDERATIVA” declara que:\\n   II.1. Es su intención celebrar el presente Convenio Modificatorio al Convenio de Coordinación y Adhesión,\\n         en términos del presente instrumento jurídico.\\n   II.2. En virtud de que el presente Convenio Modificatorio se deriva del Convenio de Coordinación y\\n         Adhesión, las declaraciones manifestadas en dicho instrumento permanecen vigentes con excepción\\n         de las expresadas en el presente Convenio Modificatorio por lo que se tienen por reproducidas\\n         y ratificadas en su integridad como si a la letra se insertaran en el Convenio de Coordinación y\\n         Adhesión de referencia, actualizándose las identificadas con los numerales II.4 y II.5, toda vez que\\n         hubo sustitución de funcionarios, para quedar como sigue.\\n             II.4. Samuel Sotelo Salgado, Secretario de Gobierno del Poder Ejecutivo Estatal, acredita\\n                   su personalidad con el nombramiento otorgado a su favor por el Gobernador\\n                   Constitucional del Estado con fecha 03 de mayo de 2022, y tiene facultades para\\n                   suscribir el presente Convenio, de conformidad con los artículos 74 de la Constitución\\n                   Política del Estado Libre y Soberano de Morelos; 3, párrafo tercero, 4, fracción I, 9,\\n                   fracción II, 13, fracción VI, 14 y 22, fracción VII, de la Ley Orgánica de la\\n                   Administración Pública del Estado Libre y Soberano de Morelos, y 8 y 9, fracción VII,\\n                   del Reglamento Interior de la Secretaría de Gobierno.\\n             II.5. José Gerardo López Huérfano, Encargado de Despacho de la Secretaría de Hacienda\\n                   del Estado, acredita su personalidad con el nombramiento otorgado a su favor por el\\n                   Gobernador del Estado con fecha 03 de mayo de 2022, y tiene facultades para\\n                   suscribir el presente Convenio, de conformidad con los artículos 74 de la Constitución\\n                   Política del Estado Libre y Soberano de Morelos; 3, 4, fracción I, 9, fracción III, 13,\\n                   fracción VI, 14, 15 y 23, fracción IV, de la Ley Orgánica de la Administración Pública\\n                   del Estado Libre y Soberano de Morelos, y 11, 12, fracción XII y 41 del Reglamento\\n                   Interior de la Secretaría de Hacienda.\\n   III.   “LAS PARTES” declaran que:\\n   III.1. Cuentan con las facultades necesarias para intervenir en la suscripción del presente Convenio\\n          Modificatorio.\\n   III.2. Se reconocen mutuamente la personalidad con que se ostentan y manifiestan su conformidad para la\\n          celebración del presente Convenio Modificatorio.\\n   III.3. Celebran el presente instrumento, de conformidad con lo establecido en los artículos 21, 22, 23,\\n          24 y 25 de los “Lineamientos” y en términos de la Cláusula Vigésima del Convenio de Coordinación\\n          y Adhesión.\\n\"\n\nclass(dof4nov)\n\n[1] \"character\"\n\n\nPara verlo mejor podemos usar el comando cat() de base para cada una de las “hojas”\n\ncat(dof4nov[6])\n\n   6                                            DIARIO OFICIAL                 Viernes 4 de noviembre de 2022\n\n   Con oficio número SEGOB/CNBP/2354/2022, de fecha 12 de agosto de 2022, “LA CNBP” autorizó la\nprocedencia de la solicitud de acceso al recurso concursable, lo anterior, con fundamento en los artículos 21,\n22, 23 y 24 de los “Lineamientos”, y en términos de la Cláusula Vigésima del Convenio de Coordinación\ny Adhesión.\n   Por lo que, resulta necesario utilizar la totalidad de los recursos destinados para el otorgamiento de\nsubsidios a las entidades federativas para realizar acciones de búsqueda en materia de desaparición forzada\nde personas y desaparición cometida por particulares.\n                                              DECLARACIONES\n   I.     “LA CNBP” declara que:\n   I.1.   En virtud de que el presente Convenio Modificatorio se deriva del Convenio de Coordinación y\n          Adhesión, las Declaraciones manifestadas en dicho instrumento permanecen vigentes, con\n          excepción de las expresadas en el presente Convenio Modificatorio, por lo que se tienen por\n          reproducidas y ratificadas en su integridad como si a la letra se insertaran en el Convenio de\n          Coordinación y Adhesión de referencia.\n   I.2.   Las documentales, justificativas y comprobatorias que acreditan y sustentan la procedencia de este\n          instrumento, obran en el expediente de “LA CNBP”; lo anterior, para todos los fines y efectos\n          legales a que haya lugar, por lo que corresponde a dicha área cualquier justificación y sustento sobre\n          el particular.\n   II.    La “ENTIDAD FEDERATIVA” declara que:\n   II.1. Es su intención celebrar el presente Convenio Modificatorio al Convenio de Coordinación y Adhesión,\n         en términos del presente instrumento jurídico.\n   II.2. En virtud de que el presente Convenio Modificatorio se deriva del Convenio de Coordinación y\n         Adhesión, las declaraciones manifestadas en dicho instrumento permanecen vigentes con excepción\n         de las expresadas en el presente Convenio Modificatorio por lo que se tienen por reproducidas\n         y ratificadas en su integridad como si a la letra se insertaran en el Convenio de Coordinación y\n         Adhesión de referencia, actualizándose las identificadas con los numerales II.4 y II.5, toda vez que\n         hubo sustitución de funcionarios, para quedar como sigue.\n             II.4. Samuel Sotelo Salgado, Secretario de Gobierno del Poder Ejecutivo Estatal, acredita\n                   su personalidad con el nombramiento otorgado a su favor por el Gobernador\n                   Constitucional del Estado con fecha 03 de mayo de 2022, y tiene facultades para\n                   suscribir el presente Convenio, de conformidad con los artículos 74 de la Constitución\n                   Política del Estado Libre y Soberano de Morelos; 3, párrafo tercero, 4, fracción I, 9,\n                   fracción II, 13, fracción VI, 14 y 22, fracción VII, de la Ley Orgánica de la\n                   Administración Pública del Estado Libre y Soberano de Morelos, y 8 y 9, fracción VII,\n                   del Reglamento Interior de la Secretaría de Gobierno.\n             II.5. José Gerardo López Huérfano, Encargado de Despacho de la Secretaría de Hacienda\n                   del Estado, acredita su personalidad con el nombramiento otorgado a su favor por el\n                   Gobernador del Estado con fecha 03 de mayo de 2022, y tiene facultades para\n                   suscribir el presente Convenio, de conformidad con los artículos 74 de la Constitución\n                   Política del Estado Libre y Soberano de Morelos; 3, 4, fracción I, 9, fracción III, 13,\n                   fracción VI, 14, 15 y 23, fracción IV, de la Ley Orgánica de la Administración Pública\n                   del Estado Libre y Soberano de Morelos, y 11, 12, fracción XII y 41 del Reglamento\n                   Interior de la Secretaría de Hacienda.\n   III.   “LAS PARTES” declaran que:\n   III.1. Cuentan con las facultades necesarias para intervenir en la suscripción del presente Convenio\n          Modificatorio.\n   III.2. Se reconocen mutuamente la personalidad con que se ostentan y manifiestan su conformidad para la\n          celebración del presente Convenio Modificatorio.\n   III.3. Celebran el presente instrumento, de conformidad con lo establecido en los artículos 21, 22, 23,\n          24 y 25 de los “Lineamientos” y en términos de la Cláusula Vigésima del Convenio de Coordinación\n          y Adhesión."
  },
  {
    "objectID": "t5_texto.html#importar-una-imagen-con-texto-con-tesseract",
    "href": "t5_texto.html#importar-una-imagen-con-texto-con-tesseract",
    "title": "T5: Análisis de texto (I)",
    "section": "Importar una imagen con texto con {tesseract}",
    "text": "Importar una imagen con texto con {tesseract}\nEl paquete {tesseract} …\n\n“utiliza datos de entrenamiento para realizar OCR. La mayoría de los sistemas utilizan de forma predeterminada los datos de entrenamiento en inglés”. Para mejorar el rendimiento de OCR para otros idiomas, puede instalar los datos de entrenamiento de su distribución… En Windows y MacOS, puede instalar idiomas mediante la función tesseract_download, que descarga datos de entrenamiento directamente desde github y los almacena en la ruta del disco…” (traducido de la viñeta)\n\n\nif(is.na(match(\"spa\", tesseract::tesseract_info()$available)))\n  tesseract::tesseract_download(\"spa\") # baja el entrenamiento para español\n\nspa <- tesseract::tesseract(\"spa\") # aquí este será el \"engine\"\n\ntext <- tesseract::ocr(\"text/texto1.png\", #ruta donde está la imagen\n                       engine = spa) # que lo lea en español\ncat(text)\n\nNOTA\n\nLas denominaciones empleadas en esta publicación y la forma en que aparecen\npresentados los datos que contiene no implican, de parte de la Secretaría de las\nNaciones Unidas, juicio alguno sobre la condición jurídica de ninguno de los países o\nterritorios citados o de sus autoridades, ni respecto de la delimitación de sus fronte-\nras O límites.\n\nEn algunos cuadros, las designaciones economías “desarrolladas” y “en\ndesarrollo”? se emplean por razones estadísticas y no expresan necesariamente juicio\nalguno sobre la etapa alcanzada por un determinado país o zona en el proceso de\ndesarrollo,\n\nEl término “país” usado en el texto de esta publicación también se refiere, cuan-\ndo proceda, a territorios o áreas.\n\nLos puntos de vista que se exponen en esta publicación son los de sus respectivos\nautores y no entrañan la manifestación de opinión alguna por parte de la Secretaría\nde las Naciones Unidas.\n\nEsta publicación ha sido preparada y refundida con arreglo a la práctica y\nrequerimientos de las Naciones Unidas.\n\nLas signaturas de los documentos de las Naciones Unidas se componen de letras\nmayúsculas y cifras. La mención de una de tales signaturas indica que se hace\nreferencia a un documento de las Naciones Unidas."
  },
  {
    "objectID": "t5_texto.html#stringr-limpieza-de-variables-de-cadena",
    "href": "t5_texto.html#stringr-limpieza-de-variables-de-cadena",
    "title": "T5: Análisis de texto (I)",
    "section": "{stringr} Limpieza de variables de cadena",
    "text": "{stringr} Limpieza de variables de cadena\n\nstringr::str_squish(text)\n\n[1] \"NOTA Las denominaciones empleadas en esta publicación y la forma en que aparecen presentados los datos que contiene no implican, de parte de la Secretaría de las Naciones Unidas, juicio alguno sobre la condición jurídica de ninguno de los países o territorios citados o de sus autoridades, ni respecto de la delimitación de sus fronte- ras O límites. En algunos cuadros, las designaciones economías “desarrolladas” y “en desarrollo”? se emplean por razones estadísticas y no expresan necesariamente juicio alguno sobre la etapa alcanzada por un determinado país o zona en el proceso de desarrollo, El término “país” usado en el texto de esta publicación también se refiere, cuan- do proceda, a territorios o áreas. Los puntos de vista que se exponen en esta publicación son los de sus respectivos autores y no entrañan la manifestación de opinión alguna por parte de la Secretaría de las Naciones Unidas. Esta publicación ha sido preparada y refundida con arreglo a la práctica y requerimientos de las Naciones Unidas. Las signaturas de los documentos de las Naciones Unidas se componen de letras mayúsculas y cifras. La mención de una de tales signaturas indica que se hace referencia a un documento de las Naciones Unidas.\"\n\n\n\nnota<-stringr::str_split_fixed(text, \"\\n\\n\", n=10) ## por párrafos\nnota\n\n     [,1]  \n[1,] \"NOTA\"\n     [,2]                                                                                                                                                                                                                                                                                                                                                           \n[1,] \"Las denominaciones empleadas en esta publicación y la forma en que aparecen\\npresentados los datos que contiene no implican, de parte de la Secretaría de las\\nNaciones Unidas, juicio alguno sobre la condición jurídica de ninguno de los países o\\nterritorios citados o de sus autoridades, ni respecto de la delimitación de sus fronte-\\nras O límites.\"\n     [,3]                                                                                                                                                                                                                                                       \n[1,] \"En algunos cuadros, las designaciones economías “desarrolladas” y “en\\ndesarrollo”? se emplean por razones estadísticas y no expresan necesariamente juicio\\nalguno sobre la etapa alcanzada por un determinado país o zona en el proceso de\\ndesarrollo,\"\n     [,4]                                                                                                                   \n[1,] \"El término “país” usado en el texto de esta publicación también se refiere, cuan-\\ndo proceda, a territorios o áreas.\"\n     [,5]                                                                                                                                                                                             \n[1,] \"Los puntos de vista que se exponen en esta publicación son los de sus respectivos\\nautores y no entrañan la manifestación de opinión alguna por parte de la Secretaría\\nde las Naciones Unidas.\"\n     [,6]                                                                                                                \n[1,] \"Esta publicación ha sido preparada y refundida con arreglo a la práctica y\\nrequerimientos de las Naciones Unidas.\"\n     [,7]                                                                                                                                                                                                               \n[1,] \"Las signaturas de los documentos de las Naciones Unidas se componen de letras\\nmayúsculas y cifras. La mención de una de tales signaturas indica que se hace\\nreferencia a un documento de las Naciones Unidas.\\n\"\n     [,8] [,9] [,10]\n[1,] \"\"   \"\"   \"\"   \n\n\n\nstringr::str_count(text, \"\\n\\n\")\n\n[1] 6\n\n\n\nnota<-stringr::str_split_fixed(text,\n                                 pattern=\"\\n\\n\", \n                                 n=str_count(text, \"\\n\\n\")+1) ## por párrafos\nnota\n\n     [,1]  \n[1,] \"NOTA\"\n     [,2]                                                                                                                                                                                                                                                                                                                                                           \n[1,] \"Las denominaciones empleadas en esta publicación y la forma en que aparecen\\npresentados los datos que contiene no implican, de parte de la Secretaría de las\\nNaciones Unidas, juicio alguno sobre la condición jurídica de ninguno de los países o\\nterritorios citados o de sus autoridades, ni respecto de la delimitación de sus fronte-\\nras O límites.\"\n     [,3]                                                                                                                                                                                                                                                       \n[1,] \"En algunos cuadros, las designaciones economías “desarrolladas” y “en\\ndesarrollo”? se emplean por razones estadísticas y no expresan necesariamente juicio\\nalguno sobre la etapa alcanzada por un determinado país o zona en el proceso de\\ndesarrollo,\"\n     [,4]                                                                                                                   \n[1,] \"El término “país” usado en el texto de esta publicación también se refiere, cuan-\\ndo proceda, a territorios o áreas.\"\n     [,5]                                                                                                                                                                                             \n[1,] \"Los puntos de vista que se exponen en esta publicación son los de sus respectivos\\nautores y no entrañan la manifestación de opinión alguna por parte de la Secretaría\\nde las Naciones Unidas.\"\n     [,6]                                                                                                                \n[1,] \"Esta publicación ha sido preparada y refundida con arreglo a la práctica y\\nrequerimientos de las Naciones Unidas.\"\n     [,7]                                                                                                                                                                                                               \n[1,] \"Las signaturas de los documentos de las Naciones Unidas se componen de letras\\nmayúsculas y cifras. La mención de una de tales signaturas indica que se hace\\nreferencia a un documento de las Naciones Unidas.\\n\"\n\n\n\nstringr::str_squish(nota)\n\n[1] \"NOTA\"                                                                                                                                                                                                                                                                                                                                                     \n[2] \"Las denominaciones empleadas en esta publicación y la forma en que aparecen presentados los datos que contiene no implican, de parte de la Secretaría de las Naciones Unidas, juicio alguno sobre la condición jurídica de ninguno de los países o territorios citados o de sus autoridades, ni respecto de la delimitación de sus fronte- ras O límites.\"\n[3] \"En algunos cuadros, las designaciones economías “desarrolladas” y “en desarrollo”? se emplean por razones estadísticas y no expresan necesariamente juicio alguno sobre la etapa alcanzada por un determinado país o zona en el proceso de desarrollo,\"                                                                                                   \n[4] \"El término “país” usado en el texto de esta publicación también se refiere, cuan- do proceda, a territorios o áreas.\"                                                                                                                                                                                                                                     \n[5] \"Los puntos de vista que se exponen en esta publicación son los de sus respectivos autores y no entrañan la manifestación de opinión alguna por parte de la Secretaría de las Naciones Unidas.\"                                                                                                                                                            \n[6] \"Esta publicación ha sido preparada y refundida con arreglo a la práctica y requerimientos de las Naciones Unidas.\"                                                                                                                                                                                                                                        \n[7] \"Las signaturas de los documentos de las Naciones Unidas se componen de letras mayúsculas y cifras. La mención de una de tales signaturas indica que se hace referencia a un documento de las Naciones Unidas.\"                                                                                                                                            \n\n\nSi queremos quitar lo “-”, lo podemos hacer:\n\nnota<-stringr::str_squish(nota)\n\nstringr::str_remove_all(nota, \n                        pattern=\"- \")\n\n[1] \"NOTA\"                                                                                                                                                                                                                                                                                                                                                   \n[2] \"Las denominaciones empleadas en esta publicación y la forma en que aparecen presentados los datos que contiene no implican, de parte de la Secretaría de las Naciones Unidas, juicio alguno sobre la condición jurídica de ninguno de los países o territorios citados o de sus autoridades, ni respecto de la delimitación de sus fronteras O límites.\"\n[3] \"En algunos cuadros, las designaciones economías “desarrolladas” y “en desarrollo”? se emplean por razones estadísticas y no expresan necesariamente juicio alguno sobre la etapa alcanzada por un determinado país o zona en el proceso de desarrollo,\"                                                                                                 \n[4] \"El término “país” usado en el texto de esta publicación también se refiere, cuando proceda, a territorios o áreas.\"                                                                                                                                                                                                                                     \n[5] \"Los puntos de vista que se exponen en esta publicación son los de sus respectivos autores y no entrañan la manifestación de opinión alguna por parte de la Secretaría de las Naciones Unidas.\"                                                                                                                                                          \n[6] \"Esta publicación ha sido preparada y refundida con arreglo a la práctica y requerimientos de las Naciones Unidas.\"                                                                                                                                                                                                                                      \n[7] \"Las signaturas de los documentos de las Naciones Unidas se componen de letras mayúsculas y cifras. La mención de una de tales signaturas indica que se hace referencia a un documento de las Naciones Unidas.\""
  },
  {
    "objectID": "t5_texto.html#más-operaciones-con-cadenas-con-stringr-y-tokenizers",
    "href": "t5_texto.html#más-operaciones-con-cadenas-con-stringr-y-tokenizers",
    "title": "T5: Análisis de texto (I)",
    "section": "Más operaciones con cadenas con {stringr} y {tokenizers}",
    "text": "Más operaciones con cadenas con {stringr} y {tokenizers}\nYa vimos el conteo de algunos patrones y cómo podemos quitar algunos. Trabajemos con el cuento de Quiroga, que también está un poco sucio, y veamos como podemos seguir utilizando el formato tidy\n\nojos_sombrios<-ojos_sombrios %>% \n  stringr::str_split_fixed( pattern=\"\\n\\n\", n=str_count(text, \"\\n\\n\")+1) %>% ## por párrafos %\n  stringr::str_squish()\n\nHay un personaje que se llama Nébel, veámos cuantas veces aparece:\n\nsummary(ojos_sombrios)\n\n   Length     Class      Mode \n        7 character character \n\nojos_sombrios %>% \nstringr::str_count(pattern=\"Vezzera\") %>% \n  sum()\n\n[1] 21\n\n\nVamos a ver cuántas palabras tiene cada párrafos, hay unos párrafos vacíos:\n\ntokenizers::count_words(ojos_sombrios)\n\n[1]    3   62   69  135   46   12 5635\n\n\nRevisemos el discurso de Amlo:\n\ntokenizers::count_words(amlo)\n\n  [1]   3   0   2   0   4   0   5   0   2   0   3   0   0  24   0 124   0   0\n [19] 514   0   0   0   0   0  57   0 113   0  33   0 150   0  27   0   0   0\n [37]   0   0   0   0  94   0 171   0  28   0 139   0   0   0   0   0   0   0\n [55] 293   0  25   0  81   0 133   0   0   0   0   0   0   0 180   0 123   0\n [73] 141   0 145   0   0   0   0   0   0   0  99   0  56   0 116   0 114   0\n [91]  87   0   0   0 214   0 208   0  58   0  89   0  85   0   0   0   3   0\n[109]  40   0 174   0  99\n\n\nDe los 113 párrafos tenemos varios que están en 0. Vamos a eliminarlos. Vemos que txt reconoció los párrafos sin problemas, sin necesidad de poner la marca de párrafo\n\ncount<-tokenizers::count_words(amlo) \ncount==0\n\n  [1] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n [13]  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n [25] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE\n [37]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n [49]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n [61] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n [73] FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE\n [85] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE\n [97] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE\n[109] FALSE  TRUE FALSE  TRUE FALSE\n\namlo<-amlo[!count==0] \n\nVamos a jugar más con algunas opciones de {tokenizers}\n\ntokenizers::count_words(amlo)\n\n [1]   3   2   4   5   2   3  24 124 514  57 113  33 150  27  94 171  28 139 293\n[20]  25  81 133 180 123 141 145  99  56 116 114  87 214 208  58  89  85   3  40\n[39] 174  99\n\ntokenizers::count_sentences(amlo)\n\n [1]  1  1  1  1  1  1  1  4 12  3  4  2  2  1  1  6  1  2  8  1  1  3  4  5  1\n[26]  4  1  1  3  1  1  2  3  1  5  1  1  2  6  2"
  },
  {
    "objectID": "t5_texto.html#tokenización-para-análisis-de-texto",
    "href": "t5_texto.html#tokenización-para-análisis-de-texto",
    "title": "T5: Análisis de texto (I)",
    "section": "Tokenización para análisis de texto",
    "text": "Tokenización para análisis de texto\nLas palabras tienen un papel en el lenguaje, por lo cual muchas veces la unidad que usaremos será esa. Uno de los primeros pasos para el análisis de texto será descomponer nuestros textos en palabras.\n\nTokenización con {tidytext}\nPara usar {tidytext}, necesitamos que nuestro texto esté en formato tibble:\n\namlo_df <-tibble(text=amlo)\n\nA partir de esto podemos pasar al proceso de tokenización:\n\namlo_df %>%\n  unnest_tokens(word, text)\n\n# A tibble: 4,056 × 1\n   word        \n   <chr>       \n 1 amigas      \n 2 y           \n 3 amigos      \n 4 invitados   \n 5 especiales  \n 6 presidentes \n 7 municipales \n 8 presidentas \n 9 municipales \n10 gobernadores\n# ℹ 4,046 more rows\n\n\nPodemos hacer un tabulado de estos elementos:\n\namlo_df %>%\n  tidytext::unnest_tokens(word, text) %>% \n  tabyl(word) %>% \n  arrange(-n) %>% \n  head(10)\n\n word   n    percent\n   de 260 0.06410256\n   la 179 0.04413215\n    y 145 0.03574951\n   en 134 0.03303748\n   el 124 0.03057199\n  que 120 0.02958580\n    a  84 0.02071006\n   se  83 0.02046351\n  los  59 0.01454635\n   es  53 0.01306706\n\n\nImporta el tipo de palabra!!! En muchos idiomas las preposiciones y determinantes son bastante comunes. Hay varios diccionarios, incluso los podemos modificar. Para este ejercicio utilizaremos las palabras comunes del paquete {quanteda}\n\nquanteda::stopwords(language=\"spa\")\n\n  [1] \"de\"           \"la\"           \"que\"          \"el\"           \"en\"          \n  [6] \"y\"            \"a\"            \"los\"          \"del\"          \"se\"          \n [11] \"las\"          \"por\"          \"un\"           \"para\"         \"con\"         \n [16] \"no\"           \"una\"          \"su\"           \"al\"           \"lo\"          \n [21] \"como\"         \"más\"          \"pero\"         \"sus\"          \"le\"          \n [26] \"ya\"           \"o\"            \"este\"         \"sí\"           \"porque\"      \n [31] \"esta\"         \"entre\"        \"cuando\"       \"muy\"          \"sin\"         \n [36] \"sobre\"        \"también\"      \"me\"           \"hasta\"        \"hay\"         \n [41] \"donde\"        \"quien\"        \"desde\"        \"todo\"         \"nos\"         \n [46] \"durante\"      \"todos\"        \"uno\"          \"les\"          \"ni\"          \n [51] \"contra\"       \"otros\"        \"ese\"          \"eso\"          \"ante\"        \n [56] \"ellos\"        \"e\"            \"esto\"         \"mí\"           \"antes\"       \n [61] \"algunos\"      \"qué\"          \"unos\"         \"yo\"           \"otro\"        \n [66] \"otras\"        \"otra\"         \"él\"           \"tanto\"        \"esa\"         \n [71] \"estos\"        \"mucho\"        \"quienes\"      \"nada\"         \"muchos\"      \n [76] \"cual\"         \"poco\"         \"ella\"         \"estar\"        \"estas\"       \n [81] \"algunas\"      \"algo\"         \"nosotros\"     \"mi\"           \"mis\"         \n [86] \"tú\"           \"te\"           \"ti\"           \"tu\"           \"tus\"         \n [91] \"ellas\"        \"nosotras\"     \"vosotros\"     \"vosotras\"     \"os\"          \n [96] \"mío\"          \"mía\"          \"míos\"         \"mías\"         \"tuyo\"        \n[101] \"tuya\"         \"tuyos\"        \"tuyas\"        \"suyo\"         \"suya\"        \n[106] \"suyos\"        \"suyas\"        \"nuestro\"      \"nuestra\"      \"nuestros\"    \n[111] \"nuestras\"     \"vuestro\"      \"vuestra\"      \"vuestros\"     \"vuestras\"    \n[116] \"esos\"         \"esas\"         \"estoy\"        \"estás\"        \"está\"        \n[121] \"estamos\"      \"estáis\"       \"están\"        \"esté\"         \"estés\"       \n[126] \"estemos\"      \"estéis\"       \"estén\"        \"estaré\"       \"estarás\"     \n[131] \"estará\"       \"estaremos\"    \"estaréis\"     \"estarán\"      \"estaría\"     \n[136] \"estarías\"     \"estaríamos\"   \"estaríais\"    \"estarían\"     \"estaba\"      \n[141] \"estabas\"      \"estábamos\"    \"estabais\"     \"estaban\"      \"estuve\"      \n[146] \"estuviste\"    \"estuvo\"       \"estuvimos\"    \"estuvisteis\"  \"estuvieron\"  \n[151] \"estuviera\"    \"estuvieras\"   \"estuviéramos\" \"estuvierais\"  \"estuvieran\"  \n[156] \"estuviese\"    \"estuvieses\"   \"estuviésemos\" \"estuvieseis\"  \"estuviesen\"  \n[161] \"estando\"      \"estado\"       \"estada\"       \"estados\"      \"estadas\"     \n[166] \"estad\"        \"he\"           \"has\"          \"ha\"           \"hemos\"       \n[171] \"habéis\"       \"han\"          \"haya\"         \"hayas\"        \"hayamos\"     \n[176] \"hayáis\"       \"hayan\"        \"habré\"        \"habrás\"       \"habrá\"       \n[181] \"habremos\"     \"habréis\"      \"habrán\"       \"habría\"       \"habrías\"     \n[186] \"habríamos\"    \"habríais\"     \"habrían\"      \"había\"        \"habías\"      \n[191] \"habíamos\"     \"habíais\"      \"habían\"       \"hube\"         \"hubiste\"     \n[196] \"hubo\"         \"hubimos\"      \"hubisteis\"    \"hubieron\"     \"hubiera\"     \n[201] \"hubieras\"     \"hubiéramos\"   \"hubierais\"    \"hubieran\"     \"hubiese\"     \n[206] \"hubieses\"     \"hubiésemos\"   \"hubieseis\"    \"hubiesen\"     \"habiendo\"    \n[211] \"habido\"       \"habida\"       \"habidos\"      \"habidas\"      \"soy\"         \n[216] \"eres\"         \"es\"           \"somos\"        \"sois\"         \"son\"         \n[221] \"sea\"          \"seas\"         \"seamos\"       \"seáis\"        \"sean\"        \n[226] \"seré\"         \"serás\"        \"será\"         \"seremos\"      \"seréis\"      \n[231] \"serán\"        \"sería\"        \"serías\"       \"seríamos\"     \"seríais\"     \n[236] \"serían\"       \"era\"          \"eras\"         \"éramos\"       \"erais\"       \n[241] \"eran\"         \"fui\"          \"fuiste\"       \"fue\"          \"fuimos\"      \n[246] \"fuisteis\"     \"fueron\"       \"fuera\"        \"fueras\"       \"fuéramos\"    \n[251] \"fuerais\"      \"fueran\"       \"fuese\"        \"fueses\"       \"fuésemos\"    \n[256] \"fueseis\"      \"fuesen\"       \"siendo\"       \"sido\"         \"tengo\"       \n[261] \"tienes\"       \"tiene\"        \"tenemos\"      \"tenéis\"       \"tienen\"      \n[266] \"tenga\"        \"tengas\"       \"tengamos\"     \"tengáis\"      \"tengan\"      \n[271] \"tendré\"       \"tendrás\"      \"tendrá\"       \"tendremos\"    \"tendréis\"    \n[276] \"tendrán\"      \"tendría\"      \"tendrías\"     \"tendríamos\"   \"tendríais\"   \n[281] \"tendrían\"     \"tenía\"        \"tenías\"       \"teníamos\"     \"teníais\"     \n[286] \"tenían\"       \"tuve\"         \"tuviste\"      \"tuvo\"         \"tuvimos\"     \n[291] \"tuvisteis\"    \"tuvieron\"     \"tuviera\"      \"tuvieras\"     \"tuviéramos\"  \n[296] \"tuvierais\"    \"tuvieran\"     \"tuviese\"      \"tuvieses\"     \"tuviésemos\"  \n[301] \"tuvieseis\"    \"tuviesen\"     \"teniendo\"     \"tenido\"       \"tenida\"      \n[306] \"tenidos\"      \"tenidas\"      \"tened\"       \n\nstop<-quanteda::stopwords(language=\"spa\")\n\n\namlo_df %>%\n  tidytext::unnest_tokens(word, text) %>% \n  filter(!word%in%stop) %>%  # ojo con el filtro\n  tabyl(word) %>% \n  arrange(-n) %>% \n  head(10)\n\n         word  n     percent\n          mil 29 0.014521783\n     millones 16 0.008012018\n       ciento 15 0.007511267\n    inversión 13 0.006509765\n         aquí 12 0.006009014\n       méxico 12 0.006009014\n         país 12 0.006009014\n trabajadores 12 0.006009014\n     gobierno 11 0.005508262\n construcción 10 0.005007511\n\n\n\n\nTokenización con {udpipe}\nPara mayor información consultar https://ufal.mff.cuni.cz/~straka/papers/2017-conll_udpipe.pdf\nPrimero vamos a bajar nuestro modelo en español\n\nudmodel <- udpipe_download_model(language = \"spanish\")  # esto trabaja con la estructura del español\n\nDownloading udpipe model from https://raw.githubusercontent.com/jwijffels/udpipe.models.ud.2.5/master/inst/udpipe-ud-2.5-191206/spanish-gsd-ud-2.5-191206.udpipe to /Users/anaescoto/Dropbox/2023/PAPIME2023/demos/spanish-gsd-ud-2.5-191206.udpipe\n\n\n - This model has been trained on version 2.5 of data from https://universaldependencies.org\n\n\n - The model is distributed under the CC-BY-SA-NC license: https://creativecommons.org/licenses/by-nc-sa/4.0\n\n\n - Visit https://github.com/jwijffels/udpipe.models.ud.2.5 for model license details.\n\n\n - For a list of all models and their licenses (most models you can download with this package have either a CC-BY-SA or a CC-BY-SA-NC license) read the documentation at ?udpipe_download_model. For building your own models: visit the documentation by typing vignette('udpipe-train', package = 'udpipe')\n\n\nDownloading finished, model stored at '/Users/anaescoto/Dropbox/2023/PAPIME2023/demos/spanish-gsd-ud-2.5-191206.udpipe'\n\n\nVamos a “tokenizar” el discurso de AMLO:\n\namlo_udpipe<-udpipe(x =amlo, \n                      object=udmodel) #\"tokeniza\" el texto\n\nAdemás de separarnos las palabras, también distingue puntuación (por eso tiene más líneas que las palabras), pero también nos da las “Universal POS tags”, donde POS=part-of-speech, que están en la variable “upos”\n\namlo_udpipe %>% \n  head(10)\n\n   doc_id paragraph_id sentence_id\n1    doc1            1           1\n2    doc1            1           1\n3    doc1            1           1\n4    doc1            1           1\n5    doc2            1           1\n6    doc2            1           1\n7    doc2            1           1\n8    doc3            1           1\n9    doc3            1           1\n10   doc3            1           1\n                                            sentence start end term_id token_id\n1                                   Amigas y amigos,     1   6       1        1\n2                                   Amigas y amigos,     8   8       2        2\n3                                   Amigas y amigos,    10  15       3        3\n4                                   Amigas y amigos,    16  16       4        4\n5                              Invitados especiales,     1   9       1        1\n6                              Invitados especiales,    11  20       2        2\n7                              Invitados especiales,    21  21       3        3\n8  Presidentes municipales, presidentas municipales,     1  11       1        1\n9  Presidentes municipales, presidentas municipales,    13  23       2        2\n10 Presidentes municipales, presidentas municipales,    24  24       3        3\n         token      lemma  upos xpos                   feats head_token_id\n1       Amigas      amiga  NOUN <NA>  Gender=Fem|Number=Plur             0\n2            y          y CCONJ <NA>                    <NA>             3\n3       amigos      amigo  NOUN <NA> Gender=Masc|Number=Plur             1\n4            ,          , PUNCT <NA>                    <NA>             1\n5    Invitados   invitado  NOUN <NA> Gender=Masc|Number=Plur             0\n6   especiales   especial   ADJ <NA>             Number=Plur             1\n7            ,          , PUNCT <NA>                    <NA>             1\n8  Presidentes presidente  NOUN <NA> Gender=Masc|Number=Plur             0\n9  municipales  municipal   ADJ <NA>             Number=Plur             1\n10           ,          , PUNCT <NA>                    <NA>             4\n   dep_rel deps            misc\n1     root <NA>            <NA>\n2       cc <NA>            <NA>\n3     conj <NA>   SpaceAfter=No\n4    punct <NA> SpacesAfter=\\\\n\n5     root <NA>            <NA>\n6     amod <NA>   SpaceAfter=No\n7    punct <NA> SpacesAfter=\\\\n\n8     root <NA>            <NA>\n9     amod <NA>   SpaceAfter=No\n10   punct <NA>            <NA>\n\n\n¿Con cuales UPOS se trabaja? https://universaldependencies.org/u/pos/\n\namlo_udpipe %>% \n  tabyl(upos)\n\n  upos   n      percent valid_percent\n   ADJ 280 0.0602668963  0.0610953524\n   ADP 715 0.1538958244  0.1560113463\n   ADV 189 0.0406801550  0.0412393629\n   AUX 179 0.0385277658  0.0390573860\n CCONJ 194 0.0417563495  0.0423303513\n   DET 607 0.1306500215  0.1324459961\n  INTJ   1 0.0002152389  0.0002181977\n  NOUN 889 0.1913473956  0.1939777438\n   NUM 126 0.0271201033  0.0274929086\n  PRON 207 0.0445544554  0.0451669212\n PROPN 166 0.0357296599  0.0362208161\n PUNCT 466 0.1003013345  0.1016801222\n SCONJ 137 0.0294877314  0.0298930831\n   SYM   1 0.0002152389  0.0002181977\n  VERB 426 0.0916917779  0.0929522147\n  <NA>  63 0.0135600517            NA\n\n\n¿Qué no logró identificar?\n\namlo_udpipe %>% \n  filter(is.na(upos)) %>% \n  tabyl(token)\n\n      token  n    percent\n         Al  1 0.01587302\n  agregarse  2 0.03174603\n         al 21 0.33333333\n      darle  1 0.01587302\n  dedicarse  1 0.01587302\n        del 35 0.55555556\n haciéndole  1 0.01587302\n  venderlos  1 0.01587302\n\n\nLa clasificación de las UPOS nos permite hacer filtro por el tipo de palabra que queremos analizar, seguro los sustantivos son los que más queremos revisar:\n\namlo_udpipe %>% \n  filter(upos==\"NOUN\") %>% \n  tabyl(token) %>% \n  arrange(-n) %>% \n  head(10)\n\n        token  n     percent\n     millones 16 0.017997750\n    inversión 13 0.014623172\n         país 12 0.013498313\n trabajadores 12 0.013498313\n construcción 10 0.011248594\n     gobierno 10 0.011248594\n    refinería  9 0.010123735\n       tiempo  9 0.010123735\n      trabajo  9 0.010123735\n     política  8 0.008998875\n\n\nAdemás de los “tokens” podemos pedirles los “lemma”, que como vemos quita el género y el número\n\namlo_udpipe %>% \n  filter(upos==\"NOUN\") %>% \n  tabyl(lemma) %>% \n  arrange(-n) %>% \n  head(10)\n\n      lemma  n    percent\n     millón 19 0.02137233\n       país 16 0.01799775\n  inversión 13 0.01462317\n  refinería 13 0.01462317\n    empresa 12 0.01349831\n   gobierno 12 0.01349831\n       obra 12 0.01349831\n     tiempo 12 0.01349831\n trabajador 12 0.01349831\n        año 11 0.01237345"
  },
  {
    "objectID": "t5_texto.html#estadísticas-de-las-palabras",
    "href": "t5_texto.html#estadísticas-de-las-palabras",
    "title": "T5: Análisis de texto (I)",
    "section": "Estadísticas de las palabras",
    "text": "Estadísticas de las palabras\nTenemos que una función en {udpipe} que se llama txt_freq(), es como un tabulado, pero nos da la frecuencia ordenada de mayor a m enor y los porcentajes relativos\n\namlo_udpipe %>% \n  filter(upos==\"NOUN\") %>% # nos vamos a quedar ahorita solo con los nombres\n  with(\n    txt_freq(token) # ojo hay que poner el with, porque no es formato tidy el comando\n    ) %>% \n  head(10) # elegir número\n\n            key freq  freq_pct\n1      millones   16 1.7997750\n2     inversión   13 1.4623172\n3          país   12 1.3498313\n4  trabajadores   12 1.3498313\n5      gobierno   10 1.1248594\n6  construcción   10 1.1248594\n7     refinería    9 1.0123735\n8        tiempo    9 1.0123735\n9       trabajo    9 1.0123735\n10     política    8 0.8998875\n\n\nUtilizando {ggplot2}, una vez que tenemos esta tabla, podemos hacer una gráfica\n\namlo_udpipe %>% \n  filter(upos==\"NOUN\") %>% # nos vamos a quedar ahorita solo con los nombres\n  with(\n    txt_freq(token) # ojo hay que poner el with, porque no es formato tidy el comando\n    ) %>% \n  head(20) %>% # me voy a quedar con las primeras 20 palabras\n  ggplot()+\n  aes(x=key, \n      y=freq) +\n  geom_bar(stat = \"identity\") + coord_flip()\n\n\n\n\nPero no está ordenado ….\n\namlo_udpipe %>% \n  filter(upos==\"NOUN\") %>% # nos vamos a quedar ahorita solo con los nombres\n  with(\n    txt_freq(token) # ojo hay que poner el with, porque no es formato tidy el comando\n    ) %>% \n  head(20) %>% # me voy a quedar con las primeras 20 palabras\n  mutate(key = forcats::fct_reorder(key, freq)) %>% # aquí ordeno de acuerdo a las frecuencias\n  ggplot() + # aquí ya empieza el gráfico\n   aes(x=key, \n      y=freq) +\n  geom_bar(stat = \"identity\", fill=\"blue\", alpha=I(0.5)) + \n  coord_flip() + theme_minimal() +\n  labs(x=\"Sustantivos\", y=\"Frecuencia\")"
  },
  {
    "objectID": "t5_texto.html#comparando-tokens-palabras-y-más",
    "href": "t5_texto.html#comparando-tokens-palabras-y-más",
    "title": "T5: Análisis de texto (I)",
    "section": "Comparando tokens, palabras y más",
    "text": "Comparando tokens, palabras y más\nPara comparar mejor, descargamos otro discurso:\n\namlo2 <- readLines(\"text/20220916_amlo.txt\") \ncount2<-tokenizers::count_words(amlo2) \namlo2<-amlo2[!count2==0] \n\namlo2_udpipe<-udpipe(x =amlo2, \n                      object=udmodel) #\"tokeniza\" el texto\n\nPodemos revisar qué tanto se pueden comparar estos textos utilizando {udpipe}\n\nsustant1<-amlo_udpipe %>% filter(upos==\"NOUN\")\nsustant2<-amlo2_udpipe %>% filter(upos==\"NOUN\")\n\ncomunes<-udpipe::txt_overlap(sustant1$lemma, # texto 1\n                    sustant1$lemma) # texto 2\n\ncomunes %>% head(10)\n\n [1] \"amiga\"      \"amigo\"      \"invitado\"   \"presidente\" \"presidenta\"\n [6] \"gobernador\" \"jefa\"       \"gobierno\"   \"Servidor\"   \"amiga\"     \n\n\nEsta función nos da todas las palabras(o lemmas) comunes a ambos textos."
  },
  {
    "objectID": "t5_texto.html#nubes-de-palabras",
    "href": "t5_texto.html#nubes-de-palabras",
    "title": "T5: Análisis de texto (I)",
    "section": "Nubes de palabras",
    "text": "Nubes de palabras\nOtra forma muy común para presentar cuántas palabras hay y su frecuencia son las nubes de palabras\nLo primero es que quizas sea más fácil tener un objeto con los conteos de palabras que encontramos usando txt_frq\n\ndf_nube<-amlo_udpipe %>% \n  filter(upos==\"NOUN\") %>% # nos vamos a quedar ahorita solo con los nombres\n  with(\n    txt_freq(token) # ojo hay que poner el with, porque no es formato tidy el comando\n    ) \n\nO si queremos usar todas las palabras independientemente de su función, podemos utilizar las palabras stop:\n\ndf_nube2<-amlo_df %>% \n  unnest_tokens(word,text) %>% \n  filter(!word%in%stop) %>%  # ojo con el filtro\n  tabyl(word) \n\ndf_nube2 %>% head(10)\n\n word n      percent\n  069 1 0.0005007511\n   10 1 0.0005007511\n  100 2 0.0010015023\n  109 1 0.0005007511\n   11 1 0.0005007511\n   12 1 0.0005007511\n   14 3 0.0015022534\n   17 1 0.0005007511\n  183 1 0.0005007511\n   19 2 0.0010015023\n\n\nOjo, aquí no se quitan algunos elementos como números. Esto es muy fácil utilizando {stringr}\n\ndf_nube2 %<>% \n  filter(stringr::str_detect(word, \"[digits]\"))\n\n\ndf_nube2 %>% head(10)\n\n           word n      percent\n       abiertas 1 0.0005007511\n       acabamos 1 0.0005007511\n       acciones 1 0.0005007511\n         acción 3 0.0015022534\n     aclaración 1 0.0005007511\n acontecimiento 1 0.0005007511\n        actitud 2 0.0010015023\n      actividad 1 0.0005007511\n       actuales 1 0.0005007511\n     actualidad 1 0.0005007511\n\n\nHoy será más fácil hacer nuestra nube\n\nNube con {wordcloud}\n\nset.seed(1234) # ojo es importante para que se vea siempre igual. Pero no es grave si no se pone\n\nwordcloud::wordcloud(words =df_nube$key, # columna donde se listan las palabras\n                     freq = df_nube$freq, # columna donde están las frecuencias\n                     min.freq = 5, # valor mínimo para incluirla\n                     max.words=200, #Máximo de palabras\n                     random.order=FALSE, #plot words in random order. If false, they will be plotted in decreasing frequency\n                     rot.per=0.35, # proportion words with 90 degree rotation\n                     colors=brewer.pal(8, \"Dark2\") # paleta de colores, aquí usamos uno de RColorBrewer\n                     )\n\n\n\n\n\n\nNube con {ggwordcloud}\nYa conocemos bastante el formato tidy, y sabemos de las ventajas de que nuestros gráficos sean ggplot\nAquí las estéticas que tenemos son “label” = columna donde están están las palabraas\ndf_palabras %>% \n  ggplot(\n    aes(label= variable donde están las palabras, \n        size = variable donde está la frecuencia))+\n  geom_text_wordcloud # la geometría especial.\n\ndf_nube %>% \n  filter(freq>2) %>% # hacemos un filtro porque muchas no se ven bien\n  ggplot()+\n  aes(label=key,\n      size=freq) +\n  geom_text_wordcloud() +\n  theme_minimal()\n\n\n\n\n\ndf_nube %>% \n  filter(freq>2) %>% # hacemos un filtro porque muchas no se ven bien\n  ggplot()+\n  aes(label=key,\n      size=freq) +\n  geom_text_wordcloud_area() +\n  theme_minimal()\n\n\n\n\nSe ve igual… dice la ayuda\n\ngeom_text_wordcloud_area is an alias with a different set of default, that chooses a font size so that the area of the text is now related to the size aesthetic.\n\nNo se ve tan divertida….\nUna de las cosas que hacía bonita a nuestra primera nube era el elemento aleatorio. Para ello vamos a necesitar saber cuántas filas tenemos\n\ndf_nube %>% \n  filter(freq>2) %>% \n  dim()\n\n[1] 76  3\n\n\n\nset.seed(1234)\n\ndf_nube %>% \n  filter(freq>2) %>% # hacemos un filtro porque muchas no se ven bien\n  ggplot() +\n    aes(\n      label =key, \n      size = freq,\n      color = factor(sample.int(10, 76, replace = TRUE)) # elegirá 10 colores aleatorios entre las 76 palabras\n      ) +\n  geom_text_wordcloud_area() +\n  scale_size_area(max_size = 8) +\n  theme_minimal()\n\n\n\n\nYa va agarrando… necesitamos los ángulos\n\ndf_nube %<>%\n  mutate(angulo = 90 * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40)))\n\n¿Qué hicimos? De manera aleatoria ponemos una variable que define los ángulos para cada una de las líneas de nuestra base\n\nset.seed(1234)\n\ndf_nube %>% \n  filter(freq>2) %>% # hacemos un filtro porque muchas no se ven bien\n  ggplot() +\n    aes(\n      label =key, \n      size = freq,\n      color = factor(sample.int(10, 76, replace = TRUE)), # elegirá 10 colores aleatorios entre las 76 palabras\n      angle= angulo) +\n  geom_text_wordcloud(rm_outside = TRUE) +\n  #scale_size_area(max_size = 8) +\n  theme_minimal()\n\n\n\n\nEs tu momento de brillar: haz una nube con el segundo discurso."
  },
  {
    "objectID": "conv.html",
    "href": "conv.html",
    "title": "¿Demografía para qué?",
    "section": "",
    "text": "Les invitamos a nuestro primer conversatorio sobre la relevancia de la demografía:\n\n\n\n\n\n📍Edificio F\nSala Lucio Mendieta y Nuñez\nFacultad de Ciencias Políticas y sociales\n\n¡Gracias por participar!"
  },
  {
    "objectID": "t2_endiseg2021.html",
    "href": "t2_endiseg2021.html",
    "title": "T2: ENDISEG 2021",
    "section": "",
    "text": "En esta liga puedes descarga el proyecto de trabajo. De esta manera no tendremos problemas con las rutas relativas.\nhttps://tinyurl.com/demos-talleres"
  },
  {
    "objectID": "t2_endiseg2021.html#video-de-la-sesión",
    "href": "t2_endiseg2021.html#video-de-la-sesión",
    "title": "T2: ENDISEG 2021",
    "section": "Video de la sesión",
    "text": "Video de la sesión\n\n\n\n\nPaquetes\n\nif (!require(\"pacman\")) install.packages(\"pacman\") # instala pacman si se requiere\n\nLoading required package: pacman\n\npacman::p_load(tidyverse,\n               haven, \n               readr,\n               foreign,\n               janitor,\n               magrittr,\n               pollster,\n               srvyr,\n               sjlabelled) #carga los paquetes necesarios \n\nEn esta práctica trabajaremos con los datos abiertos.\n¿Qué son datos abiertos?\nhttps://publications.iadb.org/publications/spanish/viewer/Los-datos-abiertos-en-América-Latina-y-el-Caribe.pdf"
  },
  {
    "objectID": "t2_endiseg2021.html#introducción-a-la-fuente",
    "href": "t2_endiseg2021.html#introducción-a-la-fuente",
    "title": "T2: ENDISEG 2021",
    "section": "Introducción a la fuente",
    "text": "Introducción a la fuente\nDe acuerdo a la información en los datos abiertos, hay cinco conjuntos de datos, uno a nivel vivienda y tres a nivel individuo:\n\nVivienda: tviv\nIndividual: tsdem\nIndividual - persona elegida: tapart_a\nIndividual - persona elegida: tapart_b\nIndividual - persona elegida: tmodulo\n\nAdemás esta base no tiene una sólo variable del id. Tiene un identificador compuesto. Podemos hacer un objeto tipo vector\n\nidviv<-c(\"folio\", \"viv_sel\")\nidper<-c(\"folio\", \"viv_sel\", \"hogar\", \"n_ren\")"
  },
  {
    "objectID": "t2_endiseg2021.html#importación-de-los-datos",
    "href": "t2_endiseg2021.html#importación-de-los-datos",
    "title": "T2: ENDISEG 2021",
    "section": "Importación de los datos",
    "text": "Importación de los datos\nAprovechamos y agregaremos un paso para limpiar los nombres con janitor::clean_names() utiliza el formato snakecase, quitará espacios y les pondra guión bajo, las mayúsculas se vuelven minúsculas y quita caracteres especiales.\n\ntvivienda <- readr::read_csv(\"data_t2/conjunto_de_datos_endiseg_2021_csv/conjunto_de_datos_tvivienda_endiseg_2021/conjunto_de_datos/conjunto_de_datos_tvivienda_endiseg_2021.csv\") %>% janitor::clean_names()\n\nRows: 43737 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (7): FOLIO, VIV_SEL, P1_2, P2_1, P2_3, EST_DIS, UPM_DIS\ndbl (14): P1_1, P1_3, P1_4, P1_5, P1_6, P1_7_1, P1_7_2, P1_7_3, P1_7_4, P1_7...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntsdem <- readr::read_csv(\"data_t2/conjunto_de_datos_endiseg_2021_csv/conjunto_de_datos_tsdem_endiseg_2021/conjunto_de_datos/conjunto_de_datos_tsdem_endiseg_2021.csv\") %>% janitor::clean_names()\n\nRows: 152497 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): FOLIO, VIV_SEL, N_REN, EDAD, P3_6_1, P3_6_2, EST_DIS, UPM_DIS\ndbl (5): HOGAR, PAREN, SEXO, P3_6_3, FACTOR\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntmodulo <- readr::read_csv(\"data_t2/conjunto_de_datos_endiseg_2021_csv/conjunto_de_datos_tmodulo_endiseg_2021/conjunto_de_datos/conjunto_de_datos_tmodulo_endiseg_2021.csv\") %>%\n  janitor::clean_names() %>% \n  dplyr::mutate(seleccionade=1)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 44189 Columns: 228\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (35): FOLIO, VIV_SEL, N_REN, P4_3A, NIV, P4_19, P5_1, P7_2, P7_3, P7_5,...\ndbl (192): HOGAR, P4_1, P4_2, P4_3, P4_4, P4_5, P4_6, P4_7, P4_8, P4_9C, PD4...\nlgl   (1): P11_2_3_3\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntapart_a <- readr::read_csv(\"data_t2/conjunto_de_datos_endiseg_2021_csv/conjunto_de_datos_tapart_a_endiseg_2021/conjunto_de_datos/conjunto_de_datos_tapart_a_endiseg_2021.csv\") %>% janitor::clean_names()\n\nRows: 2225 Columns: 50\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): FOLIO, VIV_SEL, N_REN, EST_DIS, UPM_DIS\ndbl (45): HOGAR, P6_1_01, P6_1_02, P6_1_03, P6_1_04, P6_1_05, P6_1_06, P6_1_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntapart_b <- readr::read_csv(\"data_t2/conjunto_de_datos_endiseg_2021_csv/conjunto_de_datos_tapart_b_endiseg_2021/conjunto_de_datos/conjunto_de_datos_tapart_b_endiseg_2021.csv\") %>% janitor::clean_names()\n\nRows: 41964 Columns: 50\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): FOLIO, VIV_SEL, N_REN, EST_DIS, UPM_DIS\ndbl (45): HOGAR, P6_7_01, P6_7_02, P6_7_03, P6_7_04, P6_7_05, P6_7_06, P6_7_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "t2_endiseg2021.html#fusionado-uno-a-uno-con-diferentes-conjuntos.",
    "href": "t2_endiseg2021.html#fusionado-uno-a-uno-con-diferentes-conjuntos.",
    "title": "T2: ENDISEG 2021",
    "section": "Fusionado uno a uno con diferentes conjuntos.",
    "text": "Fusionado uno a uno con diferentes conjuntos.\nMe gusta empezar con el modulo que tiene más casos y este sería mi “left” o conjunto “x”\n\nendiseg2021<-tsdem %>% \n  dplyr::left_join(tmodulo, by=idper) %>% \n  dplyr::select(-ends_with(\".y\")) %>% # quita todas las variables que terminan en .x\n  dplyr::rename_with(~ stringr::str_remove(.x,  pattern = \".x\"),  ends_with(\".x\")) \n\nSi checas me quedo con las variables repetidas que están en la izquierda, porque es mi conjunto más completo.\nHacemos lo mismo con tapart_a:\n\nendiseg2021<-endiseg2021 %>% \n  dplyr::left_join(tapart_a, by=idper) %>% \n  dplyr::select(-ends_with(\".y\")) %>% # quita todas las variables que terminan en .x\n  dplyr::rename_with(~ stringr::str_remove(.x,  pattern = \".x\"),  ends_with(\".x\")) \n\nHacemos lo mismo con el tapart_b\n\nendiseg2021<-endiseg2021 %>% \n  dplyr::left_join(tapart_b, by=idper) %>% \n  dplyr::select(-ends_with(\".y\")) %>% # quita todas las variables que terminan en .x\n  dplyr::rename_with(~ stringr::str_remove(.x,  pattern = \".x\"),  ends_with(\".x\")) \n\nY hoy agregamos la vivienda. Como para tener la lógica del cuestionario en nuestro dataframe, lo pondre como left:\n\nendiseg2021<-tvivienda %>% \n  dplyr::left_join(endiseg2021, by=idviv) %>% #ojo cambiamos acá\n  dplyr::select(-ends_with(\".y\")) %>% # quita todas las variables que terminan en .x\n  dplyr::rename_with(~ stringr::str_remove(.x,  pattern = \".x\"),  ends_with(\".x\")) \n\nVamos a botar los objetos anteriores, porque vamos a importar diccionarios y más para etiquetar nuestras variables.\n\nrm(tvivienda, tsdem, tmodulo, tapart_a, tapart_b)\ngc() # limpiamos la memoria\n\n           used  (Mb) gc trigger  (Mb) limit (Mb)  max used  (Mb)\nNcells  2352581 125.7    4567885 244.0         NA   4567885 244.0\nVcells 55380185 422.6  127518705 972.9      16384 127405643 972.1"
  },
  {
    "objectID": "t2_endiseg2021.html#etiquetado-de-variables",
    "href": "t2_endiseg2021.html#etiquetado-de-variables",
    "title": "T2: ENDISEG 2021",
    "section": "Etiquetado de variables",
    "text": "Etiquetado de variables\n\nDiccionario de variables\nEl formato abierto tiene la ventaja que siempre vendrá con diccionarios. Esto nos puede ayudar muchísimo.\nVamos a importar el diccionario del modulo que tiene las preguntas que más nos interesan\n\ndicc_tmodulo<- readr::read_csv(\"data_t2/conjunto_de_datos_endiseg_2021_csv/conjunto_de_datos_tmodulo_endiseg_2021/diccionario_de_datos/diccionario_datos_tmodulo_endiseg_2021.csv\") %>% clean_names()\n\nNew names:\nRows: 228 Columns: 9\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(5): nombre_campo, tipo, nemónico, catálogo, rango_claves dbl (1): longitud lgl\n(3): ...7, ...8, ...9\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...7`\n• `` -> `...8`\n• `` -> `...9`\n\n\nVamos a utilizar algunos elementos de cadena, para hacer la información más corta\n\ndicc_tmodulo<-dicc_tmodulo %>% \n  mutate(nombre_campo=stringr::str_remove_all(nombre_campo, \"Pregunta \"))\n\nPensemos que queremos saber cuál es el título de variable p7\n\ndicc_tmodulo %>% \n  filter(nemonico==\"p7_1\") %>% \n  select(nombre_campo)\n\n# A tibble: 1 × 1\n  nombre_campo                            \n  <chr>                                   \n1 P7.1 ¿Cuál es su sexo asignado al nacer?\n\n\nVamos a guardar esto\n\ndicc_tmodulo %>% \n  filter(nemonico==\"p7_1\") %>% \n  select(nombre_campo) -> label_p7_1\n\nCon este proceso se puede automatizar un poco:\n\nendiseg2021 %<>% \n  mutate(p7_1=sjlabelled::set_label(p7_1, label=label_p7_1$nombre_campo))\n\nRevisamos que tengamos el atributo\n\nglimpse(endiseg2021$p7_1)\n\n num [1:152497] 1 NA 2 NA NA 2 NA NA NA 2 ...\n - attr(*, \"label\")= chr \"P7.1 ¿Cuál es su sexo asignado al nacer?\"\n\n\n\n\nCatalogos de valores\nEstos nos servirán para etiquetas los valores de las variables. Hay un catálogo por variable. Sigamos con la variable p7_1\n\nlabels_p7_1 <- read_csv(\"data_t2/conjunto_de_datos_endiseg_2021_csv/conjunto_de_datos_tmodulo_endiseg_2021/catalogos/p7_1.csv\") %>% clean_names()\n\nRows: 2 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): descrip\ndbl (1): cve\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nVamos a etiquetar hoy los valores\n\nendiseg2021 %<>% \n  mutate(p7_1=sjlabelled::set_labels(p7_1, labels = labels_p7_1$descrip))\n\nRevisamos que tengamos el atributo\n\nglimpse(endiseg2021$p7_1)\n\n num [1:152497] 1 NA 2 NA NA 2 NA NA NA 2 ...\n - attr(*, \"label\")= chr \"P7.1 ¿Cuál es su sexo asignado al nacer?\"\n - attr(*, \"labels\")= Named num [1:2] 1 2\n  ..- attr(*, \"names\")= chr [1:2] \"Hombre\" \"Mujer\""
  },
  {
    "objectID": "t2_endiseg2021.html#tabulados",
    "href": "t2_endiseg2021.html#tabulados",
    "title": "T2: ENDISEG 2021",
    "section": "Tabulados",
    "text": "Tabulados\n\nTabulados con {janitor}\nSin factores de expansión este es un gran comando.\n\nendiseg2021 %>% \n  filter(seleccionade==1) %>% \n  mutate(p7_1=as_label(p7_1)) %>% \n  janitor::tabyl(p7_1) %>% \n  janitor::adorn_totals() %>% \n  janitor::adorn_pct_formatting(digits=2)\n\n   p7_1     n percent\n Hombre 20102  45.49%\n  Mujer 24087  54.51%\n  Total 44189 100.00%\n\n\nVamos a utilizar una segunda variable\n\ndicc_tmodulo %>% \n  filter(nemonico==\"p8_1\") %>% \n  select(nombre_campo) -> label_p8_1\n\nendiseg2021 %<>% \n  mutate(p8_1=sjlabelled::set_label(p8_1, label=label_p8_1$nombre_campo))\n\n\nlabels_p8_1 <- read_csv(\"data_t2/conjunto_de_datos_endiseg_2021_csv/conjunto_de_datos_tmodulo_endiseg_2021/catalogos/p8_1.csv\", locale = locale(encoding = \"latin1\")) %>% clean_names()\n\nRows: 6 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): descrip\ndbl (1): cve\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nendiseg2021 %<>% \n  mutate(p8_1=sjlabelled::set_labels(p8_1, labels = labels_p8_1$descrip))\n\n\nendiseg2021 %>% \n  filter(seleccionade==1) %>% \n  mutate(p7_1=as_label(p7_1)) %>% \n  mutate(p8_1=as_label(p8_1)) %>% \n  janitor::tabyl(p8_1, p7_1) %>% \n  janitor::adorn_totals(where=c(\"row\", \"col\")) %>% \n  janitor::adorn_percentages(\"col\") %>% \n  janitor::adorn_pct_formatting(digits=2)\n\n                                                 p8_1  Hombre   Mujer   Total\n   Una mujer a la que le gustan solamente las mujeres   0.35%   0.71%   0.55%\n     Un hombre al que le gustan solamente los hombres   2.77%   0.54%   1.56%\n Una persona que le gustan tanto hombres como mujeres   1.09%   3.78%   2.56%\n        Una mujer que le gustan solamente los hombres   0.23%  94.67%  51.71%\n        Un hombre que le gustan solamente las mujeres  95.23%   0.11%  43.38%\n                                 Con otra orientación   0.31%   0.20%   0.25%\n                                                Total 100.00% 100.00% 100.00%\n\n\n\n\nTabulados con {pollster}\nPodemos incluir el factor de expansión\n\nendiseg2021 %>% \n  filter(seleccionade==1) %>% \n  mutate(p7_1=as_label(p7_1)) %>% \n  pollster::topline(p7_1, weight = factor) \n\n# A tibble: 2 × 5\n  Response Frequency Percent `Valid Percent` `Cumulative Percent`\n  <fct>        <dbl>   <dbl>           <dbl>                <dbl>\n1 Hombre    16576979    45.1            45.1                 45.1\n2 Mujer     20181192    54.9            54.9                100  \n\n\n\nendiseg2021 %>% \n  filter(seleccionade==1) %>% \n  mutate(p7_1=as_label(p7_1)) %>% \n  pollster::moe_topline(p7_1, weight = factor) # margin of error\n\n# A tibble: 2 × 6\n  Response Frequency Percent `Valid Percent`   MOE `Cumulative Percent`\n  <fct>        <dbl>   <dbl>           <dbl> <dbl>                <dbl>\n1 Hombre    16576979    45.1            45.1 0.631                 45.1\n2 Mujer     20181192    54.9            54.9 0.631                100  \n\n\nDoble entrada\n\nendiseg2021 %>% \n  filter(seleccionade==1) %>% \n  mutate(p7_1=as_label(p7_1)) %>% \n  mutate(p8_1=as_label(p8_1)) %>% \n  pollster::crosstab(p8_1, p7_1, weight = factor, pct_type = \"col\") \n\n# A tibble: 7 × 3\n  p8_1                                                       Hombre        Mujer\n  <chr>                                                       <dbl>        <dbl>\n1 Una mujer a la que le gustan solamente las mujeres          0.276        0.688\n2 Un hombre al que le gustan solamente los hombres            2.46         0.495\n3 Una persona que le gustan tanto hombres como mujeres        0.923        3.45 \n4 Una mujer que le gustan solamente los hombres               0.214       95.1  \n5 Un hombre que le gustan solamente las mujeres              95.8          0.100\n6 Con otra orientación                                        0.285        0.163\n7 n                                                    16576979     20181192    \n\n\n\nendiseg2021 %>% \n  filter(seleccionade==1) %>% \n  mutate(p7_1=as_label(p7_1)) %>% \n  mutate(p8_1=as_label(p8_1)) %>% \n  pollster::moe_crosstab(p8_1, p7_1, weight = factor) \n\n# A tibble: 12 × 5\n   p8_1                                              p7_1     pct     moe      n\n   <fct>                                             <fct>  <dbl>   <dbl>  <dbl>\n 1 Una mujer a la que le gustan solamente las mujer… Homb… 24.8    7.41   1.85e5\n 2 Una mujer a la que le gustan solamente las mujer… Mujer 75.2    7.41   1.85e5\n 3 Un hombre al que le gustan solamente los hombres  Homb… 80.3    4.04   5.08e5\n 4 Un hombre al que le gustan solamente los hombres  Mujer 19.7    4.04   5.08e5\n 5 Una persona que le gustan tanto hombres como muj… Homb… 18.0    3.05   8.50e5\n 6 Una persona que le gustan tanto hombres como muj… Mujer 82.0    3.05   8.50e5\n 7 Una mujer que le gustan solamente los hombres     Homb…  0.184  0.0756 1.92e7\n 8 Una mujer que le gustan solamente los hombres     Mujer 99.8    0.0756 1.92e7\n 9 Un hombre que le gustan solamente las mujeres     Homb… 99.9    0.0686 1.59e7\n10 Un hombre que le gustan solamente las mujeres     Mujer  0.127  0.0686 1.59e7\n11 Con otra orientación                              Homb… 59.0   12.6    8.01e4\n12 Con otra orientación                              Mujer 41.0   12.6    8.01e4"
  },
  {
    "objectID": "t2_endiseg2021.html#diseño-muestral",
    "href": "t2_endiseg2021.html#diseño-muestral",
    "title": "T2: ENDISEG 2021",
    "section": "Diseño muestral",
    "text": "Diseño muestral\n\nendiseg_svyr <- endiseg2021 %>%\n  select(upm_dis, est_dis, factor, seleccionade, p7_1, p8_1, p4_1) %>% \n  srvyr::as_survey_design(\n    upm = upm_dis, \n    strata = est_dis,\n    weights = factor,\n    nest = TRUE)\n\nPara una media ponderada\n\nendiseg_svyr %>%\n  filter(seleccionade==1) %>% \n  summarise(\n    media_ponderada = survey_mean(p4_1, na.rm=T))\n\n# A tibble: 1 × 2\n  media_ponderada media_ponderada_se\n            <dbl>              <dbl>\n1            43.2              0.113\n\n\nSi queremos los intervalos de confianza:\n\nendiseg_svyr %>%\n  filter(seleccionade==1) %>% \n  summarise(\n    media_ponderada = survey_mean(p4_1, na.rm=T, vartype=\"ci\"))\n\n# A tibble: 1 × 3\n  media_ponderada media_ponderada_low media_ponderada_upp\n            <dbl>               <dbl>               <dbl>\n1            43.2                43.0                43.5\n\n\nEsto se puede tardar\n\nendiseg_svyr %>%\n  filter(seleccionade==1) %>% \n  mutate(p8_1=as_label(p8_1)) %>% \n  group_by(p8_1) %>% \n  summarise(\n    media_ponderada = survey_mean(p4_1, na.rm=T, vartype=\"ci\"))\n\n# A tibble: 6 × 4\n  p8_1                   media_ponderada media_ponderada_low media_ponderada_upp\n  <fct>                            <dbl>               <dbl>               <dbl>\n1 Una mujer a la que le…            36.7                34.0                39.3\n2 Un hombre al que le g…            32.2                30.9                33.5\n3 Una persona que le gu…            25.5                24.8                26.3\n4 Una mujer que le gust…            44.5                44.2                44.8\n5 Un hombre que le gust…            43.2                42.9                43.5\n6 Con otra orientación              28.0                25.0                31.0\n\n\n\nendiseg_svyr %>%\n  filter(seleccionade==1) %>% \n  mutate(p8_1=as_label(p8_1)) %>% \n  group_by(p8_1) %>% #variables cuali\n  summarise(proportion = survey_mean())\n\n# A tibble: 6 × 3\n  p8_1                                                 proportion proportion_se\n  <fct>                                                     <dbl>         <dbl>\n1 Una mujer a la que le gustan solamente las mujeres      0.00502      0.000425\n2 Un hombre al que le gustan solamente los hombres        0.0138       0.000679\n3 Una persona que le gustan tanto hombres como mujeres    0.0231       0.000924\n4 Una mujer que le gustan solamente los hombres           0.523        0.00323 \n5 Un hombre que le gustan solamente las mujeres           0.433        0.00321 \n6 Con otra orientación                                    0.00218      0.000275"
  },
  {
    "objectID": "t1_cacenso.html",
    "href": "t1_cacenso.html",
    "title": "T1: Cuestionario Ampliado",
    "section": "",
    "text": "Aquí dejo la presentación\n\n\n\n\n\nEn esta liga puedes descarga el proyecto de trabajo. De esta manera no tendremos problemas con las rutas relativas.\nhttps://tinyurl.com/demos-talleres"
  },
  {
    "objectID": "t1_cacenso.html#video-de-la-sesión",
    "href": "t1_cacenso.html#video-de-la-sesión",
    "title": "T1: Cuestionario Ampliado",
    "section": "Video de la sesión",
    "text": "Video de la sesión\n\n\n\n\nPaquetes\n\nif (!require(\"pacman\")) install.packages(\"pacman\") # instala pacman si se requiere\n\nLoading required package: pacman\n\npacman::p_load(tidyverse,\n               haven, \n               readr,\n               foreign,\n               janitor) #carga los paquetes necesarios"
  },
  {
    "objectID": "t1_cacenso.html#importación-de-datos",
    "href": "t1_cacenso.html#importación-de-datos",
    "title": "T1: Cuestionario Ampliado",
    "section": "Importación de datos",
    "text": "Importación de datos\nRecuerdo que se debe revisar la documentación\nhttps://www.inegi.org.mx/programas/ccpv/2020/#Microdatos\n\nDesde .csv\nLos archivos “.csv” son archivos separados por comas. Los podemos abrir con un bloc de notas para revisar\nHay dos comandos que nos permiten importar archivos de texto, el de base read.csv() y readr::read_csv()\n\nviviendas01 <- read.csv(\"data_t1/Viviendas01.CSV\")\n\nrevisemos los nombres y las primeres 6 líneas\n\nnames(viviendas01)\n\n [1] \"ENT\"              \"MUN\"              \"LOC50K\"           \"ID_VIV\"          \n [5] \"COBERTURA\"        \"ESTRATO\"          \"UPM\"              \"FACTOR\"          \n [9] \"CLAVIVP\"          \"PAREDES\"          \"TECHOS\"           \"PISOS\"           \n[13] \"COCINA\"           \"CUADORM\"          \"TOTCUART\"         \"LUG_COC\"         \n[17] \"COMBUSTIBLE\"      \"ESTUFA\"           \"ELECTRICIDAD\"     \"FOCOS\"           \n[21] \"FOCOS_AHORRA\"     \"AGUA_ENTUBADA\"    \"ABA_AGUA_ENTU\"    \"ABA_AGUA_NO_ENTU\"\n[25] \"TINACO\"           \"CISTERNA\"         \"BOMBA_AGUA\"       \"REGADERA\"        \n[29] \"BOILER\"           \"CALENTADOR_SOLAR\" \"AIRE_ACON\"        \"PANEL_SOLAR\"     \n[33] \"SERSAN\"           \"CONAGUA\"          \"USOEXC\"           \"DRENAJE\"         \n[37] \"SEPARACION1\"      \"SEPARACION2\"      \"SEPARACION3\"      \"SEPARACION4\"     \n[41] \"DESTINO_BAS\"      \"REFRIGERADOR\"     \"LAVADORA\"         \"HORNO\"           \n[45] \"AUTOPROP\"         \"MOTOCICLETA\"      \"BICICLETA\"        \"RADIO\"           \n[49] \"TELEVISOR\"        \"COMPUTADORA\"      \"TELEFONO\"         \"CELULAR\"         \n[53] \"INTERNET\"         \"SERV_TV_PAGA\"     \"SERV_PEL_PAGA\"    \"CON_VJUEGOS\"     \n[57] \"TENENCIA\"         \"ESCRITURAS\"       \"FORMA_ADQUI\"      \"FINANCIAMIENTO1\" \n[61] \"FINANCIAMIENTO2\"  \"FINANCIAMIENTO3\"  \"DEUDA\"            \"NUMPERS\"         \n[65] \"DUE1_NUM\"         \"DUE2_NUM\"         \"MCONMIG\"          \"MNUMPERS\"        \n[69] \"INGR_PEROTROPAIS\" \"INGR_PERDENTPAIS\" \"INGR_AYUGOB\"      \"INGR_JUBPEN\"     \n[73] \"ALIMENTACION\"     \"ALIM_ADL1\"        \"ALIM_ADL2\"        \"ING_ALIM_ADL1\"   \n[77] \"ING_ALIM_ADL2\"    \"ING_ALIM_ADL3\"    \"TIPOHOG\"          \"INGTRHOG\"        \n[81] \"JEFE_SEXO\"        \"JEFE_EDAD\"        \"TAMLOC\"          \n\nhead(viviendas01)\n\n  ENT MUN LOC50K    ID_VIV COBERTURA        ESTRATO UPM FACTOR CLAVIVP PAREDES\n1   1   1      1 1.001e+10         2 01-001-0001-00   1     59       1       8\n2   1   1      1 1.001e+10         2 01-001-0001-00   1     59       1       8\n3   1   1      1 1.001e+10         2 01-001-0001-00   1     59       1       8\n4   1   1      1 1.001e+10         2 01-001-0001-00   1     59       1       8\n5   1   1      1 1.001e+10         2 01-001-0001-00   1     59       1       8\n6   1   1      1 1.001e+10         2 01-001-0001-00   1     59       1       8\n  TECHOS PISOS COCINA CUADORM TOTCUART LUG_COC COMBUSTIBLE ESTUFA ELECTRICIDAD\n1     10     3      1       3        5       1           2     NA            1\n2     10     3      1       3        6       1           2     NA            1\n3     10     3      1       1        2       1           2     NA            1\n4     10     3      1       2        6       1           2     NA            1\n5     10     3      1       3        4       1           2     NA            1\n6     10     3      1       3        4       1           2     NA            1\n  FOCOS FOCOS_AHORRA AGUA_ENTUBADA ABA_AGUA_ENTU ABA_AGUA_NO_ENTU TINACO\n1    25           25             1             1               NA      1\n2    15           15             1             1               NA      2\n3    10           10             1             1               NA      2\n4    18           18             1             1               NA      2\n5    16           16             1             1               NA      2\n6    42           42             1             1               NA      1\n  CISTERNA BOMBA_AGUA REGADERA BOILER CALENTADOR_SOLAR AIRE_ACON PANEL_SOLAR\n1        3          5        7      1                3         6           8\n2        3          5        7      2                3         6           8\n3        3          5        7      1                3         5           8\n4        3          5        7      1                3         6           8\n5        3          5        7      2                3         6           8\n6        3          5        7      1                4         5           8\n  SERSAN CONAGUA USOEXC DRENAJE SEPARACION1 SEPARACION2 SEPARACION3 SEPARACION4\n1      1       1      3       1           1           4           6           8\n2      1       1      3       1           2           4           5           8\n3      1       1      3       1           2           4           6           8\n4      1       1      3       1           2           4           6           7\n5      1       1      3       1           1           4           6           8\n6      1       1      3       1           2           4           6           8\n  DESTINO_BAS REFRIGERADOR LAVADORA HORNO AUTOPROP MOTOCICLETA BICICLETA RADIO\n1           1            1        3     5        7           2         4     6\n2           1            1        3     5        7           2         4     5\n3           1            1        3     5        7           2         4     5\n4           1            1        3     5        7           2         4     5\n5           1            1        3     5        7           2         4     5\n6           1            1        3     5        7           2         4     5\n  TELEVISOR COMPUTADORA TELEFONO CELULAR INTERNET SERV_TV_PAGA SERV_PEL_PAGA\n1         7           1        3       5        7            1             3\n2         7           1        3       5        7            1             3\n3         7           1        4       5        7            2             3\n4         7           1        4       5        7            1             4\n5         7           1        3       5        7            1             3\n6         7           1        3       5        7            1             3\n  CON_VJUEGOS TENENCIA ESCRITURAS FORMA_ADQUI FINANCIAMIENTO1 FINANCIAMIENTO2\n1           6        1          1           2               6              NA\n2           5        1          1           2               8              NA\n3           6        1          1           2               8              NA\n4           5        1          1           1               5              NA\n5           5        1          1           1               5              NA\n6           5        1          1           1               5              NA\n  FINANCIAMIENTO3 DEUDA NUMPERS DUE1_NUM DUE2_NUM MCONMIG MNUMPERS\n1              NA     2       3        1       NA       3       NA\n2              NA    NA       4        1       NA       3       NA\n3              NA    NA       1        1       NA       3       NA\n4              NA     2       3        1       NA       3       NA\n5              NA     2       4        1       NA       3       NA\n6              NA     2       4        1       NA       3       NA\n  INGR_PEROTROPAIS INGR_PERDENTPAIS INGR_AYUGOB INGR_JUBPEN ALIMENTACION\n1                2                4           6           7            3\n2                2                4           6           8            3\n3                2                4           6           8            3\n4                2                4           6           8            3\n5                2                4           6           8            3\n6                2                4           6           8            3\n  ALIM_ADL1 ALIM_ADL2 ING_ALIM_ADL1 ING_ALIM_ADL2 ING_ALIM_ADL3 TIPOHOG\n1         2         4             2             4             6       1\n2         2         4             2             4             6       1\n3         2         4             2             4             6       5\n4         2         4             2             4             6       1\n5         2         4             2             4             6       1\n6         2         4             2             4             6       1\n  INGTRHOG JEFE_SEXO JEFE_EDAD TAMLOC\n1       NA         3        55      5\n2    30100         1        45      5\n3    20000         1        60      5\n4    66000         1        62      5\n5    25000         1        52      5\n6    50000         1        40      5\n\n\n\nviviendas01 <- read_csv(\"data_t1/Viviendas01.CSV\")\n\nRows: 24349 Columns: 83\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (10): ENT, MUN, LOC50K, ID_VIV, ESTRATO, UPM, CLAVIVP, TECHOS, DUE1_NUM,...\ndbl (73): COBERTURA, FACTOR, PAREDES, PISOS, COCINA, CUADORM, TOTCUART, LUG_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nnames(viviendas01)\n\n [1] \"ENT\"              \"MUN\"              \"LOC50K\"           \"ID_VIV\"          \n [5] \"COBERTURA\"        \"ESTRATO\"          \"UPM\"              \"FACTOR\"          \n [9] \"CLAVIVP\"          \"PAREDES\"          \"TECHOS\"           \"PISOS\"           \n[13] \"COCINA\"           \"CUADORM\"          \"TOTCUART\"         \"LUG_COC\"         \n[17] \"COMBUSTIBLE\"      \"ESTUFA\"           \"ELECTRICIDAD\"     \"FOCOS\"           \n[21] \"FOCOS_AHORRA\"     \"AGUA_ENTUBADA\"    \"ABA_AGUA_ENTU\"    \"ABA_AGUA_NO_ENTU\"\n[25] \"TINACO\"           \"CISTERNA\"         \"BOMBA_AGUA\"       \"REGADERA\"        \n[29] \"BOILER\"           \"CALENTADOR_SOLAR\" \"AIRE_ACON\"        \"PANEL_SOLAR\"     \n[33] \"SERSAN\"           \"CONAGUA\"          \"USOEXC\"           \"DRENAJE\"         \n[37] \"SEPARACION1\"      \"SEPARACION2\"      \"SEPARACION3\"      \"SEPARACION4\"     \n[41] \"DESTINO_BAS\"      \"REFRIGERADOR\"     \"LAVADORA\"         \"HORNO\"           \n[45] \"AUTOPROP\"         \"MOTOCICLETA\"      \"BICICLETA\"        \"RADIO\"           \n[49] \"TELEVISOR\"        \"COMPUTADORA\"      \"TELEFONO\"         \"CELULAR\"         \n[53] \"INTERNET\"         \"SERV_TV_PAGA\"     \"SERV_PEL_PAGA\"    \"CON_VJUEGOS\"     \n[57] \"TENENCIA\"         \"ESCRITURAS\"       \"FORMA_ADQUI\"      \"FINANCIAMIENTO1\" \n[61] \"FINANCIAMIENTO2\"  \"FINANCIAMIENTO3\"  \"DEUDA\"            \"NUMPERS\"         \n[65] \"DUE1_NUM\"         \"DUE2_NUM\"         \"MCONMIG\"          \"MNUMPERS\"        \n[69] \"INGR_PEROTROPAIS\" \"INGR_PERDENTPAIS\" \"INGR_AYUGOB\"      \"INGR_JUBPEN\"     \n[73] \"ALIMENTACION\"     \"ALIM_ADL1\"        \"ALIM_ADL2\"        \"ING_ALIM_ADL1\"   \n[77] \"ING_ALIM_ADL2\"    \"ING_ALIM_ADL3\"    \"TIPOHOG\"          \"INGTRHOG\"        \n[81] \"JEFE_SEXO\"        \"JEFE_EDAD\"        \"TAMLOC\"          \n\nhead(viviendas01)\n\n# A tibble: 6 × 83\n  ENT   MUN   LOC50K ID_VIV       COBERTURA ESTRATO UPM   FACTOR CLAVIVP PAREDES\n  <chr> <chr> <chr>  <chr>            <dbl> <chr>   <chr>  <dbl> <chr>     <dbl>\n1 01    001   0001   010010000001         2 01-001… 00001     59 01            8\n2 01    001   0001   010010000002         2 01-001… 00001     59 01            8\n3 01    001   0001   010010000003         2 01-001… 00001     59 01            8\n4 01    001   0001   010010000004         2 01-001… 00001     59 01            8\n5 01    001   0001   010010000005         2 01-001… 00001     59 01            8\n6 01    001   0001   010010000006         2 01-001… 00001     59 01            8\n# ℹ 73 more variables: TECHOS <chr>, PISOS <dbl>, COCINA <dbl>, CUADORM <dbl>,\n#   TOTCUART <dbl>, LUG_COC <dbl>, COMBUSTIBLE <dbl>, ESTUFA <dbl>,\n#   ELECTRICIDAD <dbl>, FOCOS <dbl>, FOCOS_AHORRA <dbl>, AGUA_ENTUBADA <dbl>,\n#   ABA_AGUA_ENTU <dbl>, ABA_AGUA_NO_ENTU <dbl>, TINACO <dbl>, CISTERNA <dbl>,\n#   BOMBA_AGUA <dbl>, REGADERA <dbl>, BOILER <dbl>, CALENTADOR_SOLAR <dbl>,\n#   AIRE_ACON <dbl>, PANEL_SOLAR <dbl>, SERSAN <dbl>, CONAGUA <dbl>,\n#   USOEXC <dbl>, DRENAJE <dbl>, SEPARACION1 <dbl>, SEPARACION2 <dbl>, …\n\n\n\n\nDesde SAS\n\nviviendas01 <- haven::read_sas(\"data_t1/viviendas01.sas7bdat\")\n\nnames(viviendas01)\n\n [1] \"ENT\"              \"MUN\"              \"LOC50K\"           \"ID_VIV\"          \n [5] \"COBERTURA\"        \"ESTRATO\"          \"UPM\"              \"FACTOR\"          \n [9] \"CLAVIVP\"          \"PAREDES\"          \"TECHOS\"           \"PISOS\"           \n[13] \"COCINA\"           \"CUADORM\"          \"TOTCUART\"         \"LUG_COC\"         \n[17] \"COMBUSTIBLE\"      \"ESTUFA\"           \"ELECTRICIDAD\"     \"FOCOS\"           \n[21] \"FOCOS_AHORRA\"     \"AGUA_ENTUBADA\"    \"ABA_AGUA_ENTU\"    \"ABA_AGUA_NO_ENTU\"\n[25] \"TINACO\"           \"CISTERNA\"         \"BOMBA_AGUA\"       \"REGADERA\"        \n[29] \"BOILER\"           \"CALENTADOR_SOLAR\" \"AIRE_ACON\"        \"PANEL_SOLAR\"     \n[33] \"SERSAN\"           \"CONAGUA\"          \"USOEXC\"           \"DRENAJE\"         \n[37] \"SEPARACION1\"      \"SEPARACION2\"      \"SEPARACION3\"      \"SEPARACION4\"     \n[41] \"DESTINO_BAS\"      \"REFRIGERADOR\"     \"LAVADORA\"         \"HORNO\"           \n[45] \"AUTOPROP\"         \"MOTOCICLETA\"      \"BICICLETA\"        \"RADIO\"           \n[49] \"TELEVISOR\"        \"COMPUTADORA\"      \"TELEFONO\"         \"CELULAR\"         \n[53] \"INTERNET\"         \"SERV_TV_PAGA\"     \"SERV_PEL_PAGA\"    \"CON_VJUEGOS\"     \n[57] \"TENENCIA\"         \"ESCRITURAS\"       \"FORMA_ADQUI\"      \"FINANCIAMIENTO1\" \n[61] \"FINANCIAMIENTO2\"  \"FINANCIAMIENTO3\"  \"DEUDA\"            \"NUMPERS\"         \n[65] \"DUE1_NUM\"         \"DUE2_NUM\"         \"MCONMIG\"          \"MNUMPERS\"        \n[69] \"INGR_PEROTROPAIS\" \"INGR_PERDENTPAIS\" \"INGR_AYUGOB\"      \"INGR_JUBPEN\"     \n[73] \"ALIMENTACION\"     \"ALIM_ADL1\"        \"ALIM_ADL2\"        \"ING_ALIM_ADL1\"   \n[77] \"ING_ALIM_ADL2\"    \"ING_ALIM_ADL3\"    \"TIPOHOG\"          \"INGTRHOG\"        \n[81] \"JEFE_SEXO\"        \"JEFE_EDAD\"        \"TAMLOC\"          \n\nhead(viviendas01)\n\n# A tibble: 6 × 83\n  ENT   MUN   LOC50K ID_VIV       COBERTURA ESTRATO UPM   FACTOR CLAVIVP PAREDES\n  <chr> <chr> <chr>  <chr>        <chr>     <chr>   <chr>  <dbl> <chr>   <chr>  \n1 01    001   0001   010010000001 2         01-001… 00001     59 01      8      \n2 01    001   0001   010010000002 2         01-001… 00001     59 01      8      \n3 01    001   0001   010010000003 2         01-001… 00001     59 01      8      \n4 01    001   0001   010010000004 2         01-001… 00001     59 01      8      \n5 01    001   0001   010010000005 2         01-001… 00001     59 01      8      \n6 01    001   0001   010010000006 2         01-001… 00001     59 01      8      \n# ℹ 73 more variables: TECHOS <chr>, PISOS <chr>, COCINA <chr>, CUADORM <dbl>,\n#   TOTCUART <dbl>, LUG_COC <chr>, COMBUSTIBLE <chr>, ESTUFA <chr>,\n#   ELECTRICIDAD <chr>, FOCOS <dbl>, FOCOS_AHORRA <dbl>, AGUA_ENTUBADA <chr>,\n#   ABA_AGUA_ENTU <chr>, ABA_AGUA_NO_ENTU <chr>, TINACO <chr>, CISTERNA <chr>,\n#   BOMBA_AGUA <chr>, REGADERA <chr>, BOILER <chr>, CALENTADOR_SOLAR <chr>,\n#   AIRE_ACON <chr>, PANEL_SOLAR <chr>, SERSAN <chr>, CONAGUA <chr>,\n#   USOEXC <chr>, DRENAJE <chr>, SEPARACION1 <chr>, SEPARACION2 <chr>, …\n\n\n\n\nDesde .dta\n\nviviendas01 <- haven::read_dta(\"data_t1/Viviendas01.dta\")\n\n\n\nDesde .sav\n\nviviendas01 <- haven::read_sav(\"data_t1/Viviendas01.sav\")"
  },
  {
    "objectID": "t1_cacenso.html#fusionado-de-datos",
    "href": "t1_cacenso.html#fusionado-de-datos",
    "title": "T1: Cuestionario Ampliado",
    "section": "Fusionado de datos",
    "text": "Fusionado de datos\nPara ello vamos a importar también la base de personas\n\npersonas01 <- haven::read_sav(\"data_t1/Personas01.SAV\")\n\nVeamos las dimensiones de estas tablas\n\ndim(viviendas01)\n\n[1] 24349    83\n\ndim(personas01)\n\n[1] 95983    91\n\n\nCon el INEGI no hay problema, pero bien vale revisar los id sean únicos:\n\nviviendas01 %>% \n  janitor::get_dupes(ID_VIV)\n\nNo duplicate combinations found of: ID_VIV\n\n\n# A tibble: 0 × 84\n# ℹ 84 variables: ID_VIV <chr>, dupe_count <int>, ENT <chr+lbl>, MUN <chr>,\n#   LOC50K <chr>, COBERTURA <chr+lbl>, ESTRATO <chr>, UPM <chr>, FACTOR <dbl>,\n#   CLAVIVP <chr+lbl>, PAREDES <chr+lbl>, TECHOS <chr+lbl>, PISOS <chr+lbl>,\n#   COCINA <chr+lbl>, CUADORM <dbl+lbl>, TOTCUART <dbl+lbl>, LUG_COC <chr+lbl>,\n#   COMBUSTIBLE <chr+lbl>, ESTUFA <chr+lbl>, ELECTRICIDAD <chr+lbl>,\n#   FOCOS <dbl+lbl>, FOCOS_AHORRA <dbl+lbl>, AGUA_ENTUBADA <chr+lbl>,\n#   ABA_AGUA_ENTU <chr+lbl>, ABA_AGUA_NO_ENTU <chr+lbl>, TINACO <chr+lbl>, …\n\npersonas01 %>% \n  janitor::get_dupes(ID_PERSONA)\n\nNo duplicate combinations found of: ID_PERSONA\n\n\n# A tibble: 0 × 92\n# ℹ 92 variables: ID_PERSONA <chr>, dupe_count <int>, ENT <chr+lbl>, MUN <chr>,\n#   LOC50K <chr>, ID_VIV <chr>, COBERTURA <chr+lbl>, ESTRATO <chr>, UPM <chr>,\n#   FACTOR <dbl>, CLAVIVP <chr+lbl>, NUMPER <chr>, SEXO <chr+lbl>,\n#   EDAD <dbl+lbl>, PARENTESCO <chr+lbl>, IDENT_MADRE <chr+lbl>,\n#   IDENT_PADRE <chr+lbl>, ENT_PAIS_NAC <chr+lbl>, NACIONALIDAD <chr+lbl>,\n#   SERSALUD <chr+lbl>, AFRODES <chr+lbl>, REGIS_NAC <chr+lbl>,\n#   DHSERSAL1 <chr+lbl>, DHSERSAL2 <chr+lbl>, RELIGION <chr+lbl>, …\n\n\n\nCon merge()\n\nCasos en ambas bases\nPor default, el comando tiene activado la opción “all = FALSE”, que nos deja los datos de ambas bases comunes. (tipo una intersección)\n\ncacenso01<-merge(viviendas01, \n                 personas01,\n                 by=\"ID_VIV\", \n                 all = F)\ndim(cacenso01)\n\n[1] 95983   173\n\n\n\nnames(cacenso01)\n\n  [1] \"ID_VIV\"             \"ENT.x\"              \"MUN.x\"             \n  [4] \"LOC50K.x\"           \"COBERTURA.x\"        \"ESTRATO.x\"         \n  [7] \"UPM.x\"              \"FACTOR.x\"           \"CLAVIVP.x\"         \n [10] \"PAREDES\"            \"TECHOS\"             \"PISOS\"             \n [13] \"COCINA\"             \"CUADORM\"            \"TOTCUART\"          \n [16] \"LUG_COC\"            \"COMBUSTIBLE\"        \"ESTUFA\"            \n [19] \"ELECTRICIDAD\"       \"FOCOS\"              \"FOCOS_AHORRA\"      \n [22] \"AGUA_ENTUBADA\"      \"ABA_AGUA_ENTU\"      \"ABA_AGUA_NO_ENTU\"  \n [25] \"TINACO\"             \"CISTERNA\"           \"BOMBA_AGUA\"        \n [28] \"REGADERA\"           \"BOILER\"             \"CALENTADOR_SOLAR\"  \n [31] \"AIRE_ACON\"          \"PANEL_SOLAR\"        \"SERSAN\"            \n [34] \"CONAGUA\"            \"USOEXC\"             \"DRENAJE\"           \n [37] \"SEPARACION1\"        \"SEPARACION2\"        \"SEPARACION3\"       \n [40] \"SEPARACION4\"        \"DESTINO_BAS\"        \"REFRIGERADOR\"      \n [43] \"LAVADORA\"           \"HORNO\"              \"AUTOPROP\"          \n [46] \"MOTOCICLETA\"        \"BICICLETA\"          \"RADIO\"             \n [49] \"TELEVISOR\"          \"COMPUTADORA\"        \"TELEFONO\"          \n [52] \"CELULAR\"            \"INTERNET\"           \"SERV_TV_PAGA\"      \n [55] \"SERV_PEL_PAGA\"      \"CON_VJUEGOS\"        \"TENENCIA\"          \n [58] \"ESCRITURAS\"         \"FORMA_ADQUI\"        \"FINANCIAMIENTO1\"   \n [61] \"FINANCIAMIENTO2\"    \"FINANCIAMIENTO3\"    \"DEUDA\"             \n [64] \"NUMPERS\"            \"DUE1_NUM\"           \"DUE2_NUM\"          \n [67] \"MCONMIG\"            \"MNUMPERS\"           \"INGR_PEROTROPAIS\"  \n [70] \"INGR_PERDENTPAIS\"   \"INGR_AYUGOB\"        \"INGR_JUBPEN\"       \n [73] \"ALIMENTACION\"       \"ALIM_ADL1\"          \"ALIM_ADL2\"         \n [76] \"ING_ALIM_ADL1\"      \"ING_ALIM_ADL2\"      \"ING_ALIM_ADL3\"     \n [79] \"TIPOHOG\"            \"INGTRHOG\"           \"JEFE_SEXO\"         \n [82] \"JEFE_EDAD\"          \"TAMLOC.x\"           \"ENT.y\"             \n [85] \"MUN.y\"              \"LOC50K.y\"           \"ID_PERSONA\"        \n [88] \"COBERTURA.y\"        \"ESTRATO.y\"          \"UPM.y\"             \n [91] \"FACTOR.y\"           \"CLAVIVP.y\"          \"NUMPER\"            \n [94] \"SEXO\"               \"EDAD\"               \"PARENTESCO\"        \n [97] \"IDENT_MADRE\"        \"IDENT_PADRE\"        \"ENT_PAIS_NAC\"      \n[100] \"NACIONALIDAD\"       \"SERSALUD\"           \"AFRODES\"           \n[103] \"REGIS_NAC\"          \"DHSERSAL1\"          \"DHSERSAL2\"         \n[106] \"RELIGION\"           \"DIS_VER\"            \"DIS_OIR\"           \n[109] \"DIS_CAMINAR\"        \"DIS_RECORDAR\"       \"DIS_BANARSE\"       \n[112] \"DIS_HABLAR\"         \"DIS_MENTAL\"         \"CAU_VER\"           \n[115] \"CAU_OIR\"            \"CAU_CAMINAR\"        \"CAU_RECORDAR\"      \n[118] \"CAU_BANARSE\"        \"CAU_HABLAR\"         \"CAU_MENTAL\"        \n[121] \"HLENGUA\"            \"QDIALECT_INALI\"     \"HESPANOL\"          \n[124] \"ELENGUA\"            \"PERTE_INDIGENA\"     \"ASISTEN\"           \n[127] \"MUN_ASI\"            \"ENT_PAIS_ASI\"       \"TIE_TRASLADO_ESCU\" \n[130] \"MED_TRASLADO_ESC1\"  \"MED_TRASLADO_ESC2\"  \"MED_TRASLADO_ESC3\" \n[133] \"NIVACAD\"            \"ESCOLARI\"           \"NOMCAR_C\"          \n[136] \"ALFABET\"            \"ESCOACUM\"           \"ENT_PAIS_RES_5A\"   \n[139] \"MUN_RES_5A\"         \"CAUSA_MIG_V\"        \"SITUA_CONYUGAL\"    \n[142] \"IDENT_PAREJA\"       \"CONACT\"             \"OCUPACION_C\"       \n[145] \"SITTRA\"             \"AGUINALDO\"          \"VACACIONES\"        \n[148] \"SERVICIO_MEDICO\"    \"UTILIDADES\"         \"INCAP_SUELDO\"      \n[151] \"SAR_AFORE\"          \"CREDITO_VIVIENDA\"   \"INGTRMEN\"          \n[154] \"HORTRA\"             \"ACTIVIDADES_C\"      \"MUN_TRAB\"          \n[157] \"ENT_PAIS_TRAB\"      \"TIE_TRASLADO_TRAB\"  \"MED_TRASLADO_TRAB1\"\n[160] \"MED_TRASLADO_TRAB2\" \"MED_TRASLADO_TRAB3\" \"HIJOS_NAC_VIVOS\"   \n[163] \"HIJOS_FALLECIDOS\"   \"HIJOS_SOBREVIV\"     \"FECHA_NAC_M\"       \n[166] \"FECHA_NAC_A\"        \"SOBREVIVENCIA\"      \"IDENT_HIJO\"        \n[169] \"EDAD_MORIR_D\"       \"EDAD_MORIR_M\"       \"EDAD_MORIR_A\"      \n[172] \"EDAD_MORIR_TD\"      \"TAMLOC.y\"          \n\n\n\n\nTodos los casos\nSi cambiamos la opción “all = TRUE”, que nos deja los datos comunes a ambas bases. (como una unión)\n\ncacenso01<-merge(viviendas01,\n                   personas01, \n                   by=\"ID_VIV\", \n                   all = T)\ndim(cacenso01)\n\n[1] 95983   173\n\n\n\n\nCasos en la base 1\nSi queremos quedarnos con todos los datos que hay en la primera base, x, vamos a usar a opción all.x = TRUE.\n\ncacenso01<-merge(viviendas01, \n                   personas01,\n                   by=\"ID_VIV\", \n                   all.x  = TRUE)\ndim(cacenso01)\n\n[1] 95983   173\n\n\n\n\nCasos de la base 2\nNotamos que hoy sí tenemos los datos de toda la población y hay missings en las variables aportadas por la base de trabajo\nSi queremos lo contrario, quedarnos con los datos aportados por la segunda base, y, vamos a usar la opción all.y=TRUE\n\ncacenso01<-merge(viviendas01, \n                   personas01,\n                   by=\"ID_VIV\",\n                   all.y  = TRUE)\ndim(cacenso01)\n\n[1] 95983   173\n\n\n\n\n\nCon {dplyr}\nEl caso 1:\n\ncacenso01<-dplyr::inner_join(viviendas01,\n                               personas01,\n                               by=\"ID_VIV\")\ndim(cacenso01)\n\n[1] 95983   173\n\n\nEl caso 2:\n\ncacenso01<-dplyr::full_join(viviendas01, \n                              personas01, \n                              by=\"ID_VIV\")\ndim(cacenso01)\n\n[1] 95983   173\n\n\nEl caso 3:\n\ncacenso01<-dplyr::left_join(viviendas01,\n                              personas01, \n                              by=\"ID_VIV\")\ndim(cacenso01)\n\n[1] 95983   173\n\n\nEl caso 4:\n\ncacenso01<-dplyr::right_join(viviendas01, \n                               personas01,\n                               by=\"ID_VIV\")\ndim(cacenso01)\n\n[1] 95983   173\n\n\nTambién se puede usar con pipes, cualquier opción de dplyr\n\ncacenso01<-viviendas01 %>% # pongo el conjunto que será la \"izquierda\n  dplyr::right_join(personas01, \n                    by=\"ID_VIV\")\ndim(cacenso01)\n\n[1] 95983   173"
  },
  {
    "objectID": "t1_cacenso.html#agregar-casos",
    "href": "t1_cacenso.html#agregar-casos",
    "title": "T1: Cuestionario Ampliado",
    "section": "Agregar casos",
    "text": "Agregar casos\nSupongamos que queremos pegar la información de viviendas de Aguascalientes y Tlaxcala\n\nviviendas29 <- read_sav(\"data_t1/Viviendas29.SAV\")\n\n\nCon rbind()\n\nviviendas01_29<-rbind(viviendas01, viviendas29)\n\n\ntable(viviendas01_29$ENT)\n\n\n   01    29 \n24349 86142 \n\n\n\n\nCon dplyr::bind_rows\n\nviviendas01_29<-dplyr::bind_rows(viviendas01, viviendas29)"
  },
  {
    "objectID": "recursos.html#aquí-material-extra-de-interés",
    "href": "recursos.html#aquí-material-extra-de-interés",
    "title": "Recursos en línea",
    "section": "Aquí material extra de interés",
    "text": "Aquí material extra de interés\n\nLa bañera - Dinámica Demográfica\n\n\n\nEl censo de facto en Chile por 31 minutos\n\n\n\nDra. Victoria Prieto: Big Data y Migración"
  },
  {
    "objectID": "about.html#objetivos",
    "href": "about.html#objetivos",
    "title": "De qué vamos",
    "section": "Objetivos",
    "text": "Objetivos\nEl presente proyecto busca ampliar las estrategias práctico-didácticas para la enseñanza de la Sociodemografía en la Facultad de Ciencias Políticas y Sociales a partir de la creación de recursos didácticos en línea, el acercamiento del estudiantado con quienes desarrollan las investigaciones y la exploración de fuentes de información mexicana de reciente publicación.\nEllo implica, ampliar –por un lado– las estrategias que tienen que ver recursos orientados a la aplicación de las técnicas propias del análisis sociodemográfico; así como recursos que amplíen el análisis de los problemas sociales en México desde una perspectiva demográfica."
  },
  {
    "objectID": "about.html#qué-haremos",
    "href": "about.html#qué-haremos",
    "title": "De qué vamos",
    "section": "¿Qué haremos?",
    "text": "¿Qué haremos?\nPor ello se propone la creación de espacios de discusión de los problemas demográficos y sociales como podcasts y conversatorios con la participación de académicos y estudiantes.\nAsí como la escritura de un libro digital que actualice los temas que han sido objeto de la demografía social en los últimos años y este sitio web que sistematizará los materiales prácticos y bibliografía que realicemos durante 2023."
  },
  {
    "objectID": "talleres.html",
    "href": "talleres.html",
    "title": "Talleres",
    "section": "",
    "text": "En coordinación con el capítulo de las R-Ladies CDMX, en el mes de junio se impartirán tres talleres sobre uso de información demográfica…"
  },
  {
    "objectID": "talleres.html#demostallercacenso2020",
    "href": "talleres.html#demostallercacenso2020",
    "title": "Talleres",
    "section": "demos::taller(“CACENSO2020”)",
    "text": "demos::taller(“CACENSO2020”)\n\n\n\n\n\n\nVideo de la sesión"
  },
  {
    "objectID": "talleres.html#demostallerendiseg2021",
    "href": "talleres.html#demostallerendiseg2021",
    "title": "Talleres",
    "section": "demos::taller(“ENDISEG2021”)",
    "text": "demos::taller(“ENDISEG2021”)\n\n\n\n\n\n\nVideo de la sesión"
  },
  {
    "objectID": "talleres.html#demostallerendireh2021",
    "href": "talleres.html#demostallerendireh2021",
    "title": "Talleres",
    "section": "demos::taller(“ENDIREH2021”)",
    "text": "demos::taller(“ENDIREH2021”)\n\n\n\n\n\n\nVideo de la sesión"
  },
  {
    "objectID": "talleres.html#demostallerenoe",
    "href": "talleres.html#demostallerenoe",
    "title": "Talleres",
    "section": "demos::taller(“ENOE”)",
    "text": "demos::taller(“ENOE”)\nEste taller se impartió presencialmente en dos ocasiones."
  },
  {
    "objectID": "talleres.html#demostallertexto",
    "href": "talleres.html#demostallertexto",
    "title": "Talleres",
    "section": "demos::taller(“Texto”)",
    "text": "demos::taller(“Texto”)\nEste taller se impartió en línea con invitación para miembros del proyecto."
  },
  {
    "objectID": "t3_endireh2021.html",
    "href": "t3_endireh2021.html",
    "title": "T3: ENDIREH 2021",
    "section": "",
    "text": "En esta liga puedes descarga el proyecto de trabajo. De esta manera no tendremos problemas con las rutas relativas.\nhttps://tinyurl.com/demos-talleres"
  },
  {
    "objectID": "t3_endireh2021.html#video-de-la-sesión",
    "href": "t3_endireh2021.html#video-de-la-sesión",
    "title": "T3: ENDIREH 2021",
    "section": "Video de la sesión",
    "text": "Video de la sesión\n\n\n\n\nPaquetes\n\nif (!require(\"pacman\")) install.packages(\"pacman\") # instala pacman si se requiere\n\nLoading required package: pacman\n\npacman::p_load(tidyverse,\n               skimr,\n               haven, \n               readr,\n               foreign,\n               janitor,\n               magrittr,\n               pollster,\n               srvyr,\n               sjlabelled) #carga los paquetes necesarios \n\nEn esta práctica trabajaremos de nuevo con los datos abiertos.\n¿Qué son datos abiertos?\nhttps://publications.iadb.org/publications/spanish/viewer/Los-datos-abiertos-en-América-Latina-y-el-Caribe.pdf"
  },
  {
    "objectID": "t3_endireh2021.html#introducción-a-la-fuente",
    "href": "t3_endireh2021.html#introducción-a-la-fuente",
    "title": "T3: ENDIREH 2021",
    "section": "Introducción a la fuente",
    "text": "Introducción a la fuente\nDe acuerdo a la información en los datos abiertos, hay 28 conjuntos de datos, uno a nivel vivienda y el resto a nivel individuo:\n\nVivienda: tviv\nIndividual: tsdem - toda la población\nIndividual - persona elegida: desde la sección III\n\nEs muy raro que analicemos TODA la base de datos. Trabajaremos con el fusionado de vivienda, demográfico, sección III y sección de violencia en al ámbito laboral.\nPero… vamos a automatizar el proceso. Para eso primero repasemos sobre funciones y bucles"
  },
  {
    "objectID": "t3_endireh2021.html#mi-primera-función",
    "href": "t3_endireh2021.html#mi-primera-función",
    "title": "T3: ENDIREH 2021",
    "section": "Mi primera función",
    "text": "Mi primera función\nUnos de los elementos más poderosos de R es hacer nuestra propias funciones.\nLa lógica de las funciones es la siguiente:\nnombre_de_funcion(argumento1, argumento2, ...) {\n  operaciones\n  salida\n}\nPara ello haremos una función sencilla. Para sumarle un valor un 1\n\nmi_funcion<-function(x) {\n    resultado<-x+1\n    return(resultado)\n}\n\nmi_funcion(5)\n\n[1] 6\n\n\nVamos a agregar un argumento, podemos agregar un segundo número en lugar de 1\n\nmi_funcion<-function(x, a) {\n    resultado<-x+a\n    return(resultado)\n}\n\nmi_funcion(x=5, a=6)\n\n[1] 11\n\n\nLos argumentos no necesariamente deben ser un sólo valor\n\nmi_funcion(x=1:5, a=6:10)\n\n[1]  7  9 11 13 15"
  },
  {
    "objectID": "t3_endireh2021.html#bucles",
    "href": "t3_endireh2021.html#bucles",
    "title": "T3: ENDIREH 2021",
    "section": "Bucles",
    "text": "Bucles\n\nfor()\nSupongamos que quisiéramos repetir una operación a lo largo de una secuencia, se puede realizar\nfor (i in secuencia) {\n  operación 1\n  operación 2\n  ...\n  operación final\n}\n\nfor(i in 1:10) {\n  print(i+1)\n}\n\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n[1] 11\n\nfor(j in c(\"Hugo\", \"Paco\", \"Luis\")) {\n  \n  x<-paste(\"hola\",j, sep=\" \")\n  print(x)\n}\n\n[1] \"hola Hugo\"\n[1] \"hola Paco\"\n[1] \"hola Luis\""
  },
  {
    "objectID": "t3_endireh2021.html#importación-de-los-datos",
    "href": "t3_endireh2021.html#importación-de-los-datos",
    "title": "T3: ENDIREH 2021",
    "section": "Importación de los datos",
    "text": "Importación de los datos\nLa estructura de archivos es muy consistente en los datos abiertos. Vamos a utilizar además una función llamada “paste()” que ayuda a pegar cadenas, que la había mostrado arriba\n\na<-\"Hola\"\n\nb<-\"¿Cómo estás?\"\n\npaste(a, b, sep=\" \") \n\n[1] \"Hola ¿Cómo estás?\"\n\n\nEsto será muy útil para crear nuestra función\nPor ejemplo revisemos la liga para importar los datos de la tabla “TVIV”\n\nTVIV <- read_csv(\"data_t3/conjunto_de_datos_endireh_2021_csv/conjunto_de_datos_TVIV/conjunto_de_datos/conjunto_de_datos_TVIV.csv\")\n\nRows: 122646 Columns: 35\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (16): ID_VIV, UPM, VIV_SEL, CVE_ENT, NOM_ENT, CVE_MUN, NOM_MUN, COD_RES,...\ndbl (19): P1_1, P1_4_1, P1_4_2, P1_4_3, P1_4_4, P1_4_5, P1_4_6, P1_4_7, P1_4...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nHay dos espacios donde va el nombre de la tabla\n\ncd0 <- \"data_t3/conjunto_de_datos_endireh_2021_csv/conjunto_de_datos_\"\ncd1 <- \"/conjunto_de_datos/conjunto_de_datos_\"\n\nEjemplo de cómo funciona paste() y paste0()\n\npaste0(cd0,\"TVIV\", cd1, \"TVIV\", \".csv\")\n\n[1] \"data_t3/conjunto_de_datos_endireh_2021_csv/conjunto_de_datos_TVIV/conjunto_de_datos/conjunto_de_datos_TVIV.csv\"\n\n\nPodemos crear una función de importación:\n\nimportar <- function(tabla){\n\n  path <- paste0(cd0,tabla, cd1,tabla, \".csv\")\n  \n  x<-readr::read_csv(path, locale = locale(encoding = \"latin1\"))\n  \n  return(x)\n}\n\n\nTVIV<-importar(\"TVIV\")\n\nRows: 122646 Columns: 35\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (16): ID_VIV, UPM, VIV_SEL, CVE_ENT, NOM_ENT, CVE_MUN, NOM_MUN, COD_RES,...\ndbl (19): P1_1, P1_4_1, P1_4_2, P1_4_3, P1_4_4, P1_4_5, P1_4_6, P1_4_7, P1_4...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nOjo esta función también depende de cd0 y cd1, por lo que habría que declararlo antes. O bien, incluye los objetos dentro de la función, como lo hicimos con path. Nota que ese objeto no está en nuestro ambiente.\nVamos a usar el el índice de las tablas para importar todas con un loop\n\nindice_tablas <- read_csv(\"data_t3/conjunto_de_datos_endireh_2021_csv/0_indice_tablas_ENDIREH_2021.csv\",locale = locale(encoding = \"latin1\"), skip = 1) %>%\n  clean_names()\n\nRows: 28 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Nombre de archivo, Título de Tablas\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nRevisemos este índice\n\nhead(indice_tablas)\n\n# A tibble: 6 × 2\n  nombre_de_archivo            titulo_de_tablas                                 \n  <chr>                        <chr>                                            \n1 conjunto_de_datos_TVIV       Características de la Vivienda y Hogares en la V…\n2 conjunto_de_datos_TSDem      Características Sociodemográficas de Residentes …\n3 conjunto_de_datos_TB_SEC_III Elegibilidad y Verificación de Situación Conyuga…\n4 conjunto_de_datos_TB_SEC_IV  Situación de la Relación de Pareja/ Ingresos y R…\n5 conjunto_de_datos_TB_SEC_V   Consentimiento y Privacidad                      \n6 conjunto_de_datos_TB_SEC_VI  Opinión Sobre los Roles Masculinos y Femeninos   \n\nindice_tablas %<>%\n  mutate(nombre_de_archivo=stringr::str_remove_all(nombre_de_archivo, \"conjunto_de_datos_\"))\nhead(indice_tablas)\n\n# A tibble: 6 × 2\n  nombre_de_archivo titulo_de_tablas                                            \n  <chr>             <chr>                                                       \n1 TVIV              Características de la Vivienda y Hogares en la Vivienda     \n2 TSDem             Características Sociodemográficas de Residentes de la Vivie…\n3 TB_SEC_III        Elegibilidad y Verificación de Situación Conyugal de la Muj…\n4 TB_SEC_IV         Situación de la Relación de Pareja/ Ingresos y Recursos     \n5 TB_SEC_V          Consentimiento y Privacidad                                 \n6 TB_SEC_VI         Opinión Sobre los Roles Masculinos y Femeninos              \n\n\nVamos a importar todos los conjuntos!\nCreamos un vector con las tablas que queremos importar:\n\ntablas<-indice_tablas$nombre_de_archivo[c(1:4, 9)]\n\nSi le quitas lo que hay entre corchetes, tendrías los 28 conjuntos de datos.\n\nfor(i in tablas) {\n  \n  y<-importar(i) # se importa la base\n  assign(paste(i), y) # asigna el nombre al objeto y\n}\n\nRows: 122646 Columns: 35\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (16): ID_VIV, UPM, VIV_SEL, CVE_ENT, NOM_ENT, CVE_MUN, NOM_MUN, COD_RES,...\ndbl (19): P1_1, P1_4_1, P1_4_2, P1_4_3, P1_4_4, P1_4_5, P1_4_6, P1_4_7, P1_4...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 432746 Columns: 37\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (21): ID_VIV, ID_PER, UPM, VIV_SEL, CVE_ENT, NOM_ENT, CVE_MUN, NOM_MUN, ...\ndbl (16): HOGAR, SEXO, GRA, P2_8, P2_9, P2_10, P2_11, P2_12, P2_13, P2_15, P...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 110127 Columns: 25\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (14): ID_VIV, ID_PER, UPM, VIV_SEL, CVE_ENT, NOM_ENT, CVE_MUN, NOM_MUN, ...\ndbl (11): HOGAR, P3_1, P3_2, P3_3, P3_4, P3_5, P3_6, P3_7, FAC_VIV, FAC_MUJ,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 110127 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (34): ID_VIV, ID_PER, UPM, VIV_SEL, N_REN, DOMINIO, CVE_ENT, NOM_ENT, CV...\ndbl (39): HOGAR, P4AB_1, P4A_1, P4A_2, P4B_1, P4B_2, P4BC_1, P4C_1, P4BC_3, ...\nlgl  (2): P4_10_2_3, P4_10_3_3\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 110127 Columns: 241\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (15): ID_VIV, ID_PER, UPM, VIV_SEL, N_REN, DOMINIO, CVE_ENT, NOM_ENT, C...\ndbl (144): HOGAR, P8_1, P8_2, P8_3_1_1, P8_3_1_2, P8_3_2_1, P8_3_2_2, P8_3_2...\nlgl  (82): P8_12_1_3, P8_10_2_2, P8_10_2_3, P8_12_2_1, P8_12_2_2, P8_12_2_3,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nPiensa que podríamos tener más argumentos como: el nombre de la base, la carpeta, etc."
  },
  {
    "objectID": "t3_endireh2021.html#importación-de-los-diccionarios",
    "href": "t3_endireh2021.html#importación-de-los-diccionarios",
    "title": "T3: ENDIREH 2021",
    "section": "Importación de los diccionarios",
    "text": "Importación de los diccionarios\nLos diccionarios tienen una estructura parecida. Reformulemos nuestros directorios para hacer una función más general\n\ncd2 <- \"data_t3/conjunto_de_datos_endireh_2021_csv/conjunto_de_datos_\"\n\n\nimportar2 <-function(tabla, elemento) {\n  \n  dir<-paste0(cd2,tabla,\"/\",elemento,\"/\",elemento, \"_\",tabla, \".csv\")\n  \n  x<-readr::read_csv(paste0(dir), locale = locale(encoding = \"latin1\"))\n  \n  return(x)\n}\n\n\nTB_SEC_III<-importar2(tabla=\"TB_SEC_III\",\n                     elemento=\"conjunto_de_datos\")\n\nRows: 110127 Columns: 25\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (14): ID_VIV, ID_PER, UPM, VIV_SEL, CVE_ENT, NOM_ENT, CVE_MUN, NOM_MUN, ...\ndbl (11): HOGAR, P3_1, P3_2, P3_3, P3_4, P3_5, P3_6, P3_7, FAC_VIV, FAC_MUJ,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nDIC_TB_SEC_III<-importar2(tabla=\"TB_SEC_III\",\n                     elemento=\"diccionario_de_datos\") \n\nRows: 64 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NOMBRE_CAMPO, NEMONICO, TIPO, RANGO_CLAVES\ndbl (1): LONGITUD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nLoop para importar diccionarios\nCreamos un vector con las tablas que queremos importar:\n\ntablas<-indice_tablas$nombre_de_archivo[c(1:4, 9)]\n\n\nfor(i in tablas) {\n  \n  y<-importar2(tabla=i, \n               elemento=\"diccionario_de_datos\") # se importa la base\n\n  assign(paste0(\"DICC_\",i), y) # asigna el nombre al objeto y\n}\n\nRows: 68 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NOMBRE_CAMPO, NEMONICO, TIPO, RANGO_CLAVES\ndbl (1): LONGITUD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 107 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NOMBRE_CAMPO, NEMONICO, TIPO, RANGO_CLAVES\ndbl (1): LONGITUD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 64 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NOMBRE_CAMPO, NEMONICO, TIPO, RANGO_CLAVES\ndbl (1): LONGITUD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 427 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NOMBRE_CAMPO, NEMONICO, TIPO, RANGO_CLAVES\ndbl (1): LONGITUD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 1488 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NOMBRE_CAMPO, NEMONICO, TIPO, RANGO_CLAVES\ndbl (1): LONGITUD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCuidado con estos diccionarios. Hay varios instrumentos entonces se repiten.\n\nfor(i in tablas) {\n  \n  y<-importar2(tabla=i, \n               elemento=\"diccionario_de_datos\") %>% # se importa la base\n    select(NOMBRE_CAMPO:TIPO) %>% \n    unique()\n\n  assign(paste0(\"DICC_\",i), y) # asigna el nombre al objeto y\n}\n\nRows: 68 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NOMBRE_CAMPO, NEMONICO, TIPO, RANGO_CLAVES\ndbl (1): LONGITUD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 107 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NOMBRE_CAMPO, NEMONICO, TIPO, RANGO_CLAVES\ndbl (1): LONGITUD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 64 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NOMBRE_CAMPO, NEMONICO, TIPO, RANGO_CLAVES\ndbl (1): LONGITUD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 427 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NOMBRE_CAMPO, NEMONICO, TIPO, RANGO_CLAVES\ndbl (1): LONGITUD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 1488 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): NOMBRE_CAMPO, NEMONICO, TIPO, RANGO_CLAVES\ndbl (1): LONGITUD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nEtiquetado en bucle de variables\nHoy vamos a etiquetar las variables con un bucle.\nAquí solo lo he podido resolver con base\n\nDICC_TB_SEC_III$NEMONICO\n\n [1] \"ID_VIV\"    \"ID_PER\"    \"UPM\"       \"VIV_SEL\"   \"CVE_ENT\"   \"NOM_ENT\"  \n [7] \"CVE_MUN\"   \"NOM_MUN\"   \"HOGAR\"     \"T_INSTRUM\" \"N_REN\"     \"P3_1\"     \n[13] \"P3_2\"      \"P3_3\"      \"P3_4\"      \"P3_5\"      \"P3_6\"      \"P3_7\"     \n[19] \"P3_8\"      \"FAC_VIV\"   \"FAC_MUJ\"   \"DOMINIO\"   \"EST_DIS\"   \"UPM_DIS\"  \n[25] \"ESTRATO\"  \n\nTB_SEC_III[[\"ID_VIV\"]] %>% head()\n\n[1] \"0100003.01\" \"0100003.02\" \"0100003.03\" \"0100003.05\" \"0100004.01\"\n[6] \"0100004.02\"\n\nDICC_TB_SEC_III[DICC_TB_SEC_III$NEMONICO==\"ID_VIV\",]$NOMBRE_CAMPO\n\n[1] \"Identificador de vivienda seleccionada\"\n\n\n\nfor (i in DICC_TB_SEC_III$NEMONICO) {\n  \n  TB_SEC_III[[i]]<-sjlabelled::set_label(TB_SEC_III[[i]], label=DICC_TB_SEC_III[DICC_TB_SEC_III$NEMONICO==i,]$NOMBRE_CAMPO)\n  \n}\n\n\nfor (i in DICC_TB_SEC_IV$NEMONICO) {\n  \n  TB_SEC_IV[[i]]<-sjlabelled::set_label(TB_SEC_IV[[i]], label=DICC_TB_SEC_IV[DICC_TB_SEC_IV$NEMONICO==i,]$NOMBRE_CAMPO)\n  \n}"
  },
  {
    "objectID": "t3_endireh2021.html#importación-de-catalagos",
    "href": "t3_endireh2021.html#importación-de-catalagos",
    "title": "T3: ENDIREH 2021",
    "section": "Importación de catalagos",
    "text": "Importación de catalagos\nAquí hay una pequeña complicación, hay un archivo por preguntar. Para esto nos servirán las funciones de dir()\n\ndir(\"data_t3\")\n\n[1] \"conjunto_de_datos_endireh_2021_csv\" \"endireh2021_fd.pdf\"                \n\n\nLista los archivos que hay. Si no tienen extensión son carpetas.\n\ncd3<-paste0(cd2,\"TB_SEC_III\",\"/catalogos\")\ndir(cd3)\n\n [1] \"CVE_ENT.csv\"   \"CVE_MUN.csv\"   \"DOMINIO.csv\"   \"ESTRATO.csv\"  \n [5] \"EST_DIS.csv\"   \"FAC_MUJ.csv\"   \"FAC_VIV.csv\"   \"HOGAR.csv\"    \n [9] \"ID_PER.csv\"    \"ID_VIV.csv\"    \"NOM_ENT.csv\"   \"NOM_MUN.csv\"  \n[13] \"N_REN.csv\"     \"P3_1.csv\"      \"P3_2.csv\"      \"P3_3.csv\"     \n[17] \"P3_4.csv\"      \"P3_5.csv\"      \"P3_6.csv\"      \"P3_7.csv\"     \n[21] \"P3_8.csv\"      \"T_INSTRUM.csv\" \"UPM.csv\"       \"UPM_DIS.csv\"  \n[25] \"VIV_SEL.csv\"  \n\n\nPodemos guardar esa lista como un objeto caracter\n\ncat_TB_SEC_III<-dir(cd3) %>% stringr::str_remove_all(\".csv\")\n\n\nEtiquetado de valores\nVamos a etiquetar, ojo las variables de “id” no se etiquetan en valores.\n\nvars<-cat_TB_SEC_III[c(1:8, 14:25)]\n\nfor (i in vars) {\n  \n  x <- readr::read_csv(paste0(cd3,\"/\",i,\".csv\"),\n                locale = locale(encoding = \"latin1\")) %>% unique()\n  \n  TB_SEC_III[[i]]<-as.numeric(TB_SEC_III[[i]])\n  TB_SEC_III[[i]]<-set_labels(TB_SEC_III[[i]], labels=x$descrip)\n}\n\nRows: 1 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): CVE_ENT, descrip\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nMore values in \"x\" than length of \"labels\". Additional values were added to labels.\n\nRows: 1 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): CVE_MUN, descrip\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nMore values in \"x\" than length of \"labels\". Additional values were added to labels.\n\nRows: 5 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): DOMINIO, descrip\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: NAs introducidos por coerción\n\n\nMore labels than values of \"x\". Using first 0 labels.\nRows: 4 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): ESTRATO, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.Rows: 1 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): EST_DIS, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More values in \"x\" than length of \"labels\". Additional values were added to labels.\nRows: 1 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): FAC_MUJ, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More values in \"x\" than length of \"labels\". Additional values were added to labels.\nRows: 1 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): FAC_VIV, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More values in \"x\" than length of \"labels\". Additional values were added to labels.\nRows: 1 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): HOGAR, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More values in \"x\" than length of \"labels\". Additional values were added to labels.\nRows: 6 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): descrip\ndbl (1): P3_1\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.Rows: 3 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): P3_2, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More labels than values of \"x\". Using first 2 labels.\nRows: 8 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): P3_3, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More labels than values of \"x\". Using first 7 labels.\nRows: 3 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): P3_4, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More labels than values of \"x\". Using first 2 labels.\nRows: 3 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): P3_5, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More labels than values of \"x\". Using first 2 labels.\nRows: 5 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): P3_6, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More labels than values of \"x\". Using first 4 labels.\nRows: 3 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): P3_7, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More labels than values of \"x\". Using first 2 labels.\nRows: 6 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): P3_8, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: NAs introducidos por coerción\n\n\nMore labels than values of \"x\". Using first 0 labels.\nRows: 6 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): T_INSTRUM, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning: NAs introducidos por coerción\n\n\nMore labels than values of \"x\". Using first 0 labels.\nRows: 1 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): UPM, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More values in \"x\" than length of \"labels\". Additional values were added to labels.\nRows: 5 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): UPM_DIS, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More values in \"x\" than length of \"labels\". Additional values were added to labels.\nRows: 1 Columns: 2── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): VIV_SEL, descrip\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.More values in \"x\" than length of \"labels\". Additional values were added to labels.\n\n\nEjercicio, haz lo mismo para la sección IV\n\ncd3<-paste0(cd2,\"TB_SEC_IV\",\"/catalogos\")\ndir(cd3)\n\n [1] \"CVE_ENT.csv\"   \"CVE_MUN.csv\"   \"DOMINIO.csv\"   \"ESTRATO.csv\"  \n [5] \"EST_DIS.csv\"   \"FAC_MUJ.csv\"   \"FAC_VIV.csv\"   \"HOGAR.csv\"    \n [9] \"ID_PER.csv\"    \"ID_VIV.csv\"    \"NOM_ENT.csv\"   \"NOM_MUN.csv\"  \n[13] \"N_REN.csv\"     \"N_REN_ESP.csv\" \"P4AB_1.csv\"    \"P4AB_2.csv\"   \n[17] \"P4A_1.csv\"     \"P4A_2.csv\"     \"P4BC_1.csv\"    \"P4BC_2.csv\"   \n[21] \"P4BC_3.csv\"    \"P4BC_4.csv\"    \"P4BC_5.csv\"    \"P4B_1.csv\"    \n[25] \"P4B_2.csv\"     \"P4C_1.csv\"     \"P4_1.csv\"      \"P4_10_2_1.csv\"\n[29] \"P4_10_2_2.csv\" \"P4_10_2_3.csv\" \"P4_10_3_1.csv\" \"P4_10_3_2.csv\"\n[33] \"P4_10_3_3.csv\" \"P4_11.csv\"     \"P4_12_1.csv\"   \"P4_12_2.csv\"  \n[37] \"P4_12_3.csv\"   \"P4_12_4.csv\"   \"P4_12_5.csv\"   \"P4_12_6.csv\"  \n[41] \"P4_12_7.csv\"   \"P4_13_1.csv\"   \"P4_13_2.csv\"   \"P4_13_3.csv\"  \n[45] \"P4_13_4.csv\"   \"P4_13_5.csv\"   \"P4_13_6.csv\"   \"P4_13_7.csv\"  \n[49] \"P4_2.csv\"      \"P4_2_1.csv\"    \"P4_3.csv\"      \"P4_4.csv\"     \n[53] \"P4_4_CVE.csv\"  \"P4_5_1_AB.csv\" \"P4_5_AB.csv\"   \"P4_6_AB.csv\"  \n[57] \"P4_7_AB.csv\"   \"P4_8_1.csv\"    \"P4_8_2.csv\"    \"P4_8_3.csv\"   \n[61] \"P4_8_4.csv\"    \"P4_8_5.csv\"    \"P4_8_6.csv\"    \"P4_8_7.csv\"   \n[65] \"P4_9_1.csv\"    \"P4_9_2.csv\"    \"P4_9_3.csv\"    \"P4_9_4.csv\"   \n[69] \"P4_9_5.csv\"    \"P4_9_6.csv\"    \"P4_9_7.csv\"    \"T_INSTRUM.csv\"\n[73] \"UPM.csv\"       \"UPM_DIS.csv\"   \"VIV_SEL.csv\"  \n\nDICC_TB_SEC_IV %>% \n  filter(TIPO==\"Numérico\") %>% \n  select(NEMONICO) -> vars\n\n# for (i in vars$NEMONICO) {\n#   \n#   x <- read_csv(paste0(cd3,\"/\",i,\".csv\"),\n#                 locale = locale(encoding = \"latin1\")) %>% unique() \n#   \n#   TB_SEC_IV[[i]]<-as.numeric(TB_SEC_IV[[i]])\n#   \n#   TB_SEC_IV[[i]]<-set_labels(TB_SEC_IV[[i]], labels=x$descrip)\n# }\n\nPueden haber errores pero pues, ahorra mucho\n\nTB_SEC_III %>% \n  mutate(P3_1=as_label(P3_1)) %>% \n  tabyl(P3_1)\n\n                 P3_1     n    percent\n vive en unión libre? 23597 0.21427080\n       está separada?  8628 0.07834591\n     está divorciada?  3173 0.02881219\n            es viuda?  9750 0.08853415\n         está casada? 44977 0.40841029\n        está soltera? 20002 0.18162667\n\n\nNo siempre funciona… o funcional 100\n\nTB_SEC_IV %>% \n  mutate(P4AB_1=as_label(P4AB_1)) %>% \n  tabyl(P4AB_1) \n\n P4AB_1     n   percent valid_percent\n      1 31398 0.2851072    0.34620855\n      2  2115 0.0192051    0.02332095\n      3 36019 0.3270678    0.39716179\n      4 21159 0.1921327    0.23330871\n     NA 19436 0.1764871            NA\n\n\nLo ideal en este caso es etiquetar antes de fusionar.\nVamos a botar algunos objeto que ya no ocuparemos\nCheca con glipmse()\n\nglimpse(TB_SEC_III$P3_1) # perdimos la label\n\n num [1:110127] 5 5 4 6 2 4 2 4 5 5 ...\n - attr(*, \"labels\")= Named num [1:6] 1 2 3 4 5 6\n  ..- attr(*, \"names\")= chr [1:6] \"vive en unión libre?\" \"está separada?\" \"está divorciada?\" \"es viuda?\" ...\n\n\n\nrm(list=ls(pattern=\"^DICC_\"))\nrm(list=ls(pattern=\"^cat_\"))"
  },
  {
    "objectID": "t3_endireh2021.html#fusionado",
    "href": "t3_endireh2021.html#fusionado",
    "title": "T3: ENDIREH 2021",
    "section": "Fusionado",
    "text": "Fusionado\nPara que se guarden las etiquetas debemos usar los “join” de {dplyr}\nAdemás esta base no tiene una sólo variable del id. Tiene un identificador compuesto. Podemos hacer un objeto tipo vector\n\nendireh2021_ind<-TB_SEC_III %>% \n  left_join(TB_SEC_IV, by=\"ID_PER\") %>% \n  select(-ends_with(\".y\")) %>% # quita todas las variables que terminan en .y\n  rename_with(~ stringr::str_remove(.x,  pattern = \".x\"),  ends_with(\".x\")) %>% \n  left_join(TB_SEC_VIII, by=\"ID_PER\") %>% \n  select(-ends_with(\".y\")) %>% # quita todas las variables que terminan en .y\n  rename_with(~ stringr::str_remove(.x,  pattern = \".x\"),  ends_with(\".x\")) \n\nendireh2021_ind %>% names()\n\n  [1] \"ID_VIV\"     \"ID_PER\"     \"UPM\"        \"VIV_SEL\"    \"CVE_ENT\"   \n  [6] \"NOM_ENT\"    \"CVE_MUN\"    \"NOM_MUN\"    \"HOGAR\"      \"T_INSTRUM\" \n [11] \"N_REN\"      \"P3_1\"       \"P3_2\"       \"P3_3\"       \"P3_4\"      \n [16] \"P3_5\"       \"P3_6\"       \"P3_7\"       \"P3_8\"       \"FAC_VIV\"   \n [21] \"FAC_MUJ\"    \"DOMINIO\"    \"ESTRATO\"    \"EST_DIS\"    \"UPM_DIS\"   \n [26] \"N_REN_ESP\"  \"P4AB_1\"     \"P4AB_2\"     \"P4A_1\"      \"P4A_2\"     \n [31] \"P4B_1\"      \"P4B_2\"      \"P4BC_1\"     \"P4BC_2\"     \"P4C_1\"     \n [36] \"P4BC_3\"     \"P4BC_4\"     \"P4BC_5\"     \"P4_1\"       \"P4_2\"      \n [41] \"P4_2_1\"     \"P4_3\"       \"P4_4\"       \"P4_4_CVE\"   \"P4_5_AB\"   \n [46] \"P4_5_1_AB\"  \"P4_6_AB\"    \"P4_7_AB\"    \"P4_8_1\"     \"P4_8_2\"    \n [51] \"P4_8_3\"     \"P4_8_4\"     \"P4_8_5\"     \"P4_8_6\"     \"P4_8_7\"    \n [56] \"P4_9_1\"     \"P4_9_2\"     \"P4_10_2_1\"  \"P4_10_2_2\"  \"P4_10_2_3\" \n [61] \"P4_9_3\"     \"P4_10_3_1\"  \"P4_10_3_2\"  \"P4_10_3_3\"  \"P4_9_4\"    \n [66] \"P4_9_5\"     \"P4_9_6\"     \"P4_9_7\"     \"P4_11\"      \"P4_12_1\"   \n [71] \"P4_12_2\"    \"P4_12_3\"    \"P4_12_4\"    \"P4_12_5\"    \"P4_12_6\"   \n [76] \"P4_12_7\"    \"P4_13_1\"    \"P4_13_2\"    \"P4_13_3\"    \"P4_13_4\"   \n [81] \"P4_13_5\"    \"P4_13_6\"    \"P4_13_7\"    \"P8_1\"       \"P8_2\"      \n [86] \"P8_3_1_1\"   \"P8_3_1_2\"   \"P8_3_2_1\"   \"P8_3_2_2\"   \"P8_3_2_3\"  \n [91] \"P8_4\"       \"P8_5\"       \"P8_6\"       \"P8_6_CVE\"   \"P8_7\"      \n [96] \"P8_8_1\"     \"P8_8_2\"     \"P8_8_3\"     \"P8_8_4\"     \"P8_8_5\"    \n[101] \"P8_8_6\"     \"P8_8_7\"     \"P8_8_8\"     \"P8_8_9\"     \"P8_9_1\"    \n[106] \"P8_9_2\"     \"P8_9_3\"     \"P8_9_4\"     \"P8_9_5\"     \"P8_9_6\"    \n[111] \"P8_9_7\"     \"P8_9_8\"     \"P8_9_9\"     \"P8_9_10\"    \"P8_9_11\"   \n[116] \"P8_9_12\"    \"P8_9_13\"    \"P8_9_14\"    \"P8_9_15\"    \"P8_9_16\"   \n[121] \"P8_9_17\"    \"P8_9_18\"    \"P8_9_19\"    \"P8_10_1_1\"  \"P8_10_1_2\" \n[126] \"P8_10_1_3\"  \"P8_11_1\"    \"P8_12_1_1\"  \"P8_12_1_2\"  \"P8_12_1_3\" \n[131] \"P8_10_2_1\"  \"P8_10_2_2\"  \"P8_10_2_3\"  \"P8_11_2\"    \"P8_12_2_1\" \n[136] \"P8_12_2_2\"  \"P8_12_2_3\"  \"P8_10_3_1\"  \"P8_10_3_2\"  \"P8_10_3_3\" \n[141] \"P8_11_3\"    \"P8_12_3_1\"  \"P8_12_3_2\"  \"P8_12_3_3\"  \"P8_13_3_1\" \n[146] \"P8_13_3_2\"  \"P8_13_3_3\"  \"P8_10_4_1\"  \"P8_10_4_2\"  \"P8_10_4_3\" \n[151] \"P8_11_4\"    \"P8_12_4_1\"  \"P8_12_4_2\"  \"P8_12_4_3\"  \"P8_13_4_1\" \n[156] \"P8_13_4_2\"  \"P8_13_4_3\"  \"P8_10_5_1\"  \"P8_10_5_2\"  \"P8_10_5_3\" \n[161] \"P8_11_5\"    \"P8_12_5_1\"  \"P8_12_5_2\"  \"P8_12_5_3\"  \"P8_13_5_1\" \n[166] \"P8_13_5_2\"  \"P8_13_5_3\"  \"P8_10_6_1\"  \"P8_10_6_2\"  \"P8_10_6_3\" \n[171] \"P8_11_6\"    \"P8_12_6_1\"  \"P8_12_6_2\"  \"P8_12_6_3\"  \"P8_13_6_1\" \n[176] \"P8_13_6_2\"  \"P8_13_6_3\"  \"P8_10_7_1\"  \"P8_10_7_2\"  \"P8_10_7_3\" \n[181] \"P8_11_7\"    \"P8_12_7_1\"  \"P8_12_7_2\"  \"P8_12_7_3\"  \"P8_13_7_1\" \n[186] \"P8_13_7_2\"  \"P8_13_7_3\"  \"P8_10_8_1\"  \"P8_10_8_2\"  \"P8_10_8_3\" \n[191] \"P8_11_8\"    \"P8_12_8_1\"  \"P8_12_8_2\"  \"P8_12_8_3\"  \"P8_13_8_1\" \n[196] \"P8_13_8_2\"  \"P8_13_8_3\"  \"P8_10_9_1\"  \"P8_10_9_2\"  \"P8_10_9_3\" \n[201] \"P8_11_9\"    \"P8_12_9_1\"  \"P8_12_9_2\"  \"P8_12_9_3\"  \"P8_13_9_1\" \n[206] \"P8_13_9_2\"  \"P8_13_9_3\"  \"P8_10_10_1\" \"P8_10_10_2\" \"P8_10_10_3\"\n[211] \"P8_11_10\"   \"P8_12_10_1\" \"P8_12_10_2\" \"P8_12_10_3\" \"P8_13_10_1\"\n[216] \"P8_13_10_2\" \"P8_13_10_3\" \"P8_10_11_1\" \"P8_10_11_2\" \"P8_10_11_3\"\n[221] \"P8_11_11\"   \"P8_12_11_1\" \"P8_12_11_2\" \"P8_12_11_3\" \"P8_13_11_1\"\n[226] \"P8_13_11_2\" \"P8_13_11_3\" \"P8_10_12_1\" \"P8_10_12_2\" \"P8_10_12_3\"\n[231] \"P8_11_12\"   \"P8_12_12_1\" \"P8_12_12_2\" \"P8_12_12_3\" \"P8_13_12_1\"\n[236] \"P8_13_12_2\" \"P8_13_12_3\" \"P8_10_13_1\" \"P8_10_13_2\" \"P8_10_13_3\"\n[241] \"P8_11_13\"   \"P8_12_13_1\" \"P8_12_13_2\" \"P8_12_13_3\" \"P8_13_13_1\"\n[246] \"P8_13_13_2\" \"P8_13_13_3\" \"P8_10_14_1\" \"P8_10_14_2\" \"P8_10_14_3\"\n[251] \"P8_11_14\"   \"P8_12_14_1\" \"P8_12_14_2\" \"P8_12_14_3\" \"P8_13_14_1\"\n[256] \"P8_13_14_2\" \"P8_13_14_3\" \"P8_10_15_1\" \"P8_10_15_2\" \"P8_10_15_3\"\n[261] \"P8_11_15\"   \"P8_12_15_1\" \"P8_12_15_2\" \"P8_12_15_3\" \"P8_13_15_1\"\n[266] \"P8_13_15_2\" \"P8_13_15_3\" \"P8_10_16_1\" \"P8_10_16_2\" \"P8_10_16_3\"\n[271] \"P8_11_16\"   \"P8_12_16_1\" \"P8_12_16_2\" \"P8_12_16_3\" \"P8_13_16_1\"\n[276] \"P8_13_16_2\" \"P8_13_16_3\" \"P8_10_17_1\" \"P8_10_17_2\" \"P8_10_17_3\"\n[281] \"P8_11_17\"   \"P8_12_17_1\" \"P8_12_17_2\" \"P8_12_17_3\" \"P8_13_17_1\"\n[286] \"P8_13_17_2\" \"P8_13_17_3\" \"P8_10_18_1\" \"P8_10_18_2\" \"P8_10_18_3\"\n[291] \"P8_11_18\"   \"P8_12_18_1\" \"P8_12_18_2\" \"P8_12_18_3\" \"P8_13_18_1\"\n[296] \"P8_13_18_2\" \"P8_13_18_3\" \"P8_10_19_1\" \"P8_10_19_2\" \"P8_10_19_3\"\n[301] \"P8_11_19\"   \"P8_12_19_1\" \"P8_12_19_2\" \"P8_12_19_3\" \"P8_13_19_1\"\n[306] \"P8_13_19_2\" \"P8_13_19_3\"\n\n\nHoy pegamos estas 110,127 mujeres al sociodemográfico\n\nendireh2021<-endireh2021_ind %>% \n  right_join(TSDem, by=\"ID_PER\") %>%  # ojo con el right ¿por qué?\n  select(-ends_with(\".x\")) %>% # quita todas las variables que terminan en .x\n  rename_with(~ stringr::str_remove(.x,  pattern = \".y\"),  ends_with(\".y\"))\n\nFinalmente pegamos la vivienda.\n\nendireh2021<-endireh2021 %>% \n  right_join(TVIV, by=\"ID_VIV\") %>%  # ojo con el right ¿por qué?\n  select(-ends_with(\".x\")) %>% # quita todas las variables que terminan en .x\n  rename_with(~ stringr::str_remove(.x,  pattern = \".y\"),  ends_with(\".y\"))\n\n\nrm(endireh2021_ind, indice_tablas)"
  },
  {
    "objectID": "t3_endireh2021.html#skim",
    "href": "t3_endireh2021.html#skim",
    "title": "T3: ENDIREH 2021",
    "section": "Skim",
    "text": "Skim\n\nendireh2021 %>% \n  skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n432746\n\n\nNumber of columns\n351\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n50\n\n\nlogical\n84\n\n\nnumeric\n217\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nID_PER\n0\n1.00\n15\n15\n0\n432746\n0\n\n\nN_REN_ESP\n364206\n0.16\n2\n2\n0\n16\n0\n\n\nP4AB_2\n408186\n0.06\n2\n2\n0\n70\n0\n\n\nP4BC_2\n396008\n0.08\n2\n2\n0\n13\n0\n\n\nP4_2\n383766\n0.11\n6\n6\n0\n545\n0\n\n\nP4_4\n361532\n0.16\n3\n198\n0\n23954\n0\n\n\nP4_5_AB\n369721\n0.15\n6\n6\n0\n365\n0\n\n\nP4_7_AB\n365948\n0.15\n6\n6\n0\n300\n0\n\n\nP4_9_1\n425312\n0.02\n6\n6\n0\n279\n0\n\n\nP4_9_2\n429400\n0.01\n6\n6\n0\n104\n0\n\n\nP4_9_3\n427387\n0.01\n6\n6\n0\n103\n0\n\n\nP4_9_4\n427310\n0.01\n6\n6\n0\n162\n0\n\n\nP4_9_5\n430655\n0.00\n6\n6\n0\n129\n0\n\n\nP4_9_6\n417572\n0.04\n6\n6\n0\n246\n0\n\n\nP4_9_7\n431864\n0.00\n6\n6\n0\n102\n0\n\n\nP4_13_1\n418194\n0.03\n2\n2\n0\n9\n0\n\n\nP4_13_2\n387815\n0.10\n2\n2\n0\n9\n0\n\n\nP4_13_3\n420806\n0.03\n2\n2\n0\n9\n0\n\n\nP4_13_4\n359756\n0.17\n2\n2\n0\n10\n0\n\n\nP4_13_5\n429554\n0.01\n2\n2\n0\n9\n0\n\n\nP4_13_6\n431102\n0.00\n2\n2\n0\n9\n0\n\n\nP4_13_7\n427327\n0.01\n2\n2\n0\n9\n0\n\n\nP8_6\n394950\n0.09\n3\n164\n0\n15143\n0\n\n\nP8_7\n394950\n0.09\n2\n2\n0\n15\n0\n\n\nID_VIV\n0\n1.00\n10\n10\n0\n122646\n0\n\n\nN_REN\n0\n1.00\n2\n2\n0\n24\n0\n\n\nNOMBRE\n0\n1.00\n1\n1\n0\n1\n0\n\n\nPAREN\n0\n1.00\n2\n2\n0\n11\n0\n\n\nEDAD\n0\n1.00\n2\n2\n0\n100\n0\n\n\nP2_5\n0\n1.00\n2\n2\n0\n24\n0\n\n\nP2_6\n0\n1.00\n2\n2\n0\n22\n0\n\n\nNIV\n16648\n0.96\n2\n2\n0\n12\n0\n\n\nP2_14\n271145\n0.37\n2\n2\n0\n13\n0\n\n\nREN_MUJ_EL\n322619\n0.25\n2\n2\n0\n16\n0\n\n\nREN_INF_AD\n310100\n0.28\n2\n2\n0\n18\n0\n\n\nUPM\n0\n1.00\n7\n7\n0\n17763\n0\n\n\nVIV_SEL\n0\n1.00\n2\n2\n0\n24\n0\n\n\nCVE_ENT\n0\n1.00\n2\n2\n0\n32\n0\n\n\nNOM_ENT\n0\n1.00\n6\n31\n0\n32\n0\n\n\nCVE_MUN\n0\n1.00\n3\n3\n0\n269\n0\n\n\nNOM_MUN\n0\n1.00\n4\n49\n0\n1206\n0\n\n\nCOD_RES\n0\n1.00\n2\n2\n0\n2\n0\n\n\nP1_2\n0\n1.00\n2\n2\n0\n12\n0\n\n\nP1_2_A\n0\n1.00\n2\n2\n0\n21\n0\n\n\nP1_3\n0\n1.00\n2\n2\n0\n76\n0\n\n\nP1_7\n0\n1.00\n2\n2\n0\n24\n0\n\n\nP1_9\n411265\n0.05\n2\n2\n0\n5\n0\n\n\nDOMINIO\n0\n1.00\n1\n1\n0\n3\n0\n\n\nEST_DIS\n0\n1.00\n4\n4\n0\n617\n0\n\n\nUPM_DIS\n0\n1.00\n5\n5\n0\n17763\n0\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\nP4_10_2_3\n432746\n0\nNaN\n:\n\n\nP4_10_3_3\n432746\n0\nNaN\n:\n\n\nP8_12_1_3\n432746\n0\nNaN\n:\n\n\nP8_10_2_2\n432743\n0\n1\nTRU: 3\n\n\nP8_10_2_3\n432746\n0\nNaN\n:\n\n\nP8_12_2_1\n432727\n0\n1\nTRU: 19\n\n\nP8_12_2_2\n432746\n0\nNaN\n:\n\n\nP8_12_2_3\n432746\n0\nNaN\n:\n\n\nP8_12_3_2\n432746\n0\nNaN\n:\n\n\nP8_12_3_3\n432746\n0\nNaN\n:\n\n\nP8_13_3_2\n432746\n0\nNaN\n:\n\n\nP8_13_3_3\n432746\n0\nNaN\n:\n\n\nP8_10_4_3\n432746\n0\nNaN\n:\n\n\nP8_12_4_2\n432746\n0\nNaN\n:\n\n\nP8_12_4_3\n432746\n0\nNaN\n:\n\n\nP8_13_4_2\n432746\n0\nNaN\n:\n\n\nP8_13_4_3\n432746\n0\nNaN\n:\n\n\nP8_10_5_3\n432745\n0\n1\nTRU: 1\n\n\nP8_12_5_2\n432746\n0\nNaN\n:\n\n\nP8_12_5_3\n432746\n0\nNaN\n:\n\n\nP8_13_7_2\n432746\n0\nNaN\n:\n\n\nP8_13_7_3\n432746\n0\nNaN\n:\n\n\nP8_10_8_2\n432746\n0\nNaN\n:\n\n\nP8_10_8_3\n432746\n0\nNaN\n:\n\n\nP8_12_8_2\n432746\n0\nNaN\n:\n\n\nP8_12_8_3\n432746\n0\nNaN\n:\n\n\nP8_13_8_2\n432746\n0\nNaN\n:\n\n\nP8_13_8_3\n432746\n0\nNaN\n:\n\n\nP8_10_9_1\n432716\n0\n1\nTRU: 30\n\n\nP8_10_9_2\n432746\n0\nNaN\n:\n\n\nP8_10_9_3\n432746\n0\nNaN\n:\n\n\nP8_11_9\n432736\n0\n1\nTRU: 10\n\n\nP8_12_9_1\n432741\n0\n1\nTRU: 5\n\n\nP8_12_9_2\n432746\n0\nNaN\n:\n\n\nP8_12_9_3\n432746\n0\nNaN\n:\n\n\nP8_13_9_1\n432684\n0\n1\nTRU: 62\n\n\nP8_13_9_2\n432746\n0\nNaN\n:\n\n\nP8_13_9_3\n432746\n0\nNaN\n:\n\n\nP8_10_10_2\n432746\n0\nNaN\n:\n\n\nP8_10_10_3\n432746\n0\nNaN\n:\n\n\nP8_12_10_2\n432746\n0\nNaN\n:\n\n\nP8_12_10_3\n432746\n0\nNaN\n:\n\n\nP8_13_10_2\n432746\n0\nNaN\n:\n\n\nP8_13_10_3\n432746\n0\nNaN\n:\n\n\nP8_10_11_3\n432746\n0\nNaN\n:\n\n\nP8_12_11_2\n432746\n0\nNaN\n:\n\n\nP8_12_11_3\n432746\n0\nNaN\n:\n\n\nP8_13_11_2\n432746\n0\nNaN\n:\n\n\nP8_13_11_3\n432746\n0\nNaN\n:\n\n\nP8_10_12_3\n432746\n0\nNaN\n:\n\n\nP8_12_12_2\n432746\n0\nNaN\n:\n\n\nP8_12_12_3\n432746\n0\nNaN\n:\n\n\nP8_10_13_2\n432746\n0\nNaN\n:\n\n\nP8_10_13_3\n432746\n0\nNaN\n:\n\n\nP8_12_13_2\n432746\n0\nNaN\n:\n\n\nP8_12_13_3\n432746\n0\nNaN\n:\n\n\nP8_13_13_2\n432746\n0\nNaN\n:\n\n\nP8_13_13_3\n432746\n0\nNaN\n:\n\n\nP8_10_14_2\n432746\n0\nNaN\n:\n\n\nP8_10_14_3\n432746\n0\nNaN\n:\n\n\nP8_12_14_2\n432746\n0\nNaN\n:\n\n\nP8_12_14_3\n432746\n0\nNaN\n:\n\n\nP8_13_14_2\n432746\n0\nNaN\n:\n\n\nP8_13_14_3\n432746\n0\nNaN\n:\n\n\nP8_10_15_3\n432745\n0\n1\nTRU: 1\n\n\nP8_12_15_2\n432746\n0\nNaN\n:\n\n\nP8_12_15_3\n432746\n0\nNaN\n:\n\n\nP8_13_15_2\n432746\n0\nNaN\n:\n\n\nP8_13_15_3\n432746\n0\nNaN\n:\n\n\nP8_10_16_2\n432745\n0\n1\nTRU: 1\n\n\nP8_10_16_3\n432746\n0\nNaN\n:\n\n\nP8_12_16_2\n432746\n0\nNaN\n:\n\n\nP8_12_16_3\n432746\n0\nNaN\n:\n\n\nP8_13_16_2\n432746\n0\nNaN\n:\n\n\nP8_13_16_3\n432746\n0\nNaN\n:\n\n\nP8_13_17_3\n432746\n0\nNaN\n:\n\n\nP8_13_18_2\n432746\n0\nNaN\n:\n\n\nP8_13_18_3\n432746\n0\nNaN\n:\n\n\nP8_10_19_2\n432746\n0\nNaN\n:\n\n\nP8_10_19_3\n432746\n0\nNaN\n:\n\n\nP8_12_19_2\n432746\n0\nNaN\n:\n\n\nP8_12_19_3\n432746\n0\nNaN\n:\n\n\nP8_13_19_2\n432746\n0\nNaN\n:\n\n\nP8_13_19_3\n432746\n0\nNaN\n:\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nT_INSTRUM\n432746\n0.00\nNaN\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\nP3_1\n322619\n0.25\n3.94\n1.84\n1\n2.00\n5.0\n5.00\n6\n▆▁▂▇▃\n\n\nP3_2\n364172\n0.16\n1.04\n0.19\n1\n1.00\n1.0\n1.00\n2\n▇▁▁▁▁\n\n\nP3_3\n430175\n0.01\n2.85\n1.96\n1\n1.00\n3.0\n3.00\n7\n▇▆▁▁▃\n\n\nP3_4\n411195\n0.05\n1.93\n0.25\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP3_5\n431261\n0.00\n1.96\n0.20\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP3_6\n412744\n0.05\n2.69\n1.11\n1\n1.00\n3.0\n3.00\n4\n▅▁▁▇▅\n\n\nP3_7\n423107\n0.02\n1.80\n0.40\n1\n2.00\n2.0\n2.00\n2\n▂▁▁▁▇\n\n\nP3_8\n432746\n0.00\nNaN\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\nP4AB_1\n342055\n0.21\n2.52\n1.19\n1\n1.00\n3.0\n3.00\n4\n▇▁▁▇▅\n\n\nP4A_1\n430337\n0.01\n4.56\n2.81\n1\n2.00\n5.0\n7.00\n9\n▇▆▅▃▆\n\n\nP4A_2\n430337\n0.01\n4.99\n2.64\n1\n3.00\n5.0\n8.00\n8\n▅▂▅▂▇\n\n\nP4B_1\n410595\n0.05\n1.99\n0.93\n1\n1.00\n2.0\n3.00\n3\n▇▁▂▁▇\n\n\nP4B_2\n420179\n0.03\n3.87\n2.14\n1\n2.00\n3.0\n5.00\n9\n▇▆▃▁▃\n\n\nP4BC_1\n396008\n0.08\n49.47\n24.36\n12\n29.00\n46.0\n65.00\n99\n▇▇▇▃▃\n\n\nP4C_1\n418159\n0.03\n2.70\n2.27\n1\n2.00\n2.0\n2.00\n8\n▇▁▁▁▂\n\n\nP4BC_3\n396008\n0.08\n3.07\n1.69\n1\n3.00\n3.0\n3.00\n8\n▂▇▁▁▁\n\n\nP4BC_4\n396008\n0.08\n1.94\n0.23\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP4BC_5\n430619\n0.00\n1.05\n0.22\n1\n1.00\n1.0\n1.00\n2\n▇▁▁▁▁\n\n\nP4_1\n322619\n0.25\n1.56\n0.50\n1\n1.00\n2.0\n2.00\n2\n▆▁▁▁▇\n\n\nP4_2_1\n388187\n0.10\n1.69\n0.87\n1\n1.00\n1.0\n3.00\n9\n▇▃▁▁▁\n\n\nP4_3\n337052\n0.22\n1.83\n2.05\n1\n1.00\n1.0\n2.00\n9\n▇▁▁▁▁\n\n\nP4_4_CVE\n361533\n0.16\n6257.34\n2695.63\n980\n4111.00\n6311.0\n8349.00\n9999\n▅▃▅▅▇\n\n\nP4_5_1_AB\n385711\n0.11\n1.57\n0.83\n1\n1.00\n1.0\n2.00\n9\n▇▂▁▁▁\n\n\nP4_6_AB\n351639\n0.19\n1.23\n0.67\n1\n1.00\n1.0\n1.00\n9\n▇▁▁▁▁\n\n\nP4_8_1\n322619\n0.25\n1.93\n0.25\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP4_8_2\n322619\n0.25\n1.97\n0.17\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP4_8_3\n322619\n0.25\n1.95\n0.22\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP4_8_4\n322619\n0.25\n1.95\n0.22\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP4_8_5\n322619\n0.25\n1.98\n0.14\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP4_8_6\n322619\n0.25\n1.86\n0.34\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP4_8_7\n322619\n0.25\n1.99\n0.09\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP4_10_2_1\n429400\n0.01\n2.36\n0.92\n1\n2.00\n2.0\n3.00\n5\n▂▇▂▂▁\n\n\nP4_10_2_2\n432610\n0.00\n3.56\n0.73\n2\n3.00\n4.0\n4.00\n5\n▁▇▁▇▂\n\n\nP4_10_3_1\n427388\n0.01\n2.07\n0.83\n1\n2.00\n2.0\n2.00\n5\n▂▇▁▁▁\n\n\nP4_10_3_2\n432480\n0.00\n3.67\n0.67\n2\n3.00\n4.0\n4.00\n5\n▁▆▁▇▁\n\n\nP4_11\n322619\n0.25\n1.48\n0.50\n1\n1.00\n1.0\n2.00\n2\n▇▁▁▁▇\n\n\nP4_12_1\n322619\n0.25\n1.87\n0.34\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP4_12_2\n322619\n0.25\n1.59\n0.49\n1\n1.00\n2.0\n2.00\n2\n▆▁▁▁▇\n\n\nP4_12_3\n322619\n0.25\n1.89\n0.31\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP4_12_4\n322619\n0.25\n1.34\n0.47\n1\n1.00\n1.0\n2.00\n2\n▇▁▁▁▅\n\n\nP4_12_5\n322619\n0.25\n1.97\n0.17\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP4_12_6\n322619\n0.25\n1.99\n0.12\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP4_12_7\n322619\n0.25\n1.95\n0.22\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP8_1\n322619\n0.25\n1.19\n0.40\n1\n1.00\n1.0\n1.00\n2\n▇▁▁▁▂\n\n\nP8_2\n343986\n0.21\n1.24\n0.43\n1\n1.00\n1.0\n1.00\n2\n▇▁▁▁▂\n\n\nP8_3_1_1\n365660\n0.16\n1.99\n0.78\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_3_1_2\n365660\n0.16\n2.05\n0.74\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_3_2_1\n365660\n0.16\n2.76\n0.97\n1\n2.00\n3.0\n3.00\n9\n▅▇▁▁▁\n\n\nP8_3_2_2\n365660\n0.16\n2.76\n0.96\n1\n2.00\n3.0\n3.00\n9\n▅▇▁▁▁\n\n\nP8_3_2_3\n365660\n0.16\n2.76\n0.96\n1\n2.00\n3.0\n3.00\n9\n▅▇▁▁▁\n\n\nP8_4\n365660\n0.16\n1.18\n0.38\n1\n1.00\n1.0\n1.00\n2\n▇▁▁▁▂\n\n\nP8_5\n377418\n0.13\n2.09\n1.50\n1\n1.00\n1.0\n4.00\n6\n▇▁▃▁▁\n\n\nP8_6_CVE\n394950\n0.09\n5618.39\n2993.52\n980\n3111.00\n4231.0\n9411.00\n9999\n▆▇▃▂▇\n\n\nP8_8_1\n394950\n0.09\n2.08\n0.73\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_8_2\n394950\n0.09\n2.07\n0.74\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_8_3\n394950\n0.09\n2.13\n0.71\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_8_4\n394950\n0.09\n2.14\n0.67\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_8_5\n394950\n0.09\n2.16\n0.70\n1\n2.00\n2.0\n2.00\n9\n▇▂▁▁▁\n\n\nP8_8_6\n394950\n0.09\n2.68\n0.79\n1\n2.00\n3.0\n3.00\n9\n▅▇▁▁▁\n\n\nP8_8_7\n394950\n0.09\n2.13\n0.68\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_8_8\n394950\n0.09\n2.09\n0.69\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_8_9\n394950\n0.09\n2.00\n0.61\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_1\n343986\n0.21\n1.99\n0.47\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_2\n343986\n0.21\n2.02\n0.44\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_3\n343986\n0.21\n1.98\n0.48\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_4\n343986\n0.21\n2.01\n0.46\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_5\n343986\n0.21\n1.98\n0.48\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_6\n343986\n0.21\n1.94\n0.52\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_7\n343986\n0.21\n1.97\n0.49\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_8\n343986\n0.21\n2.02\n0.44\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_9\n343986\n0.21\n2.02\n0.44\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_10\n343986\n0.21\n2.02\n0.44\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_11\n343986\n0.21\n2.00\n0.46\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_12\n343986\n0.21\n2.00\n0.46\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_13\n343986\n0.21\n2.01\n0.45\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_14\n343986\n0.21\n2.02\n0.44\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_15\n343986\n0.21\n1.99\n0.48\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_16\n343986\n0.21\n2.01\n0.45\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_17\n343986\n0.21\n1.98\n0.48\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_18\n343986\n0.21\n1.98\n0.49\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_9_19\n343986\n0.21\n2.02\n0.45\n1\n2.00\n2.0\n2.00\n9\n▇▁▁▁▁\n\n\nP8_10_1_1\n429702\n0.01\n3.55\n1.88\n1\n2.00\n4.0\n4.00\n8\n▅▁▇▁▁\n\n\nP8_10_1_2\n432009\n0.00\n4.49\n1.53\n1\n4.00\n4.0\n5.00\n8\n▁▁▇▂▁\n\n\nP8_10_1_3\n432519\n0.00\n5.35\n1.69\n1\n4.00\n5.0\n7.00\n8\n▁▁▇▂▅\n\n\nP8_11_1\n430239\n0.01\n3.09\n1.15\n1\n2.00\n4.0\n4.00\n9\n▅▇▁▁▁\n\n\nP8_12_1_1\n431558\n0.00\n3.69\n1.81\n1\n2.00\n4.0\n5.00\n8\n▃▁▇▁▁\n\n\nP8_12_1_2\n432470\n0.00\n4.69\n1.50\n2\n4.00\n4.0\n5.00\n8\n▃▇▅▂▂\n\n\nP8_10_2_1\n432262\n0.00\n4.50\n1.96\n1\n4.00\n4.0\n6.00\n8\n▂▁▇▂▂\n\n\nP8_11_2\n432339\n0.00\n3.23\n1.08\n1\n2.00\n4.0\n4.00\n9\n▃▇▁▁▁\n\n\nP8_10_3_1\n428664\n0.01\n2.42\n1.78\n1\n1.00\n2.0\n3.00\n8\n▇▂▂▁▁\n\n\nP8_10_3_2\n432090\n0.00\n3.98\n1.60\n1\n3.00\n4.0\n5.00\n8\n▃▃▇▁▂\n\n\nP8_10_3_3\n432576\n0.00\n5.14\n1.60\n1\n4.00\n5.0\n6.00\n8\n▁▂▇▁▃\n\n\nP8_11_3\n429930\n0.01\n3.45\n1.14\n1\n3.00\n4.0\n4.00\n9\n▂▇▁▁▁\n\n\nP8_12_3_1\n431849\n0.00\n2.63\n1.77\n1\n1.00\n2.0\n4.00\n8\n▇▂▃▁▁\n\n\nP8_13_3_1\n431849\n0.00\n1.30\n0.96\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP8_10_4_1\n430821\n0.00\n2.16\n1.56\n1\n1.00\n2.0\n3.00\n8\n▇▂▁▁▁\n\n\nP8_10_4_2\n432457\n0.00\n3.57\n1.50\n2\n2.00\n3.0\n4.00\n8\n▇▅▁▁▁\n\n\nP8_11_4\n431350\n0.00\n3.38\n1.14\n1\n3.00\n4.0\n4.00\n9\n▂▇▁▁▁\n\n\nP8_12_4_1\n432274\n0.00\n2.28\n1.47\n1\n1.00\n2.0\n3.00\n8\n▇▂▂▁▁\n\n\nP8_13_4_1\n432274\n0.00\n1.16\n0.72\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP8_10_5_1\n428761\n0.01\n3.26\n2.12\n1\n1.00\n3.0\n4.00\n8\n▇▁▆▁▂\n\n\nP8_10_5_2\n432126\n0.00\n4.56\n1.62\n1\n4.00\n4.0\n5.00\n8\n▂▂▇▂▂\n\n\nP8_11_5\n430061\n0.01\n3.37\n1.15\n1\n3.00\n4.0\n4.00\n9\n▂▇▁▁▁\n\n\nP8_12_5_1\n431822\n0.00\n3.52\n1.93\n1\n2.00\n4.0\n5.00\n8\n▆▁▇▁▁\n\n\nP8_13_5_1\n431822\n0.00\n1.33\n0.88\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP8_13_5_2\n432672\n0.00\n2.70\n1.13\n2\n2.00\n2.0\n3.00\n6\n▇▂▁▂▁\n\n\nP8_13_5_3\n432736\n0.00\n3.50\n0.71\n3\n3.00\n3.0\n4.00\n5\n▇▁▃▁▁\n\n\nP8_10_6_1\n425030\n0.02\n3.72\n1.80\n1\n2.00\n4.0\n4.00\n8\n▃▁▇▁▁\n\n\nP8_10_6_2\n430989\n0.00\n4.60\n1.47\n1\n4.00\n4.0\n5.00\n8\n▁▁▇▂▁\n\n\nP8_10_6_3\n432203\n0.00\n5.36\n1.51\n1\n4.00\n5.0\n6.00\n8\n▁▁▇▃▃\n\n\nP8_11_6\n427212\n0.01\n3.12\n1.22\n1\n2.00\n4.0\n4.00\n9\n▅▇▁▁▁\n\n\nP8_12_6_1\n430291\n0.01\n3.89\n1.64\n1\n4.00\n4.0\n5.00\n8\n▂▁▇▁▁\n\n\nP8_12_6_2\n432196\n0.00\n4.76\n1.37\n2\n4.00\n5.0\n5.00\n8\n▂▇▆▃▂\n\n\nP8_12_6_3\n432579\n0.00\n5.89\n1.52\n3\n5.00\n6.0\n7.50\n8\n▇▇▇▂▇\n\n\nP8_13_6_1\n430291\n0.01\n1.25\n0.84\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP8_13_6_2\n432564\n0.00\n2.52\n1.00\n2\n2.00\n2.0\n3.00\n6\n▇▁▁▁▁\n\n\nP8_13_6_3\n432716\n0.00\n3.63\n0.81\n3\n3.00\n3.0\n4.00\n6\n▇▅▁▂▁\n\n\nP8_10_7_1\n427724\n0.01\n3.15\n1.94\n1\n1.00\n3.0\n4.00\n8\n▇▂▇▁▁\n\n\nP8_10_7_2\n431646\n0.00\n4.31\n1.62\n1\n3.00\n4.0\n5.00\n8\n▂▂▇▁▂\n\n\nP8_10_7_3\n432427\n0.00\n5.04\n1.63\n1\n4.00\n5.0\n6.00\n8\n▁▂▇▂▃\n\n\nP8_11_7\n429292\n0.01\n3.20\n1.23\n1\n2.00\n4.0\n4.00\n9\n▃▇▁▁▁\n\n\nP8_12_7_1\n431315\n0.00\n3.29\n1.86\n1\n1.00\n4.0\n4.00\n8\n▇▁▇▁▁\n\n\nP8_12_7_2\n432423\n0.00\n4.37\n1.50\n2\n4.00\n4.0\n5.00\n8\n▅▇▅▂▂\n\n\nP8_12_7_3\n432650\n0.00\n5.15\n1.47\n3\n4.00\n5.0\n6.00\n8\n▇▆▃▂▂\n\n\nP8_13_7_1\n431315\n0.00\n1.22\n0.82\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP8_10_8_1\n432329\n0.00\n4.30\n2.11\n1\n4.00\n4.0\n6.00\n8\n▃▁▇▂▃\n\n\nP8_11_8\n432450\n0.00\n3.48\n0.99\n1\n3.00\n4.0\n4.00\n9\n▂▇▁▁▁\n\n\nP8_12_8_1\n432644\n0.00\n4.03\n2.03\n1\n3.25\n4.0\n5.00\n8\n▃▁▇▁▂\n\n\nP8_13_8_1\n432644\n0.00\n1.44\n0.92\n1\n1.00\n1.0\n2.00\n5\n▇▂▁▁▁\n\n\nP8_10_10_1\n432533\n0.00\n3.35\n2.07\n1\n1.00\n4.0\n4.00\n8\n▇▁▇▁▂\n\n\nP8_11_10\n432595\n0.00\n3.34\n1.18\n1\n2.50\n4.0\n4.00\n9\n▃▇▁▁▁\n\n\nP8_12_10_1\n432684\n0.00\n3.87\n1.92\n1\n2.25\n4.0\n5.00\n8\n▃▁▇▁▁\n\n\nP8_13_10_1\n432684\n0.00\n1.58\n1.44\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP8_10_11_1\n430369\n0.01\n3.95\n1.27\n1\n4.00\n4.0\n4.00\n8\n▁▁▇▁▁\n\n\nP8_10_11_2\n432421\n0.00\n4.88\n1.81\n1\n4.00\n4.0\n6.00\n8\n▂▁▇▂▃\n\n\nP8_11_11\n430901\n0.00\n3.23\n1.19\n1\n2.00\n4.0\n4.00\n9\n▃▇▁▁▁\n\n\nP8_12_11_1\n432018\n0.00\n3.97\n1.21\n1\n4.00\n4.0\n4.00\n8\n▁▁▇▁▁\n\n\nP8_13_11_1\n432018\n0.00\n1.14\n0.64\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP8_10_12_1\n430323\n0.01\n4.87\n2.02\n1\n4.00\n5.0\n6.00\n8\n▃▁▇▆▃\n\n\nP8_10_12_2\n432453\n0.00\n5.56\n1.84\n1\n4.00\n6.0\n8.00\n8\n▁▁▇▅▆\n\n\nP8_11_12\n431043\n0.00\n3.30\n1.13\n1\n2.00\n4.0\n4.00\n9\n▃▇▁▁▁\n\n\nP8_12_12_1\n432081\n0.00\n4.92\n1.89\n1\n4.00\n5.0\n6.00\n8\n▂▁▇▅▂\n\n\nP8_13_12_1\n432081\n0.00\n1.83\n0.74\n1\n1.00\n2.0\n2.00\n5\n▅▇▂▁▁\n\n\nP8_13_12_2\n432676\n0.00\n2.54\n0.85\n2\n2.00\n2.0\n3.00\n5\n▇▂▁▁▁\n\n\nP8_13_12_3\n432731\n0.00\n3.13\n0.35\n3\n3.00\n3.0\n3.00\n4\n▇▁▁▁▁\n\n\nP8_10_13_1\n431509\n0.00\n2.88\n2.14\n1\n1.00\n2.0\n4.00\n8\n▇▁▃▁▂\n\n\nP8_11_13\n431961\n0.00\n3.58\n1.17\n1\n3.00\n4.0\n4.00\n9\n▂▇▁▁▁\n\n\nP8_12_13_1\n432528\n0.00\n3.05\n2.01\n1\n1.00\n3.0\n4.00\n8\n▇▁▆▁▁\n\n\nP8_13_13_1\n432528\n0.00\n1.45\n1.10\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP8_10_14_1\n432380\n0.00\n3.24\n2.38\n1\n1.00\n3.0\n5.00\n8\n▇▁▃▁▂\n\n\nP8_11_14\n432519\n0.00\n3.48\n1.17\n1\n3.00\n4.0\n4.00\n9\n▂▇▁▁▁\n\n\nP8_12_14_1\n432676\n0.00\n3.27\n2.33\n1\n1.00\n3.5\n5.00\n8\n▇▁▆▁▂\n\n\nP8_13_14_1\n432676\n0.00\n2.16\n1.64\n1\n1.00\n1.0\n3.00\n6\n▇▁▁▂▁\n\n\nP8_10_15_1\n429080\n0.01\n3.34\n1.95\n1\n1.00\n4.0\n4.00\n8\n▇▁▇▁▂\n\n\nP8_10_15_2\n432243\n0.00\n4.56\n1.46\n1\n4.00\n4.0\n5.00\n8\n▁▁▇▁▂\n\n\nP8_11_15\n430135\n0.01\n3.40\n1.06\n1\n3.00\n4.0\n4.00\n9\n▂▇▁▁▁\n\n\nP8_12_15_1\n431816\n0.00\n3.53\n1.73\n1\n2.00\n4.0\n4.00\n8\n▅▁▇▁▁\n\n\nP8_13_15_1\n431816\n0.00\n1.25\n0.82\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP8_10_16_1\n431620\n0.00\n3.90\n2.22\n1\n1.00\n4.0\n6.00\n8\n▇▁▇▂▃\n\n\nP8_11_16\n431933\n0.00\n3.50\n1.10\n1\n3.00\n4.0\n4.00\n9\n▂▇▁▁▁\n\n\nP8_12_16_1\n432488\n0.00\n4.13\n1.92\n1\n3.00\n4.0\n5.00\n8\n▃▁▇▂▁\n\n\nP8_13_16_1\n432488\n0.00\n1.44\n1.01\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP8_10_17_1\n428939\n0.01\n2.64\n1.76\n1\n1.00\n2.0\n4.00\n8\n▇▂▃▁▁\n\n\nP8_10_17_2\n431725\n0.00\n3.75\n1.46\n1\n3.00\n4.0\n4.00\n8\n▃▂▇▁▁\n\n\nP8_10_17_3\n432418\n0.00\n4.65\n1.58\n1\n4.00\n4.0\n5.00\n8\n▁▃▇▁▂\n\n\nP8_11_17\n429977\n0.01\n3.12\n1.25\n1\n2.00\n4.0\n4.00\n9\n▅▇▁▁▁\n\n\nP8_12_17_1\n431512\n0.00\n2.58\n1.62\n1\n1.00\n2.0\n4.00\n8\n▇▂▃▁▁\n\n\nP8_12_17_2\n432383\n0.00\n3.79\n1.37\n2\n3.00\n4.0\n4.00\n8\n▆▇▂▁▁\n\n\nP8_12_17_3\n432634\n0.00\n4.89\n1.54\n3\n4.00\n5.0\n6.00\n8\n▇▃▂▁▂\n\n\nP8_13_17_1\n431512\n0.00\n1.17\n0.76\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP8_13_17_2\n432713\n0.00\n2.76\n1.32\n2\n2.00\n2.0\n3.00\n6\n▇▂▁▁▁\n\n\nP8_10_18_1\n428242\n0.01\n3.64\n1.86\n1\n2.00\n4.0\n4.00\n8\n▅▁▇▁▁\n\n\nP8_10_18_2\n431756\n0.00\n4.47\n1.63\n1\n4.00\n4.0\n5.00\n8\n▂▂▇▂▂\n\n\nP8_10_18_3\n432444\n0.00\n5.06\n1.64\n1\n4.00\n5.0\n6.00\n8\n▁▂▇▂▃\n\n\nP8_11_18\n429510\n0.01\n3.15\n1.21\n1\n2.00\n4.0\n4.00\n9\n▅▇▁▁▁\n\n\nP8_12_18_1\n431307\n0.00\n3.66\n1.74\n1\n2.00\n4.0\n4.00\n8\n▅▁▇▁▁\n\n\nP8_12_18_2\n432405\n0.00\n4.60\n1.56\n2\n4.00\n4.0\n5.00\n8\n▃▇▃▂▂\n\n\nP8_12_18_3\n432648\n0.00\n5.37\n1.58\n3\n4.00\n5.0\n6.75\n8\n▇▅▃▂▃\n\n\nP8_13_18_1\n431307\n0.00\n1.21\n0.75\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP8_10_19_1\n431709\n0.00\n3.87\n1.88\n1\n3.00\n4.0\n4.00\n8\n▃▁▇▁▂\n\n\nP8_11_19\n432027\n0.00\n3.36\n1.14\n1\n3.00\n4.0\n4.00\n9\n▂▇▁▁▁\n\n\nP8_12_19_1\n432465\n0.00\n3.94\n1.59\n1\n4.00\n4.0\n4.00\n8\n▂▁▇▁▁\n\n\nP8_13_19_1\n432465\n0.00\n1.31\n0.95\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nHOGAR\n0\n1.00\n1.03\n0.21\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nSEXO\n0\n1.00\n1.51\n0.50\n1\n1.00\n2.0\n2.00\n2\n▇▁▁▁▇\n\n\nGRA\n16648\n0.96\n3.12\n1.62\n0\n2.00\n3.0\n4.00\n9\n▂▇▂▂▁\n\n\nP2_8\n275478\n0.36\n1.30\n0.50\n1\n1.00\n1.0\n2.00\n9\n▇▁▁▁▁\n\n\nP2_9\n16648\n0.96\n1.71\n0.45\n1\n1.00\n2.0\n2.00\n2\n▃▁▁▁▇\n\n\nP2_10\n16648\n0.96\n2.53\n1.14\n1\n1.00\n3.0\n3.00\n8\n▃▇▁▁▁\n\n\nP2_11\n16648\n0.96\n1.93\n0.25\n1\n2.00\n2.0\n2.00\n2\n▁▁▁▁▇\n\n\nP2_12\n405162\n0.06\n1.08\n0.26\n1\n1.00\n1.0\n1.00\n2\n▇▁▁▁▁\n\n\nP2_13\n81468\n0.81\n1.46\n0.50\n1\n1.00\n1.0\n2.00\n2\n▇▁▁▁▇\n\n\nP2_15\n230938\n0.47\n2.17\n1.50\n1\n1.00\n1.0\n4.00\n6\n▇▁▃▁▁\n\n\nP2_16\n81468\n0.81\n4.35\n1.86\n1\n3.00\n5.0\n6.00\n6\n▆▁▁▇▇\n\n\nCOD_M15\n263134\n0.39\n1.00\n0.00\n1\n1.00\n1.0\n1.00\n1\n▁▁▇▁▁\n\n\nCODIGO\n263134\n0.39\n0.65\n0.48\n0\n0.00\n1.0\n1.00\n1\n▅▁▁▁▇\n\n\nFAC_MUJ\n0\n1.00\n116.75\n326.98\n0\n0.00\n0.0\n58.00\n8836\n▇▁▁▁▁\n\n\nP1_1\n0\n1.00\n2.40\n0.55\n1\n2.00\n2.0\n3.00\n3\n▁▁▇▁▆\n\n\nP1_4_1\n0\n1.00\n1.41\n0.49\n1\n1.00\n1.0\n2.00\n2\n▇▁▁▁▆\n\n\nP1_4_2\n0\n1.00\n1.08\n0.27\n1\n1.00\n1.0\n1.00\n2\n▇▁▁▁▁\n\n\nP1_4_3\n0\n1.00\n1.58\n0.49\n1\n1.00\n2.0\n2.00\n2\n▆▁▁▁▇\n\n\nP1_4_4\n0\n1.00\n1.64\n0.48\n1\n1.00\n2.0\n2.00\n2\n▅▁▁▁▇\n\n\nP1_4_5\n0\n1.00\n1.06\n0.24\n1\n1.00\n1.0\n1.00\n2\n▇▁▁▁▁\n\n\nP1_4_6\n0\n1.00\n1.10\n0.30\n1\n1.00\n1.0\n1.00\n2\n▇▁▁▁▁\n\n\nP1_4_7\n0\n1.00\n1.24\n0.42\n1\n1.00\n1.0\n1.00\n2\n▇▁▁▁▂\n\n\nP1_4_8\n0\n1.00\n1.51\n0.50\n1\n1.00\n2.0\n2.00\n2\n▇▁▁▁▇\n\n\nP1_4_9\n0\n1.00\n1.36\n0.48\n1\n1.00\n1.0\n2.00\n2\n▇▁▁▁▅\n\n\nP1_5\n0\n1.00\n1.43\n1.10\n1\n1.00\n1.0\n1.00\n6\n▇▁▁▁▁\n\n\nP1_6\n0\n1.00\n1.36\n0.76\n1\n1.00\n1.0\n2.00\n5\n▇▂▁▁▁\n\n\nP1_8\n0\n1.00\n1.05\n0.22\n1\n1.00\n1.0\n1.00\n2\n▇▁▁▁▁\n\n\nP1_10_1\n411265\n0.05\n0.11\n0.31\n0\n0.00\n0.0\n0.00\n1\n▇▁▁▁▁\n\n\nP1_10_2\n411265\n0.05\n0.84\n0.36\n0\n1.00\n1.0\n1.00\n1\n▂▁▁▁▇\n\n\nP1_10_3\n411265\n0.05\n0.11\n0.32\n0\n0.00\n0.0\n0.00\n1\n▇▁▁▁▁\n\n\nP1_10_4\n411265\n0.05\n0.13\n0.33\n0\n0.00\n0.0\n0.00\n1\n▇▁▁▁▁\n\n\nFAC_VIV\n0\n1.00\n295.70\n252.31\n12\n132.00\n226.0\n363.00\n2826\n▇▁▁▁▁\n\n\nESTRATO\n0\n1.00\n2.14\n0.82\n1\n2.00\n2.0\n3.00\n4\n▃▇▁▃▁"
  }
]